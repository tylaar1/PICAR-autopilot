{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fhwRSFoj6C_"
   },
   "source": [
    "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4V83PflfFkL"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "kP6UczzNe1l2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O24_U-m8q-xv",
    "outputId": "f2298893-2e7e-4b8f-cc38-0caeb1a6a670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.system())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "IF_vPVifaU9V"
   },
   "outputs": [],
   "source": [
    "# makes it so pd dfs aren't truncated\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "eocC68amnhEI"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_MvRvYnfIM5"
   },
   "source": [
    "# 1) DATA PRE-PROCESSING\n",
    "\n",
    "a) Load in kaggle data labels + image file paths\n",
    "\n",
    "b) combine kaggle data labels and image file paths into one dataframe\n",
    "\n",
    "c) load in the extra 486 image file paths\n",
    "\n",
    "d) extract the speed and angle labels from the file path names\n",
    "\n",
    "e) store that extra data in a pandas df and do the value normalisation\n",
    "\n",
    "f) merge the kaggle and extra data dfs\n",
    "\n",
    "g) EDA\n",
    "\n",
    "h) convert the images to numerical RGB feature maps\n",
    "\n",
    "i) split data into training-validation sets\n",
    "\n",
    "j) data augmentation applied to training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU3TvBZ5hfhX"
   },
   "source": [
    "### 1a) load in kaggle data labels + image file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "ZiNf_BxOfEH-"
   },
   "outputs": [],
   "source": [
    "# labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # tylers file path\n",
    "labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
    "# labels_file_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_norm.csv' # tyler hpc file path (mlis2 cluster)\n",
    "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "nOXmN--gb-Q9"
   },
   "outputs": [],
   "source": [
    "image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data' # OG data ben hpc file path (mlis2 cluster)\n",
    "# image_folder_path = '/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data'\n",
    "# image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
    "image_file_paths = [\n",
    "    os.path.join(image_folder_path, f)\n",
    "    for f in os.listdir(image_folder_path)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "]\n",
    "\n",
    "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
    "\n",
    "imagefilepaths_df = pd.DataFrame(\n",
    "    image_file_paths,\n",
    "    columns=['image_file_paths'],\n",
    "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
    ")\n",
    "\n",
    "imagefilepaths_df.index.name = 'image_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oeuvmeZaGSC"
   },
   "source": [
    "Checking labels dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pi13TZ2aFhO",
    "outputId": "fc675bb2-271b-48fd-a6c3-43834afb4500"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           angle  speed\n",
       "image_id               \n",
       "1         0.4375    0.0\n",
       "2         0.8125    1.0\n",
       "3         0.4375    1.0\n",
       "4         0.6250    1.0\n",
       "5         0.5000    0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puEjGoOJaRS4"
   },
   "source": [
    "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1suFSK7aWKH",
    "outputId": "c3cc2d29-d759-48ff-b92c-77dbd178f295"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/5.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      image_file_paths\n",
       "image_id                                                                                              \n",
       "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png\n",
       "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png\n",
       "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png\n",
       "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/4.png\n",
       "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/5.png"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagefilepaths_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjDdyYd6cMBE"
   },
   "source": [
    "### 1b) Combine the kaggle labels and image file paths into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "6NdbonzPcLKB"
   },
   "outputs": [],
   "source": [
    "kaggle_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
    "kaggle_df['speed'] = kaggle_df['speed'].round(6) # to get rid of floating point errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VstirIAdAZi",
    "outputId": "c03ff707-9e8d-4c3a-8965-f795919ace21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13794</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13794.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13795</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13795.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13796</th>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13796.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13798</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           angle  speed  \\\n",
       "image_id                  \n",
       "13794     0.6250    1.0   \n",
       "13795     0.4375    1.0   \n",
       "13796     0.5625    0.0   \n",
       "13797     0.6250    0.0   \n",
       "13798     0.6875    1.0   \n",
       "\n",
       "                                                                                          image_file_paths  \n",
       "image_id                                                                                                    \n",
       "13794     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13794.png  \n",
       "13795     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13795.png  \n",
       "13796     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13796.png  \n",
       "13797     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png  \n",
       "13798     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MgNoL8nfBm2",
    "outputId": "924e7562-25a4-4223-8305-c3fd02452846"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3139.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3140.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3142.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3143.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          angle  speed  \\\n",
       "image_id                 \n",
       "3139      0.750    1.0   \n",
       "3140      0.875    1.0   \n",
       "3142      0.625    0.0   \n",
       "3143      0.625    1.0   \n",
       "\n",
       "                                                                                         image_file_paths  \n",
       "image_id                                                                                                   \n",
       "3139      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3139.png  \n",
       "3140      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3140.png  \n",
       "3142      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3142.png  \n",
       "3143      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3143.png  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_df.loc[3139:3143]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7PCxqJbmXE6"
   },
   "source": [
    "The above cell shows that:\n",
    "\n",
    " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
    "\n",
    " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOEWqBUYX6DL"
   },
   "source": [
    "### 1c) load in the extra 486 labels image file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "wvsDiCCLOvvs"
   },
   "outputs": [],
   "source": [
    "extradata_folder_path = '/home/apyba3/petru_data'\n",
    "\n",
    "extradata_file_paths = [\n",
    "    os.path.join(extradata_folder_path, f)\n",
    "    for f in os.listdir(extradata_folder_path)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4ofcGILO4et"
   },
   "source": [
    "### 1d) extract the speed and angle labels from the file path names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFsEI4MBRf2l"
   },
   "source": [
    "image file path name follows the pattern: `randomnumber_angle_speed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "mY5-HDp-PJY9"
   },
   "outputs": [],
   "source": [
    "# Regex pattern to extract angle and speed values\n",
    "pattern = r'(\\d+)_([\\d]+)_([\\d]+)\\.png'\n",
    "\n",
    "angle_value = []\n",
    "speed_value = []\n",
    "\n",
    "# Loop through file paths and extract angle and speed values\n",
    "for file_path in extradata_file_paths:\n",
    "    match = re.search(pattern, file_path)\n",
    "    if match:\n",
    "        # Extract random number, angle, and speed values\n",
    "        random_number = match.group(1)\n",
    "        angle_value.append(int(match.group(2)))\n",
    "        speed_value.append(int(match.group(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4F8qIQJ8Y3t8"
   },
   "source": [
    "checking it has stored the labels correctly (check if the angle_value order matches that of the file path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mf1bChw_OvsT",
    "outputId": "bdf648d9-3ab3-403e-c977-0c938ae1bf18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 100, 80]\n",
      "['/home/apyba3/petru_data/1712918428740_95_0.png', '/home/apyba3/petru_data/1712923220525_100_50.png', '/home/apyba3/petru_data/1712923068961_80_35.png']\n"
     ]
    }
   ],
   "source": [
    "print(angle_value[:3])\n",
    "print(extradata_file_paths[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyvljUTBZP0E"
   },
   "source": [
    "### 1e) store that extra data in a pandas df and do the value normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tse95lu1OvnY",
    "outputId": "90ed60a7-5f9c-4901-f7ed-7442d739ccfb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13799</th>\n",
       "      <td>0.5625</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/apyba3/petru_data/1712918428740_95_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13800</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/apyba3/petru_data/1712923220525_100_50.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13801</th>\n",
       "      <td>0.3750</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/apyba3/petru_data/1712923068961_80_35.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13802</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/apyba3/petru_data/1712921566265_105_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13803</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/apyba3/petru_data/1712915924250_70_35.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           angle  speed                                  image_file_paths\n",
       "image_id                                                                 \n",
       "13799     0.5625      0    /home/apyba3/petru_data/1712918428740_95_0.png\n",
       "13800     0.6250      1  /home/apyba3/petru_data/1712923220525_100_50.png\n",
       "13801     0.3750      1   /home/apyba3/petru_data/1712923068961_80_35.png\n",
       "13802     0.6875      0   /home/apyba3/petru_data/1712921566265_105_0.png\n",
       "13803     0.2500      1   /home/apyba3/petru_data/1712915924250_70_35.png"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extradata_df = pd.DataFrame({\n",
    "    'angle': angle_value,\n",
    "    'speed': speed_value,\n",
    "    'image_file_paths': extradata_file_paths\n",
    "})\n",
    "\n",
    "# conversions (see kaggle data section)\n",
    "extradata_df.loc[extradata_df['speed'] > 0, 'speed'] = 1\n",
    "extradata_df['speed'] = pd.to_numeric(extradata_df['speed'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "extradata_df['angle'] = (extradata_df['angle'] - 50)/80\n",
    "\n",
    "extradata_df.index = pd.RangeIndex(start=13799, stop=13799 + len(extradata_df), step=1)\n",
    "extradata_df.index.name = 'image_id'\n",
    "\n",
    "extradata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qv0MwDKsbOef"
   },
   "source": [
    "### 1f) merge the kaggle and extra data dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZMZPUn4b3Kc",
    "outputId": "86bd34db-0b48-442e-b5b2-5ff322d0764b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13798</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13799</th>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/apyba3/petru_data/1712918428740_95_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13800</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/petru_data/1712923220525_100_50.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           angle  speed  \\\n",
       "image_id                  \n",
       "13797     0.6250    0.0   \n",
       "13798     0.6875    1.0   \n",
       "13799     0.5625    0.0   \n",
       "13800     0.6250    1.0   \n",
       "\n",
       "                                                                                          image_file_paths  \n",
       "image_id                                                                                                    \n",
       "13797     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png  \n",
       "13798     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png  \n",
       "13799                                                       /home/apyba3/petru_data/1712918428740_95_0.png  \n",
       "13800                                                     /home/apyba3/petru_data/1712923220525_100_50.png  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([kaggle_df, extradata_df])\n",
    "merged_df.loc[13797:13800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3OKLcn9u0Pz"
   },
   "source": [
    "### 1g) EDA - speed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angle\n",
       "0.0000      75\n",
       "0.0625      38\n",
       "0.1250     114\n",
       "0.1875     119\n",
       "0.2500     118\n",
       "0.3125     229\n",
       "0.3750     447\n",
       "0.4375    1520\n",
       "0.5000    2172\n",
       "0.5625    1644\n",
       "0.6250    2000\n",
       "0.6875    2049\n",
       "0.7500    2172\n",
       "0.8125    1162\n",
       "0.8750     308\n",
       "0.9375      74\n",
       "1.0000      38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kaggle_df['speed'].value_counts().sort_index()\n",
    "merged_df['angle'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get value counts\n",
    "speed_counts = merged_df['speed'].value_counts().sort_index()\n",
    "angle_counts = merged_df['angle'].value_counts().sort_index()\n",
    "\n",
    "# Create subplots with custom width ratios\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 4), gridspec_kw={'width_ratios': [1,4]})  # Speed plot narrower\n",
    "\n",
    "# Plot speed\n",
    "speed_counts.plot(kind='bar', edgecolor='black', ax=axes[0])\n",
    "# axes[0].set_title('Speed', fontsize=15)\n",
    "axes[0].set_xlabel('Speed', fontsize=17)\n",
    "axes[0].set_ylabel('Count', fontsize=17)\n",
    "axes[0].tick_params(axis='both', labelsize=15)\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot angle\n",
    "angle_counts.plot(kind='bar', edgecolor='black', ax=axes[1])\n",
    "# axes[1].set_title('Angle', fontsize=15)\n",
    "axes[1].set_xlabel('Angle', fontsize=17, labelpad=22)\n",
    "# axes[1].set_ylabel('Count', fontsize=17)\n",
    "axes[1].tick_params(axis='both', labelsize=15)\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout()\n",
    "plt.savefig('speed_angle_distribution.pdf', format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWQCQrR-oCps",
    "outputId": "88bb4558-2c8a-482b-de5d-8f7876ed9bc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speed\n",
       "1.000000    10840\n",
       "0.000000     3438\n",
       "1.428571        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.value_counts('speed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4pZ65pYvdqb"
   },
   "source": [
    "note: imbalance datset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMZq41-RkLz0"
   },
   "source": [
    "we want to remove the row containing the erroneous 1.428571 speed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "TDMqIiOLSKGX"
   },
   "outputs": [],
   "source": [
    "cleaned_df = merged_df[merged_df['speed'] != 1.428571]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speed\n",
       "1.0    10840\n",
       "0.0     3438\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.value_counts('speed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Di6F6km_DBmj"
   },
   "source": [
    "### 1h) convert images to numerical RGB feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "oeeBTruNCQ96"
   },
   "outputs": [],
   "source": [
    "def process_image(image_path, label, resized_shape=(224, 224)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, resized_shape)\n",
    "    image = image / 255.0  # Normalise pixel values to [0,1]\n",
    "    return image, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"speed\"])) # Convert pd df into a tf ds\n",
    "\n",
    "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(len(cleaned_df))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUOlsWQeVlyC"
   },
   "source": [
    "lets check and see if what we have done works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBTNjNhMVk2g",
    "outputId": "b00f1443-c179-43a2-e6fd-7cc90ff698f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 08:47:10.740034: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 2672 of 14279\n",
      "2025-04-17 08:47:20.742468: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 6293 of 14279\n",
      "2025-04-17 08:47:40.746452: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 13427 of 14279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3) (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 08:47:43.511810: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
      "2025-04-17 08:47:43.554163: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for images, labels in dataset.take(1):\n",
    "    print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Md6U_i84SiK5"
   },
   "source": [
    "### 1i) Splitting data into training and validation sets (test set is already provided in kaggle data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "yYlssPh5dxaO"
   },
   "outputs": [],
   "source": [
    "# 80-20 split\n",
    "\n",
    "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "train_size = int(0.8 * dataset_size)\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPUE6rd8cgQN",
    "outputId": "a418b177-e08d-481c-d272-b9b7494882d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 357, validation size: 90\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {train_size}, validation size: {dataset_size - train_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ujsjhMPSw4f"
   },
   "source": [
    "### 1j) Data Augmentation applied to training set\n",
    "\n",
    "- Random Brightness Adjustment\n",
    "- Random Contrast Adjustment\n",
    "- Random Hue Adjustment\n",
    "- Random Saturation Adjustment\n",
    "- Random Horizontal Flip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "T9r811eWsYfe"
   },
   "outputs": [],
   "source": [
    "def augment_image(image, label):\n",
    "  seed = (6, 9)\n",
    "  image = tf.image.stateless_random_brightness(image, 0.2, seed)\n",
    "  image = tf.image.stateless_random_contrast(image, 0.8, 1.2, seed)\n",
    "  image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
    "  image = tf.image.stateless_random_saturation(image, 0.8, 1.2, seed)\n",
    "  image = tf.image.stateless_random_flip_left_right(image, seed)\n",
    "  return image, label\n",
    "\n",
    "# Create a dataset of augmented images from the original train_dataset\n",
    "augmented_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Concatenate the original and augmented datasets\n",
    "train_dataset = train_dataset.concatenate(augmented_dataset)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(cleaned_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 09:08:04.271707: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:26: Filling up shuffle buffer (this may take a while): 697 of 14278\n",
      "2025-04-17 09:08:04.444216: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0     5490\n",
      "1.0    17358\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "angle_list = []\n",
    "\n",
    "for image_batch, label_batch in train_dataset:\n",
    "    angle_list.extend(label_batch.numpy())  # add all 32 values from the batch\n",
    "\n",
    "angle_distribution = pd.Series(angle_list).value_counts().sort_index()\n",
    "print(angle_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOqizFg7rvKq"
   },
   "source": [
    "count how many images are in the training set - 22016 with no extradata and 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjlyfjAxLsrC",
    "outputId": "14dc79ee-e1b4-4c37-bfb1-b6525bc586c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 16:20:24.445589: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in train_dataset: 22848\n"
     ]
    }
   ],
   "source": [
    "total_images = 0\n",
    "for image_batch, _ in train_dataset:\n",
    "    total_images += image_batch.shape[0]  # Add the batch size\n",
    "\n",
    "print(f\"Total number of images in train_dataset: {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEdi-dUCTND1"
   },
   "source": [
    "checking to see if whats been done was successful or needs debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OeboVhsQKGFS",
    "outputId": "b9c6bb08-d7ce-4951-b621-6775a6ee3bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.058292344..1.2457294].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.032506987..1.2031907].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.2810742].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.04956171..1.2650514].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0284352..1.2388163].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.2535071].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [6.660819e-05..1.2241662].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.2345543].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.03131132..1.2007287].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.052848548..1.2127264].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1,10)\n",
    "\n",
    "i = 0\n",
    "for image_batch, label_batch in train_dataset.take(1):  # Take one batch\n",
    "    for image in image_batch:  # Iterate through images in the batch\n",
    "        if i < 10:  # Only display the first 5 images\n",
    "            print('image shape: ', np.shape(image))\n",
    "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
    "            axarr[i].imshow(image)\n",
    "            axarr[i].axis('off')\n",
    "            i += 1\n",
    "        else:\n",
    "            break  # Stop after displaying 5 images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmetmzNHTWzU"
   },
   "source": [
    "# 2) CLASSIFICATION SPEED Model Building - MobNetV3Small Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48RHLVshdX5L"
   },
   "source": [
    "### 2a) Set up model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "aHjqXG1jSnCr"
   },
   "outputs": [],
   "source": [
    "dropoutrate = 0.2\n",
    "input_shape = (224,224,3)\n",
    "num_classes = 1 # we're only predicting the prob of the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "id": "ZPso3wBuN9L3",
    "outputId": "ef11a9ff-7117-4836-dd78-9bcadac15995"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " MobileNetV3Small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> \n",
       "\n",
       " global_average_pooling2d         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)                                               \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">577</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " MobileNetV3Small (\u001b[38;5;33mFunctional\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m)             \u001b[38;5;34m939,120\u001b[0m \n",
       "\n",
       " global_average_pooling2d         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)                                               \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                         \u001b[38;5;34m577\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">939,697</span> (3.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m939,697\u001b[0m (3.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">577</span> (2.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m577\u001b[0m (2.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> (3.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m939,120\u001b[0m (3.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobnetv3small = tf.keras.applications.MobileNetV3Small(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = input_shape\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  mobnetv3small,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dropout(dropoutrate),\n",
    "  tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "mobnetv3small.trainable = False  # freeze mobnetv3small layers\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ca0JFQuuN8oI"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) train the model with the mobnetv3small layers frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WPTNOtr7WjLS",
    "outputId": "63cf5fac-6100-43db-dadd-47da686c9712",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Epoch 1...\n",
      "Epoch 1/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7494 - auc: 0.4941 - loss: 0.5626 \n",
      "Epoch 1: val_loss improved from inf to 0.54240, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 1, Loss: 0.5567, Val Loss: 0.5424\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 89ms/step - accuracy: 0.7494 - auc: 0.4942 - loss: 0.5626 - val_accuracy: 0.7625 - val_auc: 0.7439 - val_loss: 0.5424\n",
      "\n",
      "Starting Epoch 2...\n",
      "Epoch 2/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7543 - auc: 0.5814 - loss: 0.5503 \n",
      "Epoch 2: val_loss improved from 0.54240 to 0.53790, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 2, Loss: 0.5444, Val Loss: 0.5379\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 88ms/step - accuracy: 0.7544 - auc: 0.5814 - loss: 0.5503 - val_accuracy: 0.7604 - val_auc: 0.7723 - val_loss: 0.5379\n",
      "\n",
      "Starting Epoch 3...\n",
      "Epoch 3/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7595 - auc: 0.6246 - loss: 0.5380 \n",
      "Epoch 3: val_loss did not improve from 0.53790\n",
      "Completed Epoch 3, Loss: 0.5371, Val Loss: 0.5381\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 87ms/step - accuracy: 0.7595 - auc: 0.6246 - loss: 0.5380 - val_accuracy: 0.7562 - val_auc: 0.7663 - val_loss: 0.5381\n",
      "\n",
      "Starting Epoch 4...\n",
      "Epoch 4/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7563 - auc: 0.6575 - loss: 0.5347 \n",
      "Epoch 4: val_loss improved from 0.53790 to 0.52958, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 4, Loss: 0.5294, Val Loss: 0.5296\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7563 - auc: 0.6575 - loss: 0.5347 - val_accuracy: 0.7583 - val_auc: 0.7918 - val_loss: 0.5296\n",
      "\n",
      "Starting Epoch 5...\n",
      "Epoch 5/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7584 - auc: 0.6802 - loss: 0.5264 \n",
      "Epoch 5: val_loss improved from 0.52958 to 0.52437, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 5, Loss: 0.5257, Val Loss: 0.5244\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 89ms/step - accuracy: 0.7584 - auc: 0.6802 - loss: 0.5264 - val_accuracy: 0.7625 - val_auc: 0.8023 - val_loss: 0.5244\n",
      "\n",
      "Starting Epoch 6...\n",
      "Epoch 6/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7586 - auc: 0.6879 - loss: 0.5230 \n",
      "Epoch 6: val_loss improved from 0.52437 to 0.52203, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 6, Loss: 0.5218, Val Loss: 0.5220\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7586 - auc: 0.6879 - loss: 0.5230 - val_accuracy: 0.7611 - val_auc: 0.7896 - val_loss: 0.5220\n",
      "\n",
      "Starting Epoch 7...\n",
      "Epoch 7/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7600 - auc: 0.6867 - loss: 0.5208 \n",
      "Epoch 7: val_loss improved from 0.52203 to 0.49890, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 7, Loss: 0.5187, Val Loss: 0.4989\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 88ms/step - accuracy: 0.7600 - auc: 0.6867 - loss: 0.5208 - val_accuracy: 0.7762 - val_auc: 0.8015 - val_loss: 0.4989\n",
      "\n",
      "Starting Epoch 8...\n",
      "Epoch 8/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7576 - auc: 0.7080 - loss: 0.5181 \n",
      "Epoch 8: val_loss did not improve from 0.49890\n",
      "Completed Epoch 8, Loss: 0.5130, Val Loss: 0.5078\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7576 - auc: 0.7080 - loss: 0.5181 - val_accuracy: 0.7629 - val_auc: 0.8185 - val_loss: 0.5078\n",
      "\n",
      "Starting Epoch 9...\n",
      "Epoch 9/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7638 - auc: 0.7133 - loss: 0.5085 \n",
      "Epoch 9: val_loss did not improve from 0.49890\n",
      "Completed Epoch 9, Loss: 0.5116, Val Loss: 0.5081\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7638 - auc: 0.7133 - loss: 0.5085 - val_accuracy: 0.7597 - val_auc: 0.8209 - val_loss: 0.5081\n",
      "\n",
      "Starting Epoch 10...\n",
      "Epoch 10/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7686 - auc: 0.7096 - loss: 0.5029 \n",
      "Epoch 10: val_loss did not improve from 0.49890\n",
      "Completed Epoch 10, Loss: 0.5114, Val Loss: 0.5052\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7686 - auc: 0.7096 - loss: 0.5029 - val_accuracy: 0.7594 - val_auc: 0.8365 - val_loss: 0.5052\n",
      "\n",
      "Starting Epoch 11...\n",
      "Epoch 11/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7645 - auc: 0.7103 - loss: 0.5064 \n",
      "Epoch 11: val_loss did not improve from 0.49890\n",
      "Completed Epoch 11, Loss: 0.5086, Val Loss: 0.5095\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7645 - auc: 0.7103 - loss: 0.5064 - val_accuracy: 0.7531 - val_auc: 0.8324 - val_loss: 0.5095\n",
      "\n",
      "Starting Epoch 12...\n",
      "Epoch 12/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7669 - auc: 0.7196 - loss: 0.5011 \n",
      "Epoch 12: val_loss improved from 0.49890 to 0.48812, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 12, Loss: 0.5025, Val Loss: 0.4881\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7669 - auc: 0.7196 - loss: 0.5011 - val_accuracy: 0.7727 - val_auc: 0.8229 - val_loss: 0.4881\n",
      "\n",
      "Starting Epoch 13...\n",
      "Epoch 13/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7721 - auc: 0.7176 - loss: 0.4966 \n",
      "Epoch 13: val_loss did not improve from 0.48812\n",
      "Completed Epoch 13, Loss: 0.5015, Val Loss: 0.5034\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7721 - auc: 0.7176 - loss: 0.4966 - val_accuracy: 0.7555 - val_auc: 0.8287 - val_loss: 0.5034\n",
      "\n",
      "Starting Epoch 14...\n",
      "Epoch 14/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7694 - auc: 0.7309 - loss: 0.4951 \n",
      "Epoch 14: val_loss improved from 0.48812 to 0.47890, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 14, Loss: 0.4995, Val Loss: 0.4789\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 89ms/step - accuracy: 0.7694 - auc: 0.7309 - loss: 0.4951 - val_accuracy: 0.7737 - val_auc: 0.8550 - val_loss: 0.4789\n",
      "\n",
      "Starting Epoch 15...\n",
      "Epoch 15/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7673 - auc: 0.7272 - loss: 0.4973 \n",
      "Epoch 15: val_loss did not improve from 0.47890\n",
      "Completed Epoch 15, Loss: 0.4971, Val Loss: 0.5086\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7673 - auc: 0.7272 - loss: 0.4973 - val_accuracy: 0.7426 - val_auc: 0.8527 - val_loss: 0.5086\n",
      "\n",
      "Starting Epoch 16...\n",
      "Epoch 16/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7633 - auc: 0.7324 - loss: 0.4996 \n",
      "Epoch 16: val_loss did not improve from 0.47890\n",
      "Completed Epoch 16, Loss: 0.4942, Val Loss: 0.4994\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7633 - auc: 0.7324 - loss: 0.4996 - val_accuracy: 0.7604 - val_auc: 0.8476 - val_loss: 0.4994\n",
      "\n",
      "Starting Epoch 17...\n",
      "Epoch 17/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7673 - auc: 0.7395 - loss: 0.4925 \n",
      "Epoch 17: val_loss did not improve from 0.47890\n",
      "Completed Epoch 17, Loss: 0.4953, Val Loss: 0.4880\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7673 - auc: 0.7395 - loss: 0.4925 - val_accuracy: 0.7646 - val_auc: 0.8374 - val_loss: 0.4880\n",
      "\n",
      "Starting Epoch 18...\n",
      "Epoch 18/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7661 - auc: 0.7318 - loss: 0.4984 \n",
      "Epoch 18: val_loss did not improve from 0.47890\n",
      "Completed Epoch 18, Loss: 0.4969, Val Loss: 0.4894\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 88ms/step - accuracy: 0.7661 - auc: 0.7319 - loss: 0.4984 - val_accuracy: 0.7583 - val_auc: 0.8467 - val_loss: 0.4894\n",
      "\n",
      "Starting Epoch 19...\n",
      "Epoch 19/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7601 - auc: 0.7379 - loss: 0.5008 \n",
      "Epoch 19: val_loss did not improve from 0.47890\n",
      "Completed Epoch 19, Loss: 0.4940, Val Loss: 0.4986\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7601 - auc: 0.7379 - loss: 0.5008 - val_accuracy: 0.7597 - val_auc: 0.8472 - val_loss: 0.4986\n",
      "\n",
      "Starting Epoch 20...\n",
      "Epoch 20/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7713 - auc: 0.7370 - loss: 0.4893 \n",
      "Epoch 20: val_loss improved from 0.47890 to 0.47621, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 20, Loss: 0.4909, Val Loss: 0.4762\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 88ms/step - accuracy: 0.7713 - auc: 0.7370 - loss: 0.4893 - val_accuracy: 0.7702 - val_auc: 0.8489 - val_loss: 0.4762\n",
      "\n",
      "Starting Epoch 21...\n",
      "Epoch 21/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7675 - auc: 0.7451 - loss: 0.4921 \n",
      "Epoch 21: val_loss improved from 0.47621 to 0.47145, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 21, Loss: 0.4892, Val Loss: 0.4714\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 88ms/step - accuracy: 0.7675 - auc: 0.7451 - loss: 0.4921 - val_accuracy: 0.7706 - val_auc: 0.8572 - val_loss: 0.4714\n",
      "\n",
      "Starting Epoch 22...\n",
      "Epoch 22/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7705 - auc: 0.7461 - loss: 0.4883 \n",
      "Epoch 22: val_loss did not improve from 0.47145\n",
      "Completed Epoch 22, Loss: 0.4892, Val Loss: 0.4720\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7705 - auc: 0.7461 - loss: 0.4883 - val_accuracy: 0.7674 - val_auc: 0.8662 - val_loss: 0.4720\n",
      "\n",
      "Starting Epoch 23...\n",
      "Epoch 23/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7692 - auc: 0.7451 - loss: 0.4901 \n",
      "Epoch 23: val_loss improved from 0.47145 to 0.47014, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 23, Loss: 0.4863, Val Loss: 0.4701\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 88ms/step - accuracy: 0.7692 - auc: 0.7452 - loss: 0.4901 - val_accuracy: 0.7699 - val_auc: 0.8526 - val_loss: 0.4701\n",
      "\n",
      "Starting Epoch 24...\n",
      "Epoch 24/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7708 - auc: 0.7513 - loss: 0.4837 \n",
      "Epoch 24: val_loss did not improve from 0.47014\n",
      "Completed Epoch 24, Loss: 0.4834, Val Loss: 0.4999\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7708 - auc: 0.7513 - loss: 0.4837 - val_accuracy: 0.7429 - val_auc: 0.8567 - val_loss: 0.4999\n",
      "\n",
      "Starting Epoch 25...\n",
      "Epoch 25/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7735 - auc: 0.7495 - loss: 0.4830 \n",
      "Epoch 25: val_loss did not improve from 0.47014\n",
      "Completed Epoch 25, Loss: 0.4853, Val Loss: 0.4702\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7735 - auc: 0.7495 - loss: 0.4830 - val_accuracy: 0.7678 - val_auc: 0.8675 - val_loss: 0.4702\n",
      "\n",
      "Starting Epoch 26...\n",
      "Epoch 26/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7695 - auc: 0.7540 - loss: 0.4860 \n",
      "Epoch 26: val_loss did not improve from 0.47014\n",
      "Completed Epoch 26, Loss: 0.4847, Val Loss: 0.4736\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7695 - auc: 0.7540 - loss: 0.4860 - val_accuracy: 0.7615 - val_auc: 0.8634 - val_loss: 0.4736\n",
      "\n",
      "Starting Epoch 27...\n",
      "Epoch 27/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7785 - auc: 0.7483 - loss: 0.4780 \n",
      "Epoch 27: val_loss improved from 0.47014 to 0.46259, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 27, Loss: 0.4816, Val Loss: 0.4626\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 87ms/step - accuracy: 0.7785 - auc: 0.7483 - loss: 0.4780 - val_accuracy: 0.7748 - val_auc: 0.8578 - val_loss: 0.4626\n",
      "\n",
      "Starting Epoch 28...\n",
      "Epoch 28/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7701 - auc: 0.7447 - loss: 0.4866 \n",
      "Epoch 28: val_loss did not improve from 0.46259\n",
      "Completed Epoch 28, Loss: 0.4826, Val Loss: 0.4671\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7702 - auc: 0.7447 - loss: 0.4866 - val_accuracy: 0.7657 - val_auc: 0.8751 - val_loss: 0.4671\n",
      "\n",
      "Starting Epoch 29...\n",
      "Epoch 29/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7749 - auc: 0.7528 - loss: 0.4794 \n",
      "Epoch 29: val_loss did not improve from 0.46259\n",
      "Completed Epoch 29, Loss: 0.4802, Val Loss: 0.4778\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7749 - auc: 0.7528 - loss: 0.4794 - val_accuracy: 0.7545 - val_auc: 0.8749 - val_loss: 0.4778\n",
      "\n",
      "Starting Epoch 30...\n",
      "Epoch 30/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7762 - auc: 0.7543 - loss: 0.4776 \n",
      "Epoch 30: val_loss did not improve from 0.46259\n",
      "Completed Epoch 30, Loss: 0.4811, Val Loss: 0.4714\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7762 - auc: 0.7542 - loss: 0.4776 - val_accuracy: 0.7601 - val_auc: 0.8629 - val_loss: 0.4714\n",
      "\n",
      "Starting Epoch 31...\n",
      "Epoch 31/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7747 - auc: 0.7511 - loss: 0.4837 \n",
      "Epoch 31: val_loss did not improve from 0.46259\n",
      "Completed Epoch 31, Loss: 0.4789, Val Loss: 0.4633\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7747 - auc: 0.7511 - loss: 0.4837 - val_accuracy: 0.7706 - val_auc: 0.8625 - val_loss: 0.4633\n",
      "\n",
      "Starting Epoch 32...\n",
      "Epoch 32/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7738 - auc: 0.7536 - loss: 0.4806 \n",
      "Epoch 32: val_loss did not improve from 0.46259\n",
      "Completed Epoch 32, Loss: 0.4802, Val Loss: 0.4765\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 88ms/step - accuracy: 0.7738 - auc: 0.7536 - loss: 0.4806 - val_accuracy: 0.7587 - val_auc: 0.8588 - val_loss: 0.4765\n",
      "\n",
      "Starting Epoch 33...\n",
      "Epoch 33/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7726 - auc: 0.7592 - loss: 0.4811 \n",
      "Epoch 33: val_loss did not improve from 0.46259\n",
      "Completed Epoch 33, Loss: 0.4789, Val Loss: 0.4785\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7726 - auc: 0.7592 - loss: 0.4811 - val_accuracy: 0.7566 - val_auc: 0.8541 - val_loss: 0.4785\n",
      "\n",
      "Starting Epoch 34...\n",
      "Epoch 34/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7796 - auc: 0.7660 - loss: 0.4701 \n",
      "Epoch 34: val_loss did not improve from 0.46259\n",
      "Completed Epoch 34, Loss: 0.4733, Val Loss: 0.4842\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7796 - auc: 0.7660 - loss: 0.4701 - val_accuracy: 0.7492 - val_auc: 0.8741 - val_loss: 0.4842\n",
      "\n",
      "Starting Epoch 35...\n",
      "Epoch 35/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7817 - auc: 0.7639 - loss: 0.4700 \n",
      "Epoch 35: val_loss did not improve from 0.46259\n",
      "Completed Epoch 35, Loss: 0.4736, Val Loss: 0.4739\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7817 - auc: 0.7639 - loss: 0.4700 - val_accuracy: 0.7562 - val_auc: 0.8656 - val_loss: 0.4739\n",
      "\n",
      "Starting Epoch 36...\n",
      "Epoch 36/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7800 - auc: 0.7616 - loss: 0.4731 \n",
      "Epoch 36: val_loss improved from 0.46259 to 0.46252, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 36, Loss: 0.4739, Val Loss: 0.4625\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7800 - auc: 0.7616 - loss: 0.4731 - val_accuracy: 0.7688 - val_auc: 0.8694 - val_loss: 0.4625\n",
      "\n",
      "Starting Epoch 37...\n",
      "Epoch 37/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7788 - auc: 0.7539 - loss: 0.4782 \n",
      "Epoch 37: val_loss improved from 0.46252 to 0.45302, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 37, Loss: 0.4758, Val Loss: 0.4530\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 89ms/step - accuracy: 0.7788 - auc: 0.7539 - loss: 0.4782 - val_accuracy: 0.7716 - val_auc: 0.8887 - val_loss: 0.4530\n",
      "\n",
      "Starting Epoch 38...\n",
      "Epoch 38/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7787 - auc: 0.7545 - loss: 0.4750 \n",
      "Epoch 38: val_loss did not improve from 0.45302\n",
      "Completed Epoch 38, Loss: 0.4743, Val Loss: 0.4593\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7787 - auc: 0.7545 - loss: 0.4750 - val_accuracy: 0.7667 - val_auc: 0.8749 - val_loss: 0.4593\n",
      "\n",
      "Starting Epoch 39...\n",
      "Epoch 39/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7803 - auc: 0.7684 - loss: 0.4696 \n",
      "Epoch 39: val_loss did not improve from 0.45302\n",
      "Completed Epoch 39, Loss: 0.4720, Val Loss: 0.4660\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7803 - auc: 0.7684 - loss: 0.4696 - val_accuracy: 0.7580 - val_auc: 0.8803 - val_loss: 0.4660\n",
      "\n",
      "Starting Epoch 40...\n",
      "Epoch 40/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7799 - auc: 0.7620 - loss: 0.4723 \n",
      "Epoch 40: val_loss did not improve from 0.45302\n",
      "Completed Epoch 40, Loss: 0.4744, Val Loss: 0.4563\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7799 - auc: 0.7620 - loss: 0.4723 - val_accuracy: 0.7699 - val_auc: 0.8707 - val_loss: 0.4563\n",
      "\n",
      "Starting Epoch 41...\n",
      "Epoch 41/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7804 - auc: 0.7672 - loss: 0.4734 \n",
      "Epoch 41: val_loss did not improve from 0.45302\n",
      "Completed Epoch 41, Loss: 0.4721, Val Loss: 0.4653\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7804 - auc: 0.7672 - loss: 0.4734 - val_accuracy: 0.7639 - val_auc: 0.8623 - val_loss: 0.4653\n",
      "\n",
      "Starting Epoch 42...\n",
      "Epoch 42/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7824 - auc: 0.7614 - loss: 0.4701 \n",
      "Epoch 42: val_loss did not improve from 0.45302\n",
      "Completed Epoch 42, Loss: 0.4711, Val Loss: 0.4770\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7824 - auc: 0.7614 - loss: 0.4701 - val_accuracy: 0.7457 - val_auc: 0.8712 - val_loss: 0.4770\n",
      "\n",
      "Starting Epoch 43...\n",
      "Epoch 43/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7828 - auc: 0.7654 - loss: 0.4676 \n",
      "Epoch 43: val_loss improved from 0.45302 to 0.45143, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 43, Loss: 0.4702, Val Loss: 0.4514\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.7828 - auc: 0.7654 - loss: 0.4676 - val_accuracy: 0.7727 - val_auc: 0.8772 - val_loss: 0.4514\n",
      "\n",
      "Starting Epoch 44...\n",
      "Epoch 44/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7824 - auc: 0.7636 - loss: 0.4697 \n",
      "Epoch 44: val_loss did not improve from 0.45143\n",
      "Completed Epoch 44, Loss: 0.4721, Val Loss: 0.4712\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 87ms/step - accuracy: 0.7824 - auc: 0.7636 - loss: 0.4697 - val_accuracy: 0.7548 - val_auc: 0.8734 - val_loss: 0.4712\n",
      "\n",
      "Starting Epoch 45...\n",
      "Epoch 45/45\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7802 - auc: 0.7644 - loss: 0.4712 \n",
      "Epoch 45: val_loss did not improve from 0.45143\n",
      "Completed Epoch 45, Loss: 0.4730, Val Loss: 0.4569\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 87ms/step - accuracy: 0.7802 - auc: 0.7644 - loss: 0.4712 - val_accuracy: 0.7678 - val_auc: 0.8728 - val_loss: 0.4569\n"
     ]
    }
   ],
   "source": [
    "# Define ModelCheckpoint callback\n",
    "checkpoint_filepath = '/home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras'\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Define a callback to print epoch tracking info\n",
    "epoch_callback = LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch, logs: print(f\"\\nStarting Epoch {epoch + 1}...\"),\n",
    "    on_epoch_end=lambda epoch, logs: print(f\"Completed Epoch {epoch + 1}, Loss: {logs['loss']:.4f}, Val Loss: {logs['val_loss']:.4f}\")\n",
    ")\n",
    "\n",
    "# Training loop with added callback\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=45,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[model_checkpoint, epoch_callback]  # Include both callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FiHy6opSP2sQ"
   },
   "outputs": [],
   "source": [
    "model.save_weights('/home/apyba3/car_frozen_classification_mobnetv3small.weights.h5')\n",
    "# model.save_weights('/home/ppytr13/car_frozen.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clear keras session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FpLHyw20P93U"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session() #Clear keras session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENHbUvQdvyFe"
   },
   "source": [
    "### 2d) fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0ek_ytyw0KB"
   },
   "source": [
    "rebuild model after clearing keras session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " MobileNetV3Small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> \n",
       "\n",
       " global_average_pooling2d         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)                                               \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">577</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " MobileNetV3Small (\u001b[38;5;33mFunctional\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m)             \u001b[38;5;34m939,120\u001b[0m \n",
       "\n",
       " global_average_pooling2d         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)                                               \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                         \u001b[38;5;34m577\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">939,697</span> (3.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m939,697\u001b[0m (3.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">927,585</span> (3.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m927,585\u001b[0m (3.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,112</span> (47.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m12,112\u001b[0m (47.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobnetv3small = tf.keras.applications.MobileNetV3Small(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=input_shape\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  mobnetv3small,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dropout(dropoutrate),\n",
    "  tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "mobnetv3small.trainable = True  # UNfreeze mobnetv3small layers\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # deliberately smaller learning rate\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now load in the learned weights from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "8oAenzEiP-C-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('/home/apyba3/car_frozen_classification_mobnetv3small.weights.h5')\n",
    "# model.load_weights('/home/ppytr13/car_frozen.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWDtRxBow89t"
   },
   "source": [
    "Initiate fine-tuning training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Epoch 1...\n",
      "Epoch 1/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - accuracy: 0.8811 - auc: 0.8638 - loss: 1.4939  \n",
      "Epoch 1: val_loss improved from inf to 4.26729, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 1, Loss: 0.6943, Val Loss: 4.2673\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 435ms/step - accuracy: 0.8811 - auc: 0.8639 - loss: 1.4928 - val_accuracy: 0.2455 - val_auc: 0.5288 - val_loss: 4.2673\n",
      "\n",
      "Starting Epoch 2...\n",
      "Epoch 2/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.9601 - auc: 0.9798 - loss: 0.1693  \n",
      "Epoch 2: val_loss improved from 4.26729 to 2.47814, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 2, Loss: 0.1417, Val Loss: 2.4781\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 431ms/step - accuracy: 0.9601 - auc: 0.9798 - loss: 0.1692 - val_accuracy: 0.2459 - val_auc: 0.5861 - val_loss: 2.4781\n",
      "\n",
      "Starting Epoch 3...\n",
      "Epoch 3/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9696 - auc: 0.9926 - loss: 0.0851  \n",
      "Epoch 3: val_loss did not improve from 2.47814\n",
      "Completed Epoch 3, Loss: 0.0857, Val Loss: 3.0127\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9696 - auc: 0.9926 - loss: 0.0851 - val_accuracy: 0.7562 - val_auc: 0.5526 - val_loss: 3.0127\n",
      "\n",
      "Starting Epoch 4...\n",
      "Epoch 4/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9799 - auc: 0.9965 - loss: 0.0550  \n",
      "Epoch 4: val_loss improved from 2.47814 to 0.80931, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 4, Loss: 0.0566, Val Loss: 0.8093\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 431ms/step - accuracy: 0.9799 - auc: 0.9965 - loss: 0.0550 - val_accuracy: 0.7510 - val_auc: 0.6593 - val_loss: 0.8093\n",
      "\n",
      "Starting Epoch 5...\n",
      "Epoch 5/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9869 - auc: 0.9976 - loss: 0.0395  \n",
      "Epoch 5: val_loss did not improve from 0.80931\n",
      "Completed Epoch 5, Loss: 0.0406, Val Loss: 2.4576\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9869 - auc: 0.9976 - loss: 0.0395 - val_accuracy: 0.5366 - val_auc: 0.7188 - val_loss: 2.4576\n",
      "\n",
      "Starting Epoch 6...\n",
      "Epoch 6/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9866 - auc: 0.9972 - loss: 0.0369  \n",
      "Epoch 6: val_loss did not improve from 0.80931\n",
      "Completed Epoch 6, Loss: 0.0388, Val Loss: 7.5126\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9866 - auc: 0.9972 - loss: 0.0369 - val_accuracy: 0.7618 - val_auc: 0.5070 - val_loss: 7.5126\n",
      "\n",
      "Starting Epoch 7...\n",
      "Epoch 7/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9895 - auc: 0.9987 - loss: 0.0267  \n",
      "Epoch 7: val_loss did not improve from 0.80931\n",
      "Completed Epoch 7, Loss: 0.0296, Val Loss: 1.9602\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 430ms/step - accuracy: 0.9895 - auc: 0.9987 - loss: 0.0267 - val_accuracy: 0.7909 - val_auc: 0.7166 - val_loss: 1.9602\n",
      "\n",
      "Starting Epoch 8...\n",
      "Epoch 8/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9909 - auc: 0.9986 - loss: 0.0257  \n",
      "Epoch 8: val_loss improved from 0.80931 to 0.59846, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 8, Loss: 0.0260, Val Loss: 0.5985\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9909 - auc: 0.9986 - loss: 0.0257 - val_accuracy: 0.8722 - val_auc: 0.9108 - val_loss: 0.5985\n",
      "\n",
      "Starting Epoch 9...\n",
      "Epoch 9/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9937 - auc: 0.9992 - loss: 0.0182  \n",
      "Epoch 9: val_loss improved from 0.59846 to 0.40243, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 9, Loss: 0.0219, Val Loss: 0.4024\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9937 - auc: 0.9992 - loss: 0.0182 - val_accuracy: 0.9306 - val_auc: 0.9315 - val_loss: 0.4024\n",
      "\n",
      "Starting Epoch 10...\n",
      "Epoch 10/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9925 - auc: 0.9988 - loss: 0.0220  \n",
      "Epoch 10: val_loss did not improve from 0.40243\n",
      "Completed Epoch 10, Loss: 0.0233, Val Loss: 1.2107\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9925 - auc: 0.9988 - loss: 0.0220 - val_accuracy: 0.7191 - val_auc: 0.7763 - val_loss: 1.2107\n",
      "\n",
      "Starting Epoch 11...\n",
      "Epoch 11/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9939 - auc: 0.9994 - loss: 0.0162  \n",
      "Epoch 11: val_loss did not improve from 0.40243\n",
      "Completed Epoch 11, Loss: 0.0177, Val Loss: 1.6019\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9939 - auc: 0.9994 - loss: 0.0162 - val_accuracy: 0.8294 - val_auc: 0.7638 - val_loss: 1.6019\n",
      "\n",
      "Starting Epoch 12...\n",
      "Epoch 12/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9943 - auc: 0.9993 - loss: 0.0149  \n",
      "Epoch 12: val_loss did not improve from 0.40243\n",
      "Completed Epoch 12, Loss: 0.0131, Val Loss: 0.5371\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9943 - auc: 0.9993 - loss: 0.0149 - val_accuracy: 0.9282 - val_auc: 0.9276 - val_loss: 0.5371\n",
      "\n",
      "Starting Epoch 13...\n",
      "Epoch 13/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9945 - auc: 0.9990 - loss: 0.0164  \n",
      "Epoch 13: val_loss did not improve from 0.40243\n",
      "Completed Epoch 13, Loss: 0.0171, Val Loss: 1.5137\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9945 - auc: 0.9990 - loss: 0.0164 - val_accuracy: 0.7138 - val_auc: 0.5557 - val_loss: 1.5137\n",
      "\n",
      "Starting Epoch 14...\n",
      "Epoch 14/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9953 - auc: 0.9994 - loss: 0.0127  \n",
      "Epoch 14: val_loss did not improve from 0.40243\n",
      "Completed Epoch 14, Loss: 0.0134, Val Loss: 1.2607\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9953 - auc: 0.9994 - loss: 0.0127 - val_accuracy: 0.8802 - val_auc: 0.8340 - val_loss: 1.2607\n",
      "\n",
      "Starting Epoch 15...\n",
      "Epoch 15/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9959 - auc: 0.9992 - loss: 0.0102  \n",
      "Epoch 15: val_loss did not improve from 0.40243\n",
      "Completed Epoch 15, Loss: 0.0120, Val Loss: 0.8182\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9959 - auc: 0.9992 - loss: 0.0102 - val_accuracy: 0.7968 - val_auc: 0.7786 - val_loss: 0.8182\n",
      "\n",
      "Starting Epoch 16...\n",
      "Epoch 16/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9951 - auc: 0.9987 - loss: 0.0150  \n",
      "Epoch 16: val_loss did not improve from 0.40243\n",
      "Completed Epoch 16, Loss: 0.0136, Val Loss: 0.6490\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9951 - auc: 0.9987 - loss: 0.0150 - val_accuracy: 0.8900 - val_auc: 0.8970 - val_loss: 0.6490\n",
      "\n",
      "Starting Epoch 17...\n",
      "Epoch 17/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9956 - auc: 0.9993 - loss: 0.0091       \n",
      "Epoch 17: val_loss improved from 0.40243 to 0.38619, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 17, Loss: 0.0103, Val Loss: 0.3862\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 431ms/step - accuracy: 0.9956 - auc: 0.9993 - loss: 0.0091 - val_accuracy: 0.9229 - val_auc: 0.9459 - val_loss: 0.3862\n",
      "\n",
      "Starting Epoch 18...\n",
      "Epoch 18/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9976 - auc: 0.9996 - loss: 0.0066      \n",
      "Epoch 18: val_loss did not improve from 0.38619\n",
      "Completed Epoch 18, Loss: 0.0090, Val Loss: 0.5164\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9976 - auc: 0.9996 - loss: 0.0067 - val_accuracy: 0.9275 - val_auc: 0.9251 - val_loss: 0.5164\n",
      "\n",
      "Starting Epoch 19...\n",
      "Epoch 19/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9971 - auc: 0.9998 - loss: 0.0081  \n",
      "Epoch 19: val_loss did not improve from 0.38619\n",
      "Completed Epoch 19, Loss: 0.0094, Val Loss: 40.4116\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9971 - auc: 0.9998 - loss: 0.0081 - val_accuracy: 0.2378 - val_auc: 0.4755 - val_loss: 40.4116\n",
      "\n",
      "Starting Epoch 20...\n",
      "Epoch 20/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9971 - auc: 0.9998 - loss: 0.0048  \n",
      "Epoch 20: val_loss did not improve from 0.38619\n",
      "Completed Epoch 20, Loss: -0.0018, Val Loss: 7.1915\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9971 - auc: 0.9998 - loss: 0.0048 - val_accuracy: 0.2294 - val_auc: 0.5123 - val_loss: 7.1915\n",
      "\n",
      "Starting Epoch 21...\n",
      "Epoch 21/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9965 - auc: 0.9998 - loss: 0.0097  \n",
      "Epoch 21: val_loss did not improve from 0.38619\n",
      "Completed Epoch 21, Loss: 0.0082, Val Loss: 0.5847\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9965 - auc: 0.9998 - loss: 0.0097 - val_accuracy: 0.9054 - val_auc: 0.9022 - val_loss: 0.5847\n",
      "\n",
      "Starting Epoch 22...\n",
      "Epoch 22/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9952 - auc: 0.9989 - loss: 0.0247       \n",
      "Epoch 22: val_loss did not improve from 0.38619\n",
      "Completed Epoch 22, Loss: 0.0343, Val Loss: 2.1453\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9952 - auc: 0.9989 - loss: 0.0247 - val_accuracy: 0.8018 - val_auc: 0.7095 - val_loss: 2.1453\n",
      "\n",
      "Starting Epoch 23...\n",
      "Epoch 23/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9975 - auc: 0.9999 - loss: 0.0065  \n",
      "Epoch 23: val_loss improved from 0.38619 to 0.13223, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 23, Loss: 0.0068, Val Loss: 0.1322\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9975 - auc: 0.9999 - loss: 0.0065 - val_accuracy: 0.9713 - val_auc: 0.9789 - val_loss: 0.1322\n",
      "\n",
      "Starting Epoch 24...\n",
      "Epoch 24/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9979 - auc: 0.9996 - loss: 0.0044      \n",
      "Epoch 24: val_loss did not improve from 0.13223\n",
      "Completed Epoch 24, Loss: 0.0053, Val Loss: 0.1820\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9979 - auc: 0.9996 - loss: 0.0044 - val_accuracy: 0.9643 - val_auc: 0.9754 - val_loss: 0.1820\n",
      "\n",
      "Starting Epoch 25...\n",
      "Epoch 25/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9986 - auc: 0.9999 - loss: 0.0025  \n",
      "Epoch 25: val_loss improved from 0.13223 to 0.04328, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 25, Loss: 0.0009, Val Loss: 0.0433\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9986 - auc: 0.9999 - loss: 0.0025 - val_accuracy: 0.9874 - val_auc: 0.9954 - val_loss: 0.0433\n",
      "\n",
      "Starting Epoch 26...\n",
      "Epoch 26/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9969 - auc: 0.9997 - loss: 0.0035  \n",
      "Epoch 26: val_loss did not improve from 0.04328\n",
      "Completed Epoch 26, Loss: 0.0069, Val Loss: 0.8471\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9969 - auc: 0.9997 - loss: 0.0035 - val_accuracy: 0.8588 - val_auc: 0.8604 - val_loss: 0.8471\n",
      "\n",
      "Starting Epoch 27...\n",
      "Epoch 27/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9984 - auc: 0.9999 - loss: -0.0016     \n",
      "Epoch 27: val_loss did not improve from 0.04328\n",
      "Completed Epoch 27, Loss: -0.0265, Val Loss: 0.2404\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9984 - auc: 0.9999 - loss: -0.0017 - val_accuracy: 0.9363 - val_auc: 0.9655 - val_loss: 0.2404\n",
      "\n",
      "Starting Epoch 28...\n",
      "Epoch 28/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9964 - auc: 0.9998 - loss: -0.0059     \n",
      "Epoch 28: val_loss did not improve from 0.04328\n",
      "Completed Epoch 28, Loss: -0.0834, Val Loss: 0.9364\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9964 - auc: 0.9998 - loss: -0.0060 - val_accuracy: 0.8109 - val_auc: 0.8263 - val_loss: 0.9364\n",
      "\n",
      "Starting Epoch 29...\n",
      "Epoch 29/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9906 - auc: 0.9977 - loss: -0.3116  \n",
      "Epoch 29: val_loss did not improve from 0.04328\n",
      "Completed Epoch 29, Loss: -0.0647, Val Loss: 0.2320\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9906 - auc: 0.9977 - loss: -0.3112 - val_accuracy: 0.9762 - val_auc: 0.9795 - val_loss: 0.2320\n",
      "\n",
      "Starting Epoch 30...\n",
      "Epoch 30/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9980 - auc: 0.9997 - loss: -0.0182      \n",
      "Epoch 30: val_loss did not improve from 0.04328\n",
      "Completed Epoch 30, Loss: -0.0500, Val Loss: 1.1723\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9980 - auc: 0.9997 - loss: -0.0182 - val_accuracy: 0.6953 - val_auc: 0.7438 - val_loss: 1.1723\n",
      "\n",
      "Starting Epoch 31...\n",
      "Epoch 31/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9957 - auc: 0.9989 - loss: -0.1872      \n",
      "Epoch 31: val_loss did not improve from 0.04328\n",
      "Completed Epoch 31, Loss: -0.1766, Val Loss: 1.9273\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9957 - auc: 0.9989 - loss: -0.1872 - val_accuracy: 0.8452 - val_auc: 0.7814 - val_loss: 1.9273\n",
      "\n",
      "Starting Epoch 32...\n",
      "Epoch 32/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9978 - auc: 0.9999 - loss: -0.0068     \n",
      "Epoch 32: val_loss did not improve from 0.04328\n",
      "Completed Epoch 32, Loss: -0.1089, Val Loss: 0.0945\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9978 - auc: 0.9999 - loss: -0.0070 - val_accuracy: 0.9769 - val_auc: 0.9892 - val_loss: 0.0945\n",
      "\n",
      "Starting Epoch 33...\n",
      "Epoch 33/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9973 - auc: 0.9998 - loss: -1.3343e-04\n",
      "Epoch 33: val_loss did not improve from 0.04328\n",
      "Completed Epoch 33, Loss: -0.2302, Val Loss: 2.1854\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9973 - auc: 0.9998 - loss: -4.5514e-04 - val_accuracy: 0.8946 - val_auc: 0.8579 - val_loss: 2.1854\n",
      "\n",
      "Starting Epoch 34...\n",
      "Epoch 34/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9953 - auc: 0.9993 - loss: -0.1793      \n",
      "Epoch 34: val_loss did not improve from 0.04328\n",
      "Completed Epoch 34, Loss: -0.2358, Val Loss: 3.8558\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - accuracy: 0.9953 - auc: 0.9993 - loss: -0.1794 - val_accuracy: 0.8914 - val_auc: 0.8258 - val_loss: 3.8558\n",
      "\n",
      "Starting Epoch 35...\n",
      "Epoch 35/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9967 - auc: 0.9996 - loss: -0.5885  \n",
      "Epoch 35: val_loss did not improve from 0.04328\n",
      "Completed Epoch 35, Loss: -0.1810, Val Loss: 0.3616\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9967 - auc: 0.9996 - loss: -0.5880 - val_accuracy: 0.9268 - val_auc: 0.9490 - val_loss: 0.3616\n",
      "\n",
      "Starting Epoch 36...\n",
      "Epoch 36/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9959 - auc: 0.9996 - loss: -0.0151     \n",
      "Epoch 36: val_loss did not improve from 0.04328\n",
      "Completed Epoch 36, Loss: -0.0689, Val Loss: 0.2879\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9959 - auc: 0.9996 - loss: -0.0152 - val_accuracy: 0.9331 - val_auc: 0.9594 - val_loss: 0.2879\n",
      "\n",
      "Starting Epoch 37...\n",
      "Epoch 37/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.9971 - auc: 0.9998 - loss: -0.1316      \n",
      "Epoch 37: val_loss did not improve from 0.04328\n",
      "Completed Epoch 37, Loss: -0.3001, Val Loss: 0.1031\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 431ms/step - accuracy: 0.9971 - auc: 0.9998 - loss: -0.1318 - val_accuracy: 0.9797 - val_auc: 0.9905 - val_loss: 0.1031\n",
      "\n",
      "Starting Epoch 38...\n",
      "Epoch 38/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.9974 - auc: 0.9996 - loss: -0.4719  \n",
      "Epoch 38: val_loss did not improve from 0.04328\n",
      "Completed Epoch 38, Loss: -0.3166, Val Loss: 0.0737\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - accuracy: 0.9974 - auc: 0.9996 - loss: -0.4717 - val_accuracy: 0.9877 - val_auc: 0.9940 - val_loss: 0.0737\n",
      "\n",
      "Starting Epoch 39...\n",
      "Epoch 39/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 0.9979 - auc: 0.9999 - loss: -0.0460      \n",
      "Epoch 39: val_loss improved from 0.04328 to 0.00723, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 39, Loss: -0.1596, Val Loss: 0.0072\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 437ms/step - accuracy: 0.9979 - auc: 0.9999 - loss: -0.0461 - val_accuracy: 0.9982 - val_auc: 1.0000 - val_loss: 0.0072\n",
      "\n",
      "Starting Epoch 40...\n",
      "Epoch 40/50\n",
      "\u001b[1m145/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4:02\u001b[0m 426ms/step - accuracy: 0.9963 - auc: 0.9995 - loss: -0.5429"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m epoch_callback \u001b[38;5;241m=\u001b[39m LambdaCallback(\n\u001b[1;32m     14\u001b[0m     on_epoch_begin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m epoch, logs: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     15\u001b[0m     on_epoch_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m epoch, logs: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Training loop with added callback\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Include both callbacks\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define ModelCheckpoint callback\n",
    "checkpoint_filepath = '/home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras'\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Define a callback to print epoch tracking info\n",
    "epoch_callback = LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch, logs: print(f\"\\nStarting Epoch {epoch + 1}...\"),\n",
    "    on_epoch_end=lambda epoch, logs: print(f\"Completed Epoch {epoch + 1}, Loss: {logs['loss']:.4f}, Val Loss: {logs['val_loss']:.4f}\")\n",
    ")\n",
    "\n",
    "# Training loop with added callback\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[model_checkpoint, epoch_callback]  # Include both callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the weights learned from fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "O14u6175RLjA"
   },
   "outputs": [],
   "source": [
    "model.save_weights('car_unfrozen_classification_mobnetv3small.weights.h5')\n",
    "# model.save_weights('/home/ppytr13/car_unfrozen.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCbo4VcLxLgQ"
   },
   "source": [
    "# 3) CLASSIFICATION SPEED Test-Set Predictions\n",
    "\n",
    "a) load in test data\n",
    "\n",
    "b) convert test images to numerical RGB feature maps\n",
    "\n",
    "c) generate predictions on the test set\n",
    "\n",
    "d) correctly format the predictions into a pandas dataframe\n",
    "\n",
    "e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnygDJsKxYhA"
   },
   "source": [
    "### 3a) load in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "W-e59lQQRXKK",
    "outputId": "aa8566ec-e472-47a6-c7a0-92266b567a62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/5.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              image_file_paths\n",
       "image_id                                                                                      \n",
       "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/1.png\n",
       "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/2.png\n",
       "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/3.png\n",
       "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/4.png\n",
       "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/5.png"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data'\n",
    "# image_folder_path = '/home/ppyt13/machine-learning-in-science-ii-2025/test_data/test_data' # tylers file path\n",
    "image_file_paths = [\n",
    "    os.path.join(image_folder_path, f)\n",
    "    for f in os.listdir(image_folder_path)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "]\n",
    "\n",
    "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
    "\n",
    "imagefilepaths_df = pd.DataFrame(\n",
    "    image_file_paths,\n",
    "    columns=['image_file_paths'],\n",
    "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
    ")\n",
    "\n",
    "imagefilepaths_df.index.name = 'image_id'\n",
    "imagefilepaths_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-9i5trTyDTf"
   },
   "source": [
    "### 3b) convert test images to numerical RGB feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "3hT_c1s5TAR-"
   },
   "outputs": [],
   "source": [
    "def process_image_no_label(image_path, resized_shape=(224, 224)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
    "    image = tf.image.resize(image, resized_shape)  # Resize to uniform shape\n",
    "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
    "    return image\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((imagefilepaths_df[\"image_file_paths\"]))\n",
    "\n",
    "test_dataset = test_dataset.map(process_image_no_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gobnK7PhyLa2"
   },
   "source": [
    "### 3c) generate predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtqcOFr7TAXa",
    "outputId": "73b4c96b-51bf-4e1c-e1b6-e8cde1321984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT1LJxHTPeQT"
   },
   "source": [
    "### 3d) correctly format the predictions into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "pFVWGi04fza7"
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions, columns=['speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "OnO0K1rReHOT",
    "outputId": "d9cebb2e-3d36-4c7a-b024-eabb646e3bbb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.370914e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.998439e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          speed\n",
       "0  1.370914e-25\n",
       "1  1.000000e+00\n",
       "2  9.999998e-01\n",
       "3  1.000000e+00\n",
       "4  9.998439e-01"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df[predictions_df['speed'] > 0.5] = 1\n",
    "predictions_df[predictions_df['speed'] < 0.5] = 0\n",
    "\n",
    "predictions_df['speed'] = predictions_df['speed'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speed\n",
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CcRKL9KTAfs",
    "outputId": "277533cd-06aa-4709-d44e-9027cc7e9438"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speed\n",
       "1    516\n",
       "0    504\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['speed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oU-PhskZPaHD"
   },
   "source": [
    "### 3e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "deXjPTO0TAiL"
   },
   "outputs": [],
   "source": [
    "predictions_df.to_csv('/home/apyba3/mobnetv3small_speedclassification_withvalidation_withpetrudata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
