{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fhwRSFoj6C_"
   },
   "source": [
    "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4V83PflfFkL"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kP6UczzNe1l2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 13:14:33.458594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-28 13:14:33.544352: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-28 13:14:33.596300: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-28 13:14:34.286817: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O24_U-m8q-xv",
    "outputId": "f2298893-2e7e-4b8f-cc38-0caeb1a6a670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.system())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IF_vPVifaU9V"
   },
   "outputs": [],
   "source": [
    "# makes it so pd dfs aren't truncated\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eocC68amnhEI"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_MvRvYnfIM5"
   },
   "source": [
    "# 1) DATA PRE-PROCESSING\n",
    "\n",
    "a) Load in kaggle data labels + image file paths\n",
    "\n",
    "b) combine kaggle data labels and image file paths into one dataframe\n",
    "\n",
    "c) load in the extra 486 image file paths\n",
    "\n",
    "d) extract the speed and angle labels from the file path names\n",
    "\n",
    "e) store that extra data in a pandas df and do the value normalisation\n",
    "\n",
    "f) merge the kaggle and extra data dfs\n",
    "\n",
    "g) EDA\n",
    "\n",
    "h) convert the images to numerical RGB feature maps\n",
    "\n",
    "i) split data into training-validation sets\n",
    "\n",
    "j) data augmentation applied to training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU3TvBZ5hfhX"
   },
   "source": [
    "### 1a) load in kaggle data labels + image file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZiNf_BxOfEH-"
   },
   "outputs": [],
   "source": [
    "# labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # tylers file path\n",
    "labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
    "# labels_file_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_norm.csv' # tyler hpc file path (mlis2 cluster)\n",
    "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nOXmN--gb-Q9"
   },
   "outputs": [],
   "source": [
    "image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data' # OG data ben hpc file path (mlis2 cluster)\n",
    "# image_folder_path = '/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data'\n",
    "# image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
    "image_file_paths = [\n",
    "    os.path.join(image_folder_path, f)\n",
    "    for f in os.listdir(image_folder_path)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "]\n",
    "\n",
    "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
    "\n",
    "imagefilepaths_df = pd.DataFrame(\n",
    "    image_file_paths,\n",
    "    columns=['image_file_paths'],\n",
    "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
    ")\n",
    "\n",
    "imagefilepaths_df.index.name = 'image_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oeuvmeZaGSC"
   },
   "source": [
    "Checking labels dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pi13TZ2aFhO",
    "outputId": "fc675bb2-271b-48fd-a6c3-43834afb4500"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           angle  speed\n",
       "image_id               \n",
       "1         0.4375    0.0\n",
       "2         0.8125    1.0\n",
       "3         0.4375    1.0\n",
       "4         0.6250    1.0\n",
       "5         0.5000    0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puEjGoOJaRS4"
   },
   "source": [
    "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1suFSK7aWKH",
    "outputId": "c3cc2d29-d759-48ff-b92c-77dbd178f295"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/5.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      image_file_paths\n",
       "image_id                                                                                              \n",
       "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png\n",
       "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png\n",
       "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png\n",
       "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/4.png\n",
       "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/5.png"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagefilepaths_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjDdyYd6cMBE"
   },
   "source": [
    "### 1b) Combine the kaggle labels and image file paths into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6NdbonzPcLKB"
   },
   "outputs": [],
   "source": [
    "kaggle_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
    "kaggle_df['speed'] = kaggle_df['speed'].round(6) # to get rid of floating point errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VstirIAdAZi",
    "outputId": "c03ff707-9e8d-4c3a-8965-f795919ace21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13794</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13794.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13795</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13795.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13796</th>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13796.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13798</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           angle  speed  \\\n",
       "image_id                  \n",
       "13794     0.6250    1.0   \n",
       "13795     0.4375    1.0   \n",
       "13796     0.5625    0.0   \n",
       "13797     0.6250    0.0   \n",
       "13798     0.6875    1.0   \n",
       "\n",
       "                                                                                          image_file_paths  \n",
       "image_id                                                                                                    \n",
       "13794     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13794.png  \n",
       "13795     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13795.png  \n",
       "13796     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13796.png  \n",
       "13797     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png  \n",
       "13798     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MgNoL8nfBm2",
    "outputId": "924e7562-25a4-4223-8305-c3fd02452846"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3139.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3140.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3142.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3143.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          angle  speed  \\\n",
       "image_id                 \n",
       "3139      0.750    1.0   \n",
       "3140      0.875    1.0   \n",
       "3142      0.625    0.0   \n",
       "3143      0.625    1.0   \n",
       "\n",
       "                                                                                         image_file_paths  \n",
       "image_id                                                                                                   \n",
       "3139      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3139.png  \n",
       "3140      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3140.png  \n",
       "3142      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3142.png  \n",
       "3143      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3143.png  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_df.loc[3139:3143]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7PCxqJbmXE6"
   },
   "source": [
    "The above cell shows that:\n",
    "\n",
    " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
    "\n",
    " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOEWqBUYX6DL"
   },
   "source": [
    "### 1c) load in the extra 486 labels image file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wvsDiCCLOvvs"
   },
   "outputs": [],
   "source": [
    "extradata_folder_path = '/home/apyba3/petru_data'\n",
    "\n",
    "extradata_file_paths = [\n",
    "    os.path.join(extradata_folder_path, f)\n",
    "    for f in os.listdir(extradata_folder_path)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4ofcGILO4et"
   },
   "source": [
    "### 1d) extract the speed and angle labels from the file path names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFsEI4MBRf2l"
   },
   "source": [
    "image file path name follows the pattern: `randomnumber_angle_speed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mY5-HDp-PJY9"
   },
   "outputs": [],
   "source": [
    "# Regex pattern to extract angle and speed values\n",
    "pattern = r'(\\d+)_([\\d]+)_([\\d]+)\\.png'\n",
    "\n",
    "angle_value = []\n",
    "speed_value = []\n",
    "\n",
    "# Loop through file paths and extract angle and speed values\n",
    "for file_path in extradata_file_paths:\n",
    "    match = re.search(pattern, file_path)\n",
    "    if match:\n",
    "        # Extract random number, angle, and speed values\n",
    "        random_number = match.group(1)\n",
    "        angle_value.append(int(match.group(2)))\n",
    "        speed_value.append(int(match.group(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4F8qIQJ8Y3t8"
   },
   "source": [
    "checking it has stored the labels correctly (check if the angle_value order matches that of the file path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mf1bChw_OvsT",
    "outputId": "bdf648d9-3ab3-403e-c977-0c938ae1bf18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 100, 80]\n",
      "['/home/apyba3/petru_data/1712918428740_95_0.png', '/home/apyba3/petru_data/1712923220525_100_50.png', '/home/apyba3/petru_data/1712923068961_80_35.png']\n"
     ]
    }
   ],
   "source": [
    "print(angle_value[:3])\n",
    "print(extradata_file_paths[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyvljUTBZP0E"
   },
   "source": [
    "### 1e) store that extra data in a pandas df and do the value normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tse95lu1OvnY",
    "outputId": "90ed60a7-5f9c-4901-f7ed-7442d739ccfb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13799</th>\n",
       "      <td>0.5625</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/apyba3/petru_data/1712918428740_95_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13800</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/apyba3/petru_data/1712923220525_100_50.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13801</th>\n",
       "      <td>0.3750</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/apyba3/petru_data/1712923068961_80_35.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13802</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/apyba3/petru_data/1712921566265_105_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13803</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/apyba3/petru_data/1712915924250_70_35.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           angle  speed                                  image_file_paths\n",
       "image_id                                                                 \n",
       "13799     0.5625      0    /home/apyba3/petru_data/1712918428740_95_0.png\n",
       "13800     0.6250      1  /home/apyba3/petru_data/1712923220525_100_50.png\n",
       "13801     0.3750      1   /home/apyba3/petru_data/1712923068961_80_35.png\n",
       "13802     0.6875      0   /home/apyba3/petru_data/1712921566265_105_0.png\n",
       "13803     0.2500      1   /home/apyba3/petru_data/1712915924250_70_35.png"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extradata_df = pd.DataFrame({\n",
    "    'angle': angle_value,\n",
    "    'speed': speed_value,\n",
    "    'image_file_paths': extradata_file_paths\n",
    "})\n",
    "\n",
    "# conversions (see kaggle data section)\n",
    "extradata_df.loc[extradata_df['speed'] > 0, 'speed'] = 1\n",
    "extradata_df['speed'] = pd.to_numeric(extradata_df['speed'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "extradata_df['angle'] = (extradata_df['angle'] - 50)/80\n",
    "\n",
    "extradata_df.index = pd.RangeIndex(start=13799, stop=13799 + len(extradata_df), step=1)\n",
    "extradata_df.index.name = 'image_id'\n",
    "\n",
    "extradata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qv0MwDKsbOef"
   },
   "source": [
    "### 1f) merge the kaggle and extra data dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZMZPUn4b3Kc",
    "outputId": "86bd34db-0b48-442e-b5b2-5ff322d0764b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13798</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13799</th>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/apyba3/petru_data/1712918428740_95_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13800</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/home/apyba3/petru_data/1712923220525_100_50.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           angle  speed  \\\n",
       "image_id                  \n",
       "13797     0.6250    0.0   \n",
       "13798     0.6875    1.0   \n",
       "13799     0.5625    0.0   \n",
       "13800     0.6250    1.0   \n",
       "\n",
       "                                                                                          image_file_paths  \n",
       "image_id                                                                                                    \n",
       "13797     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png  \n",
       "13798     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png  \n",
       "13799                                                       /home/apyba3/petru_data/1712918428740_95_0.png  \n",
       "13800                                                     /home/apyba3/petru_data/1712923220525_100_50.png  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([kaggle_df, extradata_df])\n",
    "merged_df.loc[13797:13800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3OKLcn9u0Pz"
   },
   "source": [
    "### 1g) EDA - angle column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWQCQrR-oCps",
    "outputId": "88bb4558-2c8a-482b-de5d-8f7876ed9bc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angle\n",
       "0.5000    2172\n",
       "0.7500    2172\n",
       "0.6875    2049\n",
       "0.6250    2000\n",
       "0.5625    1644\n",
       "0.4375    1520\n",
       "0.8125    1162\n",
       "0.3750     447\n",
       "0.8750     308\n",
       "0.3125     229\n",
       "0.1875     119\n",
       "0.2500     118\n",
       "0.1250     114\n",
       "0.0000      75\n",
       "0.9375      74\n",
       "0.0625      38\n",
       "1.0000      38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.value_counts('angle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4pZ65pYvdqb"
   },
   "source": [
    "note: imbalance datset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMZq41-RkLz0"
   },
   "source": [
    "we want to remove the row containing the erroneous 1.428571 speed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TDMqIiOLSKGX"
   },
   "outputs": [],
   "source": [
    "cleaned_df = merged_df[merged_df['angle'] != 1.428571]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Di6F6km_DBmj"
   },
   "source": [
    "### 1h) convert images to numerical RGB feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oeeBTruNCQ96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 13:15:01.541763: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "def process_image(image_path, label, resized_shape=(224, 224)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, resized_shape)\n",
    "    image = image / 255.0  # Normalise pixel values to [0,1]\n",
    "    return image, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"angle\"])) # Convert pd df into a tf ds\n",
    "\n",
    "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(len(cleaned_df))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUOlsWQeVlyC"
   },
   "source": [
    "lets check and see if what we have done works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBTNjNhMVk2g",
    "outputId": "b00f1443-c179-43a2-e6fd-7cc90ff698f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 13:15:12.152346: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 2726 of 14279\n",
      "2025-03-28 13:15:32.136063: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 9891 of 14279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3) (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 13:15:45.336259: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
      "2025-03-28 13:15:45.354225: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for images, labels in dataset.take(1):\n",
    "    print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Md6U_i84SiK5"
   },
   "source": [
    "### 1i) Splitting data into training and validation sets (test set is already provided in kaggle data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yYlssPh5dxaO"
   },
   "outputs": [],
   "source": [
    "# 80-20 split\n",
    "\n",
    "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "train_size = int(0.8 * dataset_size)\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPUE6rd8cgQN",
    "outputId": "a418b177-e08d-481c-d272-b9b7494882d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 357, validation size: 90\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {train_size}, validation size: {dataset_size - train_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ujsjhMPSw4f"
   },
   "source": [
    "### 1j) Data Augmentation applied to training set\n",
    "\n",
    "- Random Brightness Adjustment\n",
    "- Random Contrast Adjustment\n",
    "- Random Hue Adjustment\n",
    "- Random Saturation Adjustment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9r811eWsYfe"
   },
   "outputs": [],
   "source": [
    "def augment_image(image, label):\n",
    "  seed = (6, 9)\n",
    "  image = tf.image.stateless_random_brightness(image, 0.2, seed)\n",
    "  image = tf.image.stateless_random_contrast(image, 0.8, 1.2, seed)\n",
    "  image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
    "  image = tf.image.stateless_random_saturation(image, 0.8, 1.2, seed)\n",
    "  return image, label\n",
    "\n",
    "# Create a dataset of augmented images from the original train_dataset\n",
    "augmented_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Concatenate the original and augmented datasets\n",
    "train_dataset = train_dataset.concatenate(augmented_dataset)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(cleaned_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOqizFg7rvKq"
   },
   "source": [
    "count how many images are in the training set - 22016 with no extradata and 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjlyfjAxLsrC",
    "outputId": "14dc79ee-e1b4-4c37-bfb1-b6525bc586c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 13:15:51.762481: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in train_dataset: 22848\n"
     ]
    }
   ],
   "source": [
    "total_images = 0\n",
    "for image_batch, _ in train_dataset:\n",
    "    total_images += image_batch.shape[0]  # Add the batch size\n",
    "\n",
    "print(f\"Total number of images in train_dataset: {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEdi-dUCTND1"
   },
   "source": [
    "checking to see if whats been done was successful or needs debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OeboVhsQKGFS",
    "outputId": "b9c6bb08-d7ce-4951-b621-6775a6ee3bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (224, 224, 3)\n",
      "label: 0.5\n",
      "image shape:  (224, 224, 3)\n",
      "label: 0.5625\n",
      "image shape:  (224, 224, 3)\n",
      "label: 0.4375\n",
      "image shape:  (224, 224, 3)\n",
      "label: 0.5625\n",
      "image shape:  (224, 224, 3)\n",
      "label: 0.75\n",
      "image shape:  (224, 224, 3)\n",
      "label: 0.625\n",
      "image shape:  (224, 224, 3)\n",
      "label: 0.625\n",
      "image shape:  (224, 224, 3)\n",
      "label: 0.625\n",
      "image shape:  (224, 224, 3)\n",
      "label: 0.8125\n",
      "image shape:  (224, 224, 3)\n",
      "label: 0.1875\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1,10)\n",
    "\n",
    "i = 0\n",
    "for image_batch, label_batch in train_dataset.take(1):  # Take one batch\n",
    "    for image in image_batch:  # Iterate through images in the batch\n",
    "        if i < 10:  # Only display the first 5 images\n",
    "            print('image shape: ', np.shape(image))\n",
    "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
    "            axarr[i].imshow(image)\n",
    "            axarr[i].axis('off')\n",
    "            i += 1\n",
    "        else:\n",
    "            break  # Stop after displaying 5 images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmetmzNHTWzU"
   },
   "source": [
    "# 2) Model Building -  Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48RHLVshdX5L"
   },
   "source": [
    "### 2a) Set up model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aHjqXG1jSnCr"
   },
   "outputs": [],
   "source": [
    "dropoutrate = 0.2\n",
    "input_shape = (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "id": "ZPso3wBuN9L3",
    "outputId": "ef11a9ff-7117-4836-dd78-9bcadac15995"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " MobileNetV3Small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> \n",
       "\n",
       " global_average_pooling2d         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)                                               \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">147,712</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> \n",
       "\n",
       " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \n",
       "\n",
       " dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> \n",
       "\n",
       " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " MobileNetV3Small (\u001b[38;5;33mFunctional\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m)             \u001b[38;5;34m939,120\u001b[0m \n",
       "\n",
       " global_average_pooling2d         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)                                               \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   \u001b[38;5;34m147,712\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m32,896\u001b[0m \n",
       "\n",
       " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                      \u001b[38;5;34m8,256\u001b[0m \n",
       "\n",
       " dropout_3 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      \u001b[38;5;34m2,080\u001b[0m \n",
       "\n",
       " dense_4 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m33\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,130,097</span> (4.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,130,097\u001b[0m (4.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,977</span> (746.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m190,977\u001b[0m (746.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> (3.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m939,120\u001b[0m (3.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobnetv3small = tf.keras.applications.MobileNetV3Small(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = input_shape\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  mobnetv3small,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dropout(dropoutrate),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dropout(dropoutrate),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(dropoutrate),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dropout(dropoutrate),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "mobnetv3small.trainable = False  # freeze mobnetv3small layers\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Ca0JFQuuN8oI"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) train the model with the mobnetv3small layers frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WPTNOtr7WjLS",
    "outputId": "63cf5fac-6100-43db-dadd-47da686c9712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Epoch 1...\n",
      "Epoch 1/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0583 \n",
      "Epoch 1: val_loss improved from inf to 0.03172, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 1, Loss: 0.0335, Val Loss: 0.0317\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 90ms/step - loss: 0.0583 - val_loss: 0.0317\n",
      "\n",
      "Starting Epoch 2...\n",
      "Epoch 2/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0200 \n",
      "Epoch 2: val_loss improved from 0.03172 to 0.02856, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 2, Loss: 0.0199, Val Loss: 0.0286\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 89ms/step - loss: 0.0200 - val_loss: 0.0286\n",
      "\n",
      "Starting Epoch 3...\n",
      "Epoch 3/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0189 \n",
      "Epoch 3: val_loss improved from 0.02856 to 0.02240, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 3, Loss: 0.0185, Val Loss: 0.0224\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 88ms/step - loss: 0.0189 - val_loss: 0.0224\n",
      "\n",
      "Starting Epoch 4...\n",
      "Epoch 4/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0176 \n",
      "Epoch 4: val_loss improved from 0.02240 to 0.01765, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 4, Loss: 0.0175, Val Loss: 0.0176\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0176 - val_loss: 0.0176\n",
      "\n",
      "Starting Epoch 5...\n",
      "Epoch 5/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0167 \n",
      "Epoch 5: val_loss improved from 0.01765 to 0.01667, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 5, Loss: 0.0169, Val Loss: 0.0167\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 89ms/step - loss: 0.0167 - val_loss: 0.0167\n",
      "\n",
      "Starting Epoch 6...\n",
      "Epoch 6/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0170 \n",
      "Epoch 6: val_loss improved from 0.01667 to 0.01337, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 6, Loss: 0.0167, Val Loss: 0.0134\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 89ms/step - loss: 0.0170 - val_loss: 0.0134\n",
      "\n",
      "Starting Epoch 7...\n",
      "Epoch 7/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0164 \n",
      "Epoch 7: val_loss did not improve from 0.01337\n",
      "Completed Epoch 7, Loss: 0.0160, Val Loss: 0.0139\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0164 - val_loss: 0.0139\n",
      "\n",
      "Starting Epoch 8...\n",
      "Epoch 8/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0155 \n",
      "Epoch 8: val_loss did not improve from 0.01337\n",
      "Completed Epoch 8, Loss: 0.0158, Val Loss: 0.0152\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0155 - val_loss: 0.0152\n",
      "\n",
      "Starting Epoch 9...\n",
      "Epoch 9/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0160 \n",
      "Epoch 9: val_loss did not improve from 0.01337\n",
      "Completed Epoch 9, Loss: 0.0159, Val Loss: 0.0150\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "\n",
      "Starting Epoch 10...\n",
      "Epoch 10/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0151 \n",
      "Epoch 10: val_loss improved from 0.01337 to 0.01286, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 10, Loss: 0.0157, Val Loss: 0.0129\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0151 - val_loss: 0.0129\n",
      "\n",
      "Starting Epoch 11...\n",
      "Epoch 11/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0160 \n",
      "Epoch 11: val_loss did not improve from 0.01286\n",
      "Completed Epoch 11, Loss: 0.0158, Val Loss: 0.0148\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0160 - val_loss: 0.0148\n",
      "\n",
      "Starting Epoch 12...\n",
      "Epoch 12/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0162 \n",
      "Epoch 12: val_loss did not improve from 0.01286\n",
      "Completed Epoch 12, Loss: 0.0162, Val Loss: 0.0145\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0162 - val_loss: 0.0145\n",
      "\n",
      "Starting Epoch 13...\n",
      "Epoch 13/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0162 \n",
      "Epoch 13: val_loss did not improve from 0.01286\n",
      "Completed Epoch 13, Loss: 0.0158, Val Loss: 0.0132\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "\n",
      "Starting Epoch 14...\n",
      "Epoch 14/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0154 \n",
      "Epoch 14: val_loss did not improve from 0.01286\n",
      "Completed Epoch 14, Loss: 0.0152, Val Loss: 0.0146\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0154 - val_loss: 0.0146\n",
      "\n",
      "Starting Epoch 15...\n",
      "Epoch 15/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0156 \n",
      "Epoch 15: val_loss did not improve from 0.01286\n",
      "Completed Epoch 15, Loss: 0.0155, Val Loss: 0.0136\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0156 - val_loss: 0.0136\n",
      "\n",
      "Starting Epoch 16...\n",
      "Epoch 16/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0154 \n",
      "Epoch 16: val_loss did not improve from 0.01286\n",
      "Completed Epoch 16, Loss: 0.0155, Val Loss: 0.0141\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0154 - val_loss: 0.0141\n",
      "\n",
      "Starting Epoch 17...\n",
      "Epoch 17/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0152 \n",
      "Epoch 17: val_loss did not improve from 0.01286\n",
      "Completed Epoch 17, Loss: 0.0152, Val Loss: 0.0132\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0152 - val_loss: 0.0132\n",
      "\n",
      "Starting Epoch 18...\n",
      "Epoch 18/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0150 \n",
      "Epoch 18: val_loss did not improve from 0.01286\n",
      "Completed Epoch 18, Loss: 0.0151, Val Loss: 0.0133\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0150 - val_loss: 0.0133\n",
      "\n",
      "Starting Epoch 19...\n",
      "Epoch 19/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0150 \n",
      "Epoch 19: val_loss did not improve from 0.01286\n",
      "Completed Epoch 19, Loss: 0.0151, Val Loss: 0.0137\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0150 - val_loss: 0.0137\n",
      "\n",
      "Starting Epoch 20...\n",
      "Epoch 20/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0153 \n",
      "Epoch 20: val_loss did not improve from 0.01286\n",
      "Completed Epoch 20, Loss: 0.0155, Val Loss: 0.0144\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "\n",
      "Starting Epoch 21...\n",
      "Epoch 21/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0154 \n",
      "Epoch 21: val_loss did not improve from 0.01286\n",
      "Completed Epoch 21, Loss: 0.0154, Val Loss: 0.0139\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0154 - val_loss: 0.0139\n",
      "\n",
      "Starting Epoch 22...\n",
      "Epoch 22/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0155 \n",
      "Epoch 22: val_loss did not improve from 0.01286\n",
      "Completed Epoch 22, Loss: 0.0152, Val Loss: 0.0130\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0155 - val_loss: 0.0130\n",
      "\n",
      "Starting Epoch 23...\n",
      "Epoch 23/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0145 \n",
      "Epoch 23: val_loss did not improve from 0.01286\n",
      "Completed Epoch 23, Loss: 0.0150, Val Loss: 0.0136\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0145 - val_loss: 0.0136\n",
      "\n",
      "Starting Epoch 24...\n",
      "Epoch 24/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0150 \n",
      "Epoch 24: val_loss did not improve from 0.01286\n",
      "Completed Epoch 24, Loss: 0.0152, Val Loss: 0.0136\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0150 - val_loss: 0.0136\n",
      "\n",
      "Starting Epoch 25...\n",
      "Epoch 25/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0153 \n",
      "Epoch 25: val_loss did not improve from 0.01286\n",
      "Completed Epoch 25, Loss: 0.0153, Val Loss: 0.0136\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0153 - val_loss: 0.0136\n",
      "\n",
      "Starting Epoch 26...\n",
      "Epoch 26/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0150 \n",
      "Epoch 26: val_loss improved from 0.01286 to 0.01167, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 26, Loss: 0.0152, Val Loss: 0.0117\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "\n",
      "Starting Epoch 27...\n",
      "Epoch 27/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0156 \n",
      "Epoch 27: val_loss did not improve from 0.01167\n",
      "Completed Epoch 27, Loss: 0.0151, Val Loss: 0.0139\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0156 - val_loss: 0.0139\n",
      "\n",
      "Starting Epoch 28...\n",
      "Epoch 28/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0144 \n",
      "Epoch 28: val_loss did not improve from 0.01167\n",
      "Completed Epoch 28, Loss: 0.0148, Val Loss: 0.0133\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0144 - val_loss: 0.0133\n",
      "\n",
      "Starting Epoch 29...\n",
      "Epoch 29/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0150 \n",
      "Epoch 29: val_loss did not improve from 0.01167\n",
      "Completed Epoch 29, Loss: 0.0148, Val Loss: 0.0140\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0150 - val_loss: 0.0140\n",
      "\n",
      "Starting Epoch 30...\n",
      "Epoch 30/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0151 \n",
      "Epoch 30: val_loss did not improve from 0.01167\n",
      "Completed Epoch 30, Loss: 0.0151, Val Loss: 0.0126\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "\n",
      "Starting Epoch 31...\n",
      "Epoch 31/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0152 \n",
      "Epoch 31: val_loss did not improve from 0.01167\n",
      "Completed Epoch 31, Loss: 0.0151, Val Loss: 0.0141\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0152 - val_loss: 0.0141\n",
      "\n",
      "Starting Epoch 32...\n",
      "Epoch 32/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0152 \n",
      "Epoch 32: val_loss did not improve from 0.01167\n",
      "Completed Epoch 32, Loss: 0.0149, Val Loss: 0.0140\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0152 - val_loss: 0.0140\n",
      "\n",
      "Starting Epoch 33...\n",
      "Epoch 33/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0149 \n",
      "Epoch 33: val_loss did not improve from 0.01167\n",
      "Completed Epoch 33, Loss: 0.0151, Val Loss: 0.0130\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0149 - val_loss: 0.0130\n",
      "\n",
      "Starting Epoch 34...\n",
      "Epoch 34/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0149 \n",
      "Epoch 34: val_loss did not improve from 0.01167\n",
      "Completed Epoch 34, Loss: 0.0150, Val Loss: 0.0154\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0149 - val_loss: 0.0154\n",
      "\n",
      "Starting Epoch 35...\n",
      "Epoch 35/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0147 \n",
      "Epoch 35: val_loss did not improve from 0.01167\n",
      "Completed Epoch 35, Loss: 0.0147, Val Loss: 0.0136\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0147 - val_loss: 0.0136\n",
      "\n",
      "Starting Epoch 36...\n",
      "Epoch 36/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0144 \n",
      "Epoch 36: val_loss did not improve from 0.01167\n",
      "Completed Epoch 36, Loss: 0.0149, Val Loss: 0.0135\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0144 - val_loss: 0.0135\n",
      "\n",
      "Starting Epoch 37...\n",
      "Epoch 37/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0153 \n",
      "Epoch 37: val_loss did not improve from 0.01167\n",
      "Completed Epoch 37, Loss: 0.0150, Val Loss: 0.0129\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0153 - val_loss: 0.0129\n",
      "\n",
      "Starting Epoch 38...\n",
      "Epoch 38/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0148 \n",
      "Epoch 38: val_loss did not improve from 0.01167\n",
      "Completed Epoch 38, Loss: 0.0147, Val Loss: 0.0161\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0148 - val_loss: 0.0161\n",
      "\n",
      "Starting Epoch 39...\n",
      "Epoch 39/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0151 \n",
      "Epoch 39: val_loss did not improve from 0.01167\n",
      "Completed Epoch 39, Loss: 0.0151, Val Loss: 0.0146\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0151 - val_loss: 0.0146\n",
      "\n",
      "Starting Epoch 40...\n",
      "Epoch 40/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0151 \n",
      "Epoch 40: val_loss did not improve from 0.01167\n",
      "Completed Epoch 40, Loss: 0.0151, Val Loss: 0.0145\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "\n",
      "Starting Epoch 41...\n",
      "Epoch 41/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0142 \n",
      "Epoch 41: val_loss did not improve from 0.01167\n",
      "Completed Epoch 41, Loss: 0.0149, Val Loss: 0.0140\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "\n",
      "Starting Epoch 42...\n",
      "Epoch 42/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0148 \n",
      "Epoch 42: val_loss did not improve from 0.01167\n",
      "Completed Epoch 42, Loss: 0.0150, Val Loss: 0.0146\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "\n",
      "Starting Epoch 43...\n",
      "Epoch 43/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0145 \n",
      "Epoch 43: val_loss did not improve from 0.01167\n",
      "Completed Epoch 43, Loss: 0.0148, Val Loss: 0.0149\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0145 - val_loss: 0.0149\n",
      "\n",
      "Starting Epoch 44...\n",
      "Epoch 44/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0147 \n",
      "Epoch 44: val_loss did not improve from 0.01167\n",
      "Completed Epoch 44, Loss: 0.0146, Val Loss: 0.0142\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0147 - val_loss: 0.0142\n",
      "\n",
      "Starting Epoch 45...\n",
      "Epoch 45/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0145 \n",
      "Epoch 45: val_loss did not improve from 0.01167\n",
      "Completed Epoch 45, Loss: 0.0146, Val Loss: 0.0129\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0145 - val_loss: 0.0129\n",
      "\n",
      "Starting Epoch 46...\n",
      "Epoch 46/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0146 \n",
      "Epoch 46: val_loss did not improve from 0.01167\n",
      "Completed Epoch 46, Loss: 0.0146, Val Loss: 0.0207\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0146 - val_loss: 0.0207\n",
      "\n",
      "Starting Epoch 47...\n",
      "Epoch 47/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0145 \n",
      "Epoch 47: val_loss did not improve from 0.01167\n",
      "Completed Epoch 47, Loss: 0.0144, Val Loss: 0.0151\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0145 - val_loss: 0.0151\n",
      "\n",
      "Starting Epoch 48...\n",
      "Epoch 48/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0147 \n",
      "Epoch 48: val_loss did not improve from 0.01167\n",
      "Completed Epoch 48, Loss: 0.0147, Val Loss: 0.0136\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0147 - val_loss: 0.0136\n",
      "\n",
      "Starting Epoch 49...\n",
      "Epoch 49/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0144 \n",
      "Epoch 49: val_loss did not improve from 0.01167\n",
      "Completed Epoch 49, Loss: 0.0144, Val Loss: 0.0128\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 88ms/step - loss: 0.0144 - val_loss: 0.0128\n",
      "\n",
      "Starting Epoch 50...\n",
      "Epoch 50/50\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0146 \n",
      "Epoch 50: val_loss did not improve from 0.01167\n",
      "Completed Epoch 50, Loss: 0.0149, Val Loss: 0.0135\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - loss: 0.0146 - val_loss: 0.0135\n"
     ]
    }
   ],
   "source": [
    "# Define ModelCheckpoint callback\n",
    "checkpoint_filepath = '/home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras'\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Define a callback to print epoch tracking info\n",
    "epoch_callback = LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch, logs: print(f\"\\nStarting Epoch {epoch + 1}...\"),\n",
    "    on_epoch_end=lambda epoch, logs: print(f\"Completed Epoch {epoch + 1}, Loss: {logs['loss']:.4f}, Val Loss: {logs['val_loss']:.4f}\")\n",
    ")\n",
    "\n",
    "# Training loop with added callback\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[model_checkpoint, epoch_callback]  # Include both callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FiHy6opSP2sQ"
   },
   "outputs": [],
   "source": [
    "model.save_weights('/home/apyba3/car_frozen_regression_mobnetv3small.weights.h5')\n",
    "# model.save_weights('/home/ppytr13/car_frozen.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clear keras session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FpLHyw20P93U"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session() #Clear keras session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENHbUvQdvyFe"
   },
   "source": [
    "### 2d) fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0ek_ytyw0KB"
   },
   "source": [
    "rebuild model after clearing keras session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " MobileNetV3Small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> \n",
       "\n",
       " global_average_pooling2d         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)                                               \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">147,712</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> \n",
       "\n",
       " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \n",
       "\n",
       " dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> \n",
       "\n",
       " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " MobileNetV3Small (\u001b[38;5;33mFunctional\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m)             \u001b[38;5;34m939,120\u001b[0m \n",
       "\n",
       " global_average_pooling2d         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)                                               \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   \u001b[38;5;34m147,712\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m32,896\u001b[0m \n",
       "\n",
       " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                      \u001b[38;5;34m8,256\u001b[0m \n",
       "\n",
       " dropout_3 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      \u001b[38;5;34m2,080\u001b[0m \n",
       "\n",
       " dense_4 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m33\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,130,097</span> (4.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,130,097\u001b[0m (4.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,117,985</span> (4.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,117,985\u001b[0m (4.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,112</span> (47.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m12,112\u001b[0m (47.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobnetv3small = tf.keras.applications.MobileNetV3Small(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = input_shape\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  mobnetv3small,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dropout(dropoutrate),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dropout(dropoutrate),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(dropoutrate),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dropout(dropoutrate),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "mobnetv3small.trainable = True  # Make the entire model trainable\n",
    "\n",
    "model.summary() # print the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # deliberately smaller learning rate\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now load in the learned weights from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "8oAenzEiP-C-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('/home/apyba3/car_frozen_regression_mobnetv3small.weights.h5')\n",
    "# model.load_weights('/home/ppytr13/car_frozen.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWDtRxBow89t"
   },
   "source": [
    "Initiate fine-tuning training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Epoch 1...\n",
      "Epoch 1/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: 1.7482   \n",
      "Epoch 1: val_loss improved from inf to 0.02090, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 1, Loss: 0.3715, Val Loss: 0.0209\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 435ms/step - loss: 1.7463 - val_loss: 0.0209\n",
      "\n",
      "Starting Epoch 2...\n",
      "Epoch 2/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.0235  \n",
      "Epoch 2: val_loss did not improve from 0.02090\n",
      "Completed Epoch 2, Loss: 0.0222, Val Loss: 0.0315\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 432ms/step - loss: 0.0235 - val_loss: 0.0315\n",
      "\n",
      "Starting Epoch 3...\n",
      "Epoch 3/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.0186  \n",
      "Epoch 3: val_loss did not improve from 0.02090\n",
      "Completed Epoch 3, Loss: 0.0177, Val Loss: 0.0344\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 432ms/step - loss: 0.0186 - val_loss: 0.0344\n",
      "\n",
      "Starting Epoch 4...\n",
      "Epoch 4/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: 0.0158  \n",
      "Epoch 4: val_loss did not improve from 0.02090\n",
      "Completed Epoch 4, Loss: 0.0155, Val Loss: 0.0226\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 431ms/step - loss: 0.0158 - val_loss: 0.0226\n",
      "\n",
      "Starting Epoch 5...\n",
      "Epoch 5/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: 0.0142  \n",
      "Epoch 5: val_loss improved from 0.02090 to 0.01859, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 5, Loss: 0.0140, Val Loss: 0.0186\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 432ms/step - loss: 0.0142 - val_loss: 0.0186\n",
      "\n",
      "Starting Epoch 6...\n",
      "Epoch 6/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0135  \n",
      "Epoch 6: val_loss improved from 0.01859 to 0.01629, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 6, Loss: 0.0132, Val Loss: 0.0163\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0135 - val_loss: 0.0163\n",
      "\n",
      "Starting Epoch 7...\n",
      "Epoch 7/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0126  \n",
      "Epoch 7: val_loss improved from 0.01629 to 0.01541, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 7, Loss: 0.0121, Val Loss: 0.0154\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0125 - val_loss: 0.0154\n",
      "\n",
      "Starting Epoch 8...\n",
      "Epoch 8/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0109  \n",
      "Epoch 8: val_loss improved from 0.01541 to 0.01237, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 8, Loss: 0.0107, Val Loss: 0.0124\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0109 - val_loss: 0.0124\n",
      "\n",
      "Starting Epoch 9...\n",
      "Epoch 9/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0099  \n",
      "Epoch 9: val_loss improved from 0.01237 to 0.01129, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 9, Loss: 0.0096, Val Loss: 0.0113\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "\n",
      "Starting Epoch 10...\n",
      "Epoch 10/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0089  \n",
      "Epoch 10: val_loss improved from 0.01129 to 0.00827, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 10, Loss: 0.0087, Val Loss: 0.0083\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "\n",
      "Starting Epoch 11...\n",
      "Epoch 11/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0081  \n",
      "Epoch 11: val_loss improved from 0.00827 to 0.00673, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 11, Loss: 0.0080, Val Loss: 0.0067\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "\n",
      "Starting Epoch 12...\n",
      "Epoch 12/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0074  \n",
      "Epoch 12: val_loss did not improve from 0.00673\n",
      "Completed Epoch 12, Loss: 0.0072, Val Loss: 0.0073\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "\n",
      "Starting Epoch 13...\n",
      "Epoch 13/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0068  \n",
      "Epoch 13: val_loss did not improve from 0.00673\n",
      "Completed Epoch 13, Loss: 0.0068, Val Loss: 0.0077\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "\n",
      "Starting Epoch 14...\n",
      "Epoch 14/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0065  \n",
      "Epoch 14: val_loss did not improve from 0.00673\n",
      "Completed Epoch 14, Loss: 0.0064, Val Loss: 0.0091\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - loss: 0.0065 - val_loss: 0.0091\n",
      "\n",
      "Starting Epoch 15...\n",
      "Epoch 15/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0063  \n",
      "Epoch 15: val_loss did not improve from 0.00673\n",
      "Completed Epoch 15, Loss: 0.0062, Val Loss: 0.0109\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - loss: 0.0063 - val_loss: 0.0109\n",
      "\n",
      "Starting Epoch 16...\n",
      "Epoch 16/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0059  \n",
      "Epoch 16: val_loss did not improve from 0.00673\n",
      "Completed Epoch 16, Loss: 0.0058, Val Loss: 0.0085\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0059 - val_loss: 0.0085\n",
      "\n",
      "Starting Epoch 17...\n",
      "Epoch 17/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0055  \n",
      "Epoch 17: val_loss did not improve from 0.00673\n",
      "Completed Epoch 17, Loss: 0.0055, Val Loss: 0.0076\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - loss: 0.0055 - val_loss: 0.0076\n",
      "\n",
      "Starting Epoch 18...\n",
      "Epoch 18/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: 0.0053  \n",
      "Epoch 18: val_loss did not improve from 0.00673\n",
      "Completed Epoch 18, Loss: 0.0052, Val Loss: 0.0101\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "\n",
      "Starting Epoch 19...\n",
      "Epoch 19/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0050  \n",
      "Epoch 19: val_loss did not improve from 0.00673\n",
      "Completed Epoch 19, Loss: 0.0051, Val Loss: 0.0140\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - loss: 0.0050 - val_loss: 0.0140\n",
      "\n",
      "Starting Epoch 20...\n",
      "Epoch 20/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0049  \n",
      "Epoch 20: val_loss did not improve from 0.00673\n",
      "Completed Epoch 20, Loss: 0.0049, Val Loss: 0.0112\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0049 - val_loss: 0.0112\n",
      "\n",
      "Starting Epoch 21...\n",
      "Epoch 21/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0045  \n",
      "Epoch 21: val_loss did not improve from 0.00673\n",
      "Completed Epoch 21, Loss: 0.0048, Val Loss: 0.0752\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - loss: 0.0045 - val_loss: 0.0752\n",
      "\n",
      "Starting Epoch 22...\n",
      "Epoch 22/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0047  \n",
      "Epoch 22: val_loss did not improve from 0.00673\n",
      "Completed Epoch 22, Loss: 0.0046, Val Loss: 0.0109\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - loss: 0.0047 - val_loss: 0.0109\n",
      "\n",
      "Starting Epoch 23...\n",
      "Epoch 23/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0040  \n",
      "Epoch 23: val_loss improved from 0.00673 to 0.00556, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 23, Loss: 0.0041, Val Loss: 0.0056\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0040 - val_loss: 0.0056\n",
      "\n",
      "Starting Epoch 24...\n",
      "Epoch 24/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0041  \n",
      "Epoch 24: val_loss did not improve from 0.00556\n",
      "Completed Epoch 24, Loss: 0.0042, Val Loss: 0.0066\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0041 - val_loss: 0.0066\n",
      "\n",
      "Starting Epoch 25...\n",
      "Epoch 25/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0038  \n",
      "Epoch 25: val_loss did not improve from 0.00556\n",
      "Completed Epoch 25, Loss: 0.0039, Val Loss: 0.0075\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - loss: 0.0038 - val_loss: 0.0075\n",
      "\n",
      "Starting Epoch 26...\n",
      "Epoch 26/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0038  \n",
      "Epoch 26: val_loss did not improve from 0.00556\n",
      "Completed Epoch 26, Loss: 0.0040, Val Loss: 0.0225\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0038 - val_loss: 0.0225\n",
      "\n",
      "Starting Epoch 27...\n",
      "Epoch 27/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0038  \n",
      "Epoch 27: val_loss did not improve from 0.00556\n",
      "Completed Epoch 27, Loss: 0.0038, Val Loss: 0.0120\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - loss: 0.0038 - val_loss: 0.0120\n",
      "\n",
      "Starting Epoch 28...\n",
      "Epoch 28/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0034  \n",
      "Epoch 28: val_loss did not improve from 0.00556\n",
      "Completed Epoch 28, Loss: 0.0034, Val Loss: 0.0066\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0034 - val_loss: 0.0066\n",
      "\n",
      "Starting Epoch 29...\n",
      "Epoch 29/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0033  \n",
      "Epoch 29: val_loss did not improve from 0.00556\n",
      "Completed Epoch 29, Loss: 0.0033, Val Loss: 0.0090\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 430ms/step - loss: 0.0033 - val_loss: 0.0090\n",
      "\n",
      "Starting Epoch 30...\n",
      "Epoch 30/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: 0.0031  \n",
      "Epoch 30: val_loss did not improve from 0.00556\n",
      "Completed Epoch 30, Loss: 0.0032, Val Loss: 0.0193\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0031 - val_loss: 0.0193\n",
      "\n",
      "Starting Epoch 31...\n",
      "Epoch 31/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0033  \n",
      "Epoch 31: val_loss did not improve from 0.00556\n",
      "Completed Epoch 31, Loss: 0.0032, Val Loss: 0.0088\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 430ms/step - loss: 0.0033 - val_loss: 0.0088\n",
      "\n",
      "Starting Epoch 32...\n",
      "Epoch 32/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0031  \n",
      "Epoch 32: val_loss improved from 0.00556 to 0.00513, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 32, Loss: 0.0030, Val Loss: 0.0051\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0031 - val_loss: 0.0051\n",
      "\n",
      "Starting Epoch 33...\n",
      "Epoch 33/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0029  \n",
      "Epoch 33: val_loss improved from 0.00513 to 0.00495, saving model to /home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras\n",
      "Completed Epoch 33, Loss: 0.0029, Val Loss: 0.0050\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "\n",
      "Starting Epoch 34...\n",
      "Epoch 34/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0027  \n",
      "Epoch 34: val_loss did not improve from 0.00495\n",
      "Completed Epoch 34, Loss: 0.0027, Val Loss: 0.0079\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 431ms/step - loss: 0.0027 - val_loss: 0.0079\n",
      "\n",
      "Starting Epoch 35...\n",
      "Epoch 35/38\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0027  \n",
      "Epoch 35: val_loss did not improve from 0.00495\n",
      "Completed Epoch 35, Loss: 0.0028, Val Loss: 0.0056\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 430ms/step - loss: 0.0027 - val_loss: 0.0056\n",
      "\n",
      "Starting Epoch 36...\n",
      "Epoch 36/38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m epoch_callback \u001b[38;5;241m=\u001b[39m LambdaCallback(\n\u001b[1;32m     14\u001b[0m     on_epoch_begin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m epoch, logs: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     15\u001b[0m     on_epoch_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m epoch, logs: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Training loop with added callback\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m38\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Include both callbacks\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define ModelCheckpoint callback\n",
    "checkpoint_filepath = '/home/apyba3/MobNetV3Small/mobnetv3smallcheckpoint.keras'\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Define a callback to print epoch tracking info\n",
    "epoch_callback = LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch, logs: print(f\"\\nStarting Epoch {epoch + 1}...\"),\n",
    "    on_epoch_end=lambda epoch, logs: print(f\"Completed Epoch {epoch + 1}, Loss: {logs['loss']:.4f}, Val Loss: {logs['val_loss']:.4f}\")\n",
    ")\n",
    "\n",
    "# Training loop with added callback\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=38,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[model_checkpoint, epoch_callback]  # Include both callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the weights learned from fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "O14u6175RLjA"
   },
   "outputs": [],
   "source": [
    "model.save_weights('car_unfrozen_regression_mobnetv3small.weights.h5')\n",
    "# model.save_weights('/home/ppytr13/car_unfrozen.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCbo4VcLxLgQ"
   },
   "source": [
    "# 3) Test-Set Predictions\n",
    "\n",
    "a) load in test data\n",
    "\n",
    "b) convert test images to numerical RGB feature maps\n",
    "\n",
    "c) generate predictions on the test set\n",
    "\n",
    "d) correctly format the predictions into a pandas dataframe\n",
    "\n",
    "e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnygDJsKxYhA"
   },
   "source": [
    "### 3a) load in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "W-e59lQQRXKK",
    "outputId": "aa8566ec-e472-47a6-c7a0-92266b567a62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/5.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              image_file_paths\n",
       "image_id                                                                                      \n",
       "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/1.png\n",
       "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/2.png\n",
       "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/3.png\n",
       "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/4.png\n",
       "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/5.png"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data'\n",
    "# image_folder_path = '/home/ppyt13/machine-learning-in-science-ii-2025/test_data/test_data' # tylers file path\n",
    "image_file_paths = [\n",
    "    os.path.join(image_folder_path, f)\n",
    "    for f in os.listdir(image_folder_path)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "]\n",
    "\n",
    "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
    "\n",
    "imagefilepaths_df = pd.DataFrame(\n",
    "    image_file_paths,\n",
    "    columns=['image_file_paths'],\n",
    "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
    ")\n",
    "\n",
    "imagefilepaths_df.index.name = 'image_id'\n",
    "imagefilepaths_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-9i5trTyDTf"
   },
   "source": [
    "### 3b) convert test images to numerical RGB feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3hT_c1s5TAR-"
   },
   "outputs": [],
   "source": [
    "def process_image_no_label(image_path, resized_shape=(224, 224)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
    "    image = tf.image.resize(image, resized_shape)  # Resize to uniform shape\n",
    "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
    "    return image\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((imagefilepaths_df[\"image_file_paths\"]))\n",
    "\n",
    "test_dataset = test_dataset.map(process_image_no_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gobnK7PhyLa2"
   },
   "source": [
    "### 3c) generate predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtqcOFr7TAXa",
    "outputId": "73b4c96b-51bf-4e1c-e1b6-e8cde1321984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT1LJxHTPeQT"
   },
   "source": [
    "### 3d) correctly format the predictions into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "pFVWGi04fza7"
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions, columns=['angle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "OnO0K1rReHOT",
    "outputId": "d9cebb2e-3d36-4c7a-b024-eabb646e3bbb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.573428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.732077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.188098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      angle\n",
       "0  0.573428\n",
       "1  0.732077\n",
       "2  0.188098\n",
       "3  0.196967\n",
       "4  0.169281"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CcRKL9KTAfs",
    "outputId": "277533cd-06aa-4709-d44e-9027cc7e9438"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angle\n",
       "0.254174    1\n",
       "0.573428    1\n",
       "0.732077    1\n",
       "0.188098    1\n",
       "0.196967    1\n",
       "0.169281    1\n",
       "0.660120    1\n",
       "0.653696    1\n",
       "0.743585    1\n",
       "0.631948    1\n",
       "0.566528    1\n",
       "0.581694    1\n",
       "0.715047    1\n",
       "0.448052    1\n",
       "0.543990    1\n",
       "0.228387    1\n",
       "0.558458    1\n",
       "0.557174    1\n",
       "0.724658    1\n",
       "0.452504    1\n",
       "0.128574    1\n",
       "0.850488    1\n",
       "0.225213    1\n",
       "0.224168    1\n",
       "0.731123    1\n",
       "0.689312    1\n",
       "0.674881    1\n",
       "0.631100    1\n",
       "0.203592    1\n",
       "0.608497    1\n",
       "0.671797    1\n",
       "0.671608    1\n",
       "0.662162    1\n",
       "0.190784    1\n",
       "0.438939    1\n",
       "0.697620    1\n",
       "0.564853    1\n",
       "0.514004    1\n",
       "0.656687    1\n",
       "0.581329    1\n",
       "0.440722    1\n",
       "0.705727    1\n",
       "0.691638    1\n",
       "0.739633    1\n",
       "0.653484    1\n",
       "0.515683    1\n",
       "0.577943    1\n",
       "0.541233    1\n",
       "0.654818    1\n",
       "0.256934    1\n",
       "0.746365    1\n",
       "0.581792    1\n",
       "0.663440    1\n",
       "0.165161    1\n",
       "0.117512    1\n",
       "0.152427    1\n",
       "0.525718    1\n",
       "0.215527    1\n",
       "0.531891    1\n",
       "0.419353    1\n",
       "0.447581    1\n",
       "0.497297    1\n",
       "0.508197    1\n",
       "0.181916    1\n",
       "0.627600    1\n",
       "0.222633    1\n",
       "0.526223    1\n",
       "0.459289    1\n",
       "0.817422    1\n",
       "0.399599    1\n",
       "0.542744    1\n",
       "0.690802    1\n",
       "0.786481    1\n",
       "0.731086    1\n",
       "0.622071    1\n",
       "0.439502    1\n",
       "0.395601    1\n",
       "0.670666    1\n",
       "0.455553    1\n",
       "0.537317    1\n",
       "0.690716    1\n",
       "0.691739    1\n",
       "0.488270    1\n",
       "0.743175    1\n",
       "0.739630    1\n",
       "0.473589    1\n",
       "0.680194    1\n",
       "0.652290    1\n",
       "0.647000    1\n",
       "0.747830    1\n",
       "0.502507    1\n",
       "0.639699    1\n",
       "0.684826    1\n",
       "0.533809    1\n",
       "0.752049    1\n",
       "0.616593    1\n",
       "0.588566    1\n",
       "0.524878    1\n",
       "0.440293    1\n",
       "0.484331    1\n",
       "0.674200    1\n",
       "0.699654    1\n",
       "0.414108    1\n",
       "0.499585    1\n",
       "0.677935    1\n",
       "0.463047    1\n",
       "0.639189    1\n",
       "0.468019    1\n",
       "0.709439    1\n",
       "0.701008    1\n",
       "0.335501    1\n",
       "0.479113    1\n",
       "0.303262    1\n",
       "0.615620    1\n",
       "0.625983    1\n",
       "0.189837    1\n",
       "0.642565    1\n",
       "0.206236    1\n",
       "0.660663    1\n",
       "0.420866    1\n",
       "0.329738    1\n",
       "0.653044    1\n",
       "0.483622    1\n",
       "0.622637    1\n",
       "0.434441    1\n",
       "0.440443    1\n",
       "0.711949    1\n",
       "0.664053    1\n",
       "0.652346    1\n",
       "0.541241    1\n",
       "0.547330    1\n",
       "0.559705    1\n",
       "0.655001    1\n",
       "0.184706    1\n",
       "0.478708    1\n",
       "0.421995    1\n",
       "0.457052    1\n",
       "0.773659    1\n",
       "0.297729    1\n",
       "0.496138    1\n",
       "0.678177    1\n",
       "0.637507    1\n",
       "0.688644    1\n",
       "0.645153    1\n",
       "0.434509    1\n",
       "0.660186    1\n",
       "0.413081    1\n",
       "0.652143    1\n",
       "0.112104    1\n",
       "0.743147    1\n",
       "0.228314    1\n",
       "0.376354    1\n",
       "0.226323    1\n",
       "0.492901    1\n",
       "0.702412    1\n",
       "0.461222    1\n",
       "0.394369    1\n",
       "0.719211    1\n",
       "0.431303    1\n",
       "0.504289    1\n",
       "0.481574    1\n",
       "0.759674    1\n",
       "0.381313    1\n",
       "0.641671    1\n",
       "0.700913    1\n",
       "0.445048    1\n",
       "0.299929    1\n",
       "0.427756    1\n",
       "0.702796    1\n",
       "0.754436    1\n",
       "0.463487    1\n",
       "0.441018    1\n",
       "0.601324    1\n",
       "0.192242    1\n",
       "0.475919    1\n",
       "0.519673    1\n",
       "0.194830    1\n",
       "0.671929    1\n",
       "0.432402    1\n",
       "0.566906    1\n",
       "0.644857    1\n",
       "0.646112    1\n",
       "0.478538    1\n",
       "0.183667    1\n",
       "0.772400    1\n",
       "0.428268    1\n",
       "0.703190    1\n",
       "0.709609    1\n",
       "0.683367    1\n",
       "0.440742    1\n",
       "0.779133    1\n",
       "0.670250    1\n",
       "0.683237    1\n",
       "0.671682    1\n",
       "0.567068    1\n",
       "0.631922    1\n",
       "0.168875    1\n",
       "0.668263    1\n",
       "0.652023    1\n",
       "0.493647    1\n",
       "0.122317    1\n",
       "0.489286    1\n",
       "0.708507    1\n",
       "0.639551    1\n",
       "0.617092    1\n",
       "0.423708    1\n",
       "0.731840    1\n",
       "0.461907    1\n",
       "0.496403    1\n",
       "0.673971    1\n",
       "0.534798    1\n",
       "0.278960    1\n",
       "0.665886    1\n",
       "0.682401    1\n",
       "0.504890    1\n",
       "0.558194    1\n",
       "0.520086    1\n",
       "0.509356    1\n",
       "0.493260    1\n",
       "0.164636    1\n",
       "0.533947    1\n",
       "0.172765    1\n",
       "0.564946    1\n",
       "0.163509    1\n",
       "0.690288    1\n",
       "0.679282    1\n",
       "0.425828    1\n",
       "0.603417    1\n",
       "0.216244    1\n",
       "0.533828    1\n",
       "0.447358    1\n",
       "0.616946    1\n",
       "0.378223    1\n",
       "0.632268    1\n",
       "0.658714    1\n",
       "0.667180    1\n",
       "0.399452    1\n",
       "0.184607    1\n",
       "0.532763    1\n",
       "0.457343    1\n",
       "0.772240    1\n",
       "0.496804    1\n",
       "0.647438    1\n",
       "0.751347    1\n",
       "0.747840    1\n",
       "0.662909    1\n",
       "0.707619    1\n",
       "0.132700    1\n",
       "0.150231    1\n",
       "0.721088    1\n",
       "0.247941    1\n",
       "0.772931    1\n",
       "0.667801    1\n",
       "0.645526    1\n",
       "0.763873    1\n",
       "0.471256    1\n",
       "0.517004    1\n",
       "0.752488    1\n",
       "0.140388    1\n",
       "0.508733    1\n",
       "0.734351    1\n",
       "0.182038    1\n",
       "0.737316    1\n",
       "0.126655    1\n",
       "0.748084    1\n",
       "0.647284    1\n",
       "0.496876    1\n",
       "0.206956    1\n",
       "0.726734    1\n",
       "0.641811    1\n",
       "0.655575    1\n",
       "0.673347    1\n",
       "0.558677    1\n",
       "0.655285    1\n",
       "0.703355    1\n",
       "0.820945    1\n",
       "0.647729    1\n",
       "0.754581    1\n",
       "0.592771    1\n",
       "0.675776    1\n",
       "0.678186    1\n",
       "0.714171    1\n",
       "0.123365    1\n",
       "0.485034    1\n",
       "0.504226    1\n",
       "0.654646    1\n",
       "0.627280    1\n",
       "0.164401    1\n",
       "0.723601    1\n",
       "0.778747    1\n",
       "0.553939    1\n",
       "0.627524    1\n",
       "0.604502    1\n",
       "0.491115    1\n",
       "0.789366    1\n",
       "0.659744    1\n",
       "0.198020    1\n",
       "0.654861    1\n",
       "0.670644    1\n",
       "0.670539    1\n",
       "0.449852    1\n",
       "0.736287    1\n",
       "0.784479    1\n",
       "0.498088    1\n",
       "0.499542    1\n",
       "0.525920    1\n",
       "0.514132    1\n",
       "0.600762    1\n",
       "0.420254    1\n",
       "0.630603    1\n",
       "0.625309    1\n",
       "0.605170    1\n",
       "0.371319    1\n",
       "0.599969    1\n",
       "0.660464    1\n",
       "0.733607    1\n",
       "0.279343    1\n",
       "0.621126    1\n",
       "0.455030    1\n",
       "0.678927    1\n",
       "0.423460    1\n",
       "0.696673    1\n",
       "0.483003    1\n",
       "0.643449    1\n",
       "0.750444    1\n",
       "0.620740    1\n",
       "0.699806    1\n",
       "0.252738    1\n",
       "0.530252    1\n",
       "0.758877    1\n",
       "0.750499    1\n",
       "0.459636    1\n",
       "0.668192    1\n",
       "0.534126    1\n",
       "0.184066    1\n",
       "0.724300    1\n",
       "0.669805    1\n",
       "0.723479    1\n",
       "0.683151    1\n",
       "0.601666    1\n",
       "0.686933    1\n",
       "0.163726    1\n",
       "0.488959    1\n",
       "0.511249    1\n",
       "0.546112    1\n",
       "0.376566    1\n",
       "0.667780    1\n",
       "0.748263    1\n",
       "0.459398    1\n",
       "0.469826    1\n",
       "0.482602    1\n",
       "0.127035    1\n",
       "0.701571    1\n",
       "0.469478    1\n",
       "0.689660    1\n",
       "0.522139    1\n",
       "0.635830    1\n",
       "0.446404    1\n",
       "0.715940    1\n",
       "0.742497    1\n",
       "0.524060    1\n",
       "0.498680    1\n",
       "0.443266    1\n",
       "0.502201    1\n",
       "0.572717    1\n",
       "0.525613    1\n",
       "0.653513    1\n",
       "0.714474    1\n",
       "0.776903    1\n",
       "0.617178    1\n",
       "0.756586    1\n",
       "0.584766    1\n",
       "0.622220    1\n",
       "0.571229    1\n",
       "0.562184    1\n",
       "0.462278    1\n",
       "0.485321    1\n",
       "0.441676    1\n",
       "0.574351    1\n",
       "0.362065    1\n",
       "0.564187    1\n",
       "0.510460    1\n",
       "0.542560    1\n",
       "0.622621    1\n",
       "0.074543    1\n",
       "0.691109    1\n",
       "0.657441    1\n",
       "0.583074    1\n",
       "0.211590    1\n",
       "0.758622    1\n",
       "0.559022    1\n",
       "0.738585    1\n",
       "0.384806    1\n",
       "0.685807    1\n",
       "0.175132    1\n",
       "0.440104    1\n",
       "0.430235    1\n",
       "0.662358    1\n",
       "0.164523    1\n",
       "0.475538    1\n",
       "0.518825    1\n",
       "0.488150    1\n",
       "0.465112    1\n",
       "0.192986    1\n",
       "0.295808    1\n",
       "0.640743    1\n",
       "0.581517    1\n",
       "0.430515    1\n",
       "0.644683    1\n",
       "0.615689    1\n",
       "0.541571    1\n",
       "0.131946    1\n",
       "0.433990    1\n",
       "0.425242    1\n",
       "0.684156    1\n",
       "0.152959    1\n",
       "0.479347    1\n",
       "0.175297    1\n",
       "0.196325    1\n",
       "0.650631    1\n",
       "0.747999    1\n",
       "0.423239    1\n",
       "0.661032    1\n",
       "0.182142    1\n",
       "0.666180    1\n",
       "0.634862    1\n",
       "0.610941    1\n",
       "0.479657    1\n",
       "0.727470    1\n",
       "0.667202    1\n",
       "0.706966    1\n",
       "0.422502    1\n",
       "0.403866    1\n",
       "0.431213    1\n",
       "0.489310    1\n",
       "0.413103    1\n",
       "0.733778    1\n",
       "0.721753    1\n",
       "0.641584    1\n",
       "0.843156    1\n",
       "0.183597    1\n",
       "0.609491    1\n",
       "0.754981    1\n",
       "0.408916    1\n",
       "0.781147    1\n",
       "0.557940    1\n",
       "0.638240    1\n",
       "0.472046    1\n",
       "0.172984    1\n",
       "0.486703    1\n",
       "0.645458    1\n",
       "0.082258    1\n",
       "0.678835    1\n",
       "0.638030    1\n",
       "0.228880    1\n",
       "0.608735    1\n",
       "0.741444    1\n",
       "0.722085    1\n",
       "0.554656    1\n",
       "0.445871    1\n",
       "0.393126    1\n",
       "0.641855    1\n",
       "0.756904    1\n",
       "0.642559    1\n",
       "0.246154    1\n",
       "0.426298    1\n",
       "0.587812    1\n",
       "0.171638    1\n",
       "0.500169    1\n",
       "0.726139    1\n",
       "0.595740    1\n",
       "0.500722    1\n",
       "0.686431    1\n",
       "0.766017    1\n",
       "0.651708    1\n",
       "0.650394    1\n",
       "0.645057    1\n",
       "0.671289    1\n",
       "0.459536    1\n",
       "0.268011    1\n",
       "0.754718    1\n",
       "0.584097    1\n",
       "0.228429    1\n",
       "0.540190    1\n",
       "0.722686    1\n",
       "0.738175    1\n",
       "0.569320    1\n",
       "0.181067    1\n",
       "0.617369    1\n",
       "0.186654    1\n",
       "0.505389    1\n",
       "0.526792    1\n",
       "0.769827    1\n",
       "0.488511    1\n",
       "0.498832    1\n",
       "0.654544    1\n",
       "0.235016    1\n",
       "0.403519    1\n",
       "0.138405    1\n",
       "0.632638    1\n",
       "0.767999    1\n",
       "0.432061    1\n",
       "0.682266    1\n",
       "0.511557    1\n",
       "0.680632    1\n",
       "0.587541    1\n",
       "0.681653    1\n",
       "0.477893    1\n",
       "0.714055    1\n",
       "0.647211    1\n",
       "0.569378    1\n",
       "0.571741    1\n",
       "0.718358    1\n",
       "0.732924    1\n",
       "0.512558    1\n",
       "0.432706    1\n",
       "0.718432    1\n",
       "0.466238    1\n",
       "0.672222    1\n",
       "0.622916    1\n",
       "0.478973    1\n",
       "0.641877    1\n",
       "0.656807    1\n",
       "0.243670    1\n",
       "0.616732    1\n",
       "0.133578    1\n",
       "0.574588    1\n",
       "0.580634    1\n",
       "0.705425    1\n",
       "0.347222    1\n",
       "0.576951    1\n",
       "0.432953    1\n",
       "0.535265    1\n",
       "0.492626    1\n",
       "0.754230    1\n",
       "0.650928    1\n",
       "0.773704    1\n",
       "0.651301    1\n",
       "0.257784    1\n",
       "0.580239    1\n",
       "0.734626    1\n",
       "0.420482    1\n",
       "0.607896    1\n",
       "0.691769    1\n",
       "0.491688    1\n",
       "0.502301    1\n",
       "0.471910    1\n",
       "0.481009    1\n",
       "0.164452    1\n",
       "0.505953    1\n",
       "0.649809    1\n",
       "0.491982    1\n",
       "0.469827    1\n",
       "0.721587    1\n",
       "0.597101    1\n",
       "0.640287    1\n",
       "0.682050    1\n",
       "0.461472    1\n",
       "0.488292    1\n",
       "0.205539    1\n",
       "0.198814    1\n",
       "0.655330    1\n",
       "0.195683    1\n",
       "0.753244    1\n",
       "0.186287    1\n",
       "0.672884    1\n",
       "0.813457    1\n",
       "0.595604    1\n",
       "0.502413    1\n",
       "0.809230    1\n",
       "0.383235    1\n",
       "0.442236    1\n",
       "0.703459    1\n",
       "0.480718    1\n",
       "0.745525    1\n",
       "0.428633    1\n",
       "0.759680    1\n",
       "0.529347    1\n",
       "0.168507    1\n",
       "0.665601    1\n",
       "0.504762    1\n",
       "0.376691    1\n",
       "0.745393    1\n",
       "0.620443    1\n",
       "0.505605    1\n",
       "0.645523    1\n",
       "0.198728    1\n",
       "0.110180    1\n",
       "0.503088    1\n",
       "0.432295    1\n",
       "0.169394    1\n",
       "0.640236    1\n",
       "0.654010    1\n",
       "0.644518    1\n",
       "0.651638    1\n",
       "0.518045    1\n",
       "0.761583    1\n",
       "0.564416    1\n",
       "0.233146    1\n",
       "0.751651    1\n",
       "0.814680    1\n",
       "0.683726    1\n",
       "0.526047    1\n",
       "0.411250    1\n",
       "0.664928    1\n",
       "0.452130    1\n",
       "0.731846    1\n",
       "0.564547    1\n",
       "0.698278    1\n",
       "0.223428    1\n",
       "0.475055    1\n",
       "0.620765    1\n",
       "0.613114    1\n",
       "0.492321    1\n",
       "0.655213    1\n",
       "0.728289    1\n",
       "0.181052    1\n",
       "0.611319    1\n",
       "0.132693    1\n",
       "0.779734    1\n",
       "0.640197    1\n",
       "0.585620    1\n",
       "0.591602    1\n",
       "0.633637    1\n",
       "0.680867    1\n",
       "0.781997    1\n",
       "0.517814    1\n",
       "0.487515    1\n",
       "0.461794    1\n",
       "0.120756    1\n",
       "0.842210    1\n",
       "0.542266    1\n",
       "0.213413    1\n",
       "0.667058    1\n",
       "0.189890    1\n",
       "0.789014    1\n",
       "0.710671    1\n",
       "0.538137    1\n",
       "0.590216    1\n",
       "0.587011    1\n",
       "0.503694    1\n",
       "0.486075    1\n",
       "0.176840    1\n",
       "0.588561    1\n",
       "0.449183    1\n",
       "0.677113    1\n",
       "0.446346    1\n",
       "0.610651    1\n",
       "0.545664    1\n",
       "0.441217    1\n",
       "0.586735    1\n",
       "0.710315    1\n",
       "0.680101    1\n",
       "0.636316    1\n",
       "0.668840    1\n",
       "0.364053    1\n",
       "0.484067    1\n",
       "0.624020    1\n",
       "0.563631    1\n",
       "0.613251    1\n",
       "0.665331    1\n",
       "0.408547    1\n",
       "0.527487    1\n",
       "0.663162    1\n",
       "0.720923    1\n",
       "0.657554    1\n",
       "0.640824    1\n",
       "0.675936    1\n",
       "0.541075    1\n",
       "0.175376    1\n",
       "0.171378    1\n",
       "0.740159    1\n",
       "0.515381    1\n",
       "0.528754    1\n",
       "0.500424    1\n",
       "0.478332    1\n",
       "0.638756    1\n",
       "0.653762    1\n",
       "0.633370    1\n",
       "0.509620    1\n",
       "0.746991    1\n",
       "0.508338    1\n",
       "0.750712    1\n",
       "0.389430    1\n",
       "0.226950    1\n",
       "0.655487    1\n",
       "0.635038    1\n",
       "0.653627    1\n",
       "0.664428    1\n",
       "0.698331    1\n",
       "0.230200    1\n",
       "0.497887    1\n",
       "0.408504    1\n",
       "0.556050    1\n",
       "0.169565    1\n",
       "0.698236    1\n",
       "0.669286    1\n",
       "0.645333    1\n",
       "0.448571    1\n",
       "0.271058    1\n",
       "0.742290    1\n",
       "0.664843    1\n",
       "0.678493    1\n",
       "0.664941    1\n",
       "0.155367    1\n",
       "0.462866    1\n",
       "0.436179    1\n",
       "0.573861    1\n",
       "0.399263    1\n",
       "0.660749    1\n",
       "0.176299    1\n",
       "0.430869    1\n",
       "0.632314    1\n",
       "0.135648    1\n",
       "0.743534    1\n",
       "0.647054    1\n",
       "0.167262    1\n",
       "0.676432    1\n",
       "0.124807    1\n",
       "0.137381    1\n",
       "0.537691    1\n",
       "0.418014    1\n",
       "0.380925    1\n",
       "0.571087    1\n",
       "0.502452    1\n",
       "0.354417    1\n",
       "0.206023    1\n",
       "0.229797    1\n",
       "0.667285    1\n",
       "0.644949    1\n",
       "0.483240    1\n",
       "0.721904    1\n",
       "0.163933    1\n",
       "0.454564    1\n",
       "0.400500    1\n",
       "0.450774    1\n",
       "0.499843    1\n",
       "0.472641    1\n",
       "0.712649    1\n",
       "0.222851    1\n",
       "0.196197    1\n",
       "0.598761    1\n",
       "0.607482    1\n",
       "0.232016    1\n",
       "0.707510    1\n",
       "0.459334    1\n",
       "0.678943    1\n",
       "0.629718    1\n",
       "0.667247    1\n",
       "0.633316    1\n",
       "0.731934    1\n",
       "0.627662    1\n",
       "0.646853    1\n",
       "0.634760    1\n",
       "0.563427    1\n",
       "0.677614    1\n",
       "0.698423    1\n",
       "0.483439    1\n",
       "0.250753    1\n",
       "0.406131    1\n",
       "0.635643    1\n",
       "0.791423    1\n",
       "0.713637    1\n",
       "0.427763    1\n",
       "0.686586    1\n",
       "0.829743    1\n",
       "0.525131    1\n",
       "0.595252    1\n",
       "0.645563    1\n",
       "0.213587    1\n",
       "0.566269    1\n",
       "0.482103    1\n",
       "0.436270    1\n",
       "0.459719    1\n",
       "0.601787    1\n",
       "0.437869    1\n",
       "0.131701    1\n",
       "0.637978    1\n",
       "0.492745    1\n",
       "0.773488    1\n",
       "0.717398    1\n",
       "0.434454    1\n",
       "0.755816    1\n",
       "0.748456    1\n",
       "0.194804    1\n",
       "0.433024    1\n",
       "0.204040    1\n",
       "0.713784    1\n",
       "0.687658    1\n",
       "0.746490    1\n",
       "0.661145    1\n",
       "0.488213    1\n",
       "0.484891    1\n",
       "0.466315    1\n",
       "0.875893    1\n",
       "0.180033    1\n",
       "0.503777    1\n",
       "0.723723    1\n",
       "0.474342    1\n",
       "0.455409    1\n",
       "0.681052    1\n",
       "0.532629    1\n",
       "0.680373    1\n",
       "0.733106    1\n",
       "0.757969    1\n",
       "0.769297    1\n",
       "0.243135    1\n",
       "0.113110    1\n",
       "0.733395    1\n",
       "0.721565    1\n",
       "0.630359    1\n",
       "0.612422    1\n",
       "0.587048    1\n",
       "0.696969    1\n",
       "0.745804    1\n",
       "0.505029    1\n",
       "0.743653    1\n",
       "0.744019    1\n",
       "0.682203    1\n",
       "0.638747    1\n",
       "0.447881    1\n",
       "0.692371    1\n",
       "0.589423    1\n",
       "0.704452    1\n",
       "0.640440    1\n",
       "0.671136    1\n",
       "0.659684    1\n",
       "0.177193    1\n",
       "0.512230    1\n",
       "0.744667    1\n",
       "0.645909    1\n",
       "0.506362    1\n",
       "0.573232    1\n",
       "0.428656    1\n",
       "0.660854    1\n",
       "0.202321    1\n",
       "0.728102    1\n",
       "0.172516    1\n",
       "0.519643    1\n",
       "0.464549    1\n",
       "0.838895    1\n",
       "0.453302    1\n",
       "0.744092    1\n",
       "0.442130    1\n",
       "0.563901    1\n",
       "0.506221    1\n",
       "0.654151    1\n",
       "0.508240    1\n",
       "0.517608    1\n",
       "0.684421    1\n",
       "0.499335    1\n",
       "0.408260    1\n",
       "0.415259    1\n",
       "0.659851    1\n",
       "0.705062    1\n",
       "0.207101    1\n",
       "0.436575    1\n",
       "0.660768    1\n",
       "0.724137    1\n",
       "0.470153    1\n",
       "0.734940    1\n",
       "0.451972    1\n",
       "0.565068    1\n",
       "0.689849    1\n",
       "0.701940    1\n",
       "0.715973    1\n",
       "0.400665    1\n",
       "0.173437    1\n",
       "0.658502    1\n",
       "0.458538    1\n",
       "0.437629    1\n",
       "0.665640    1\n",
       "0.495219    1\n",
       "0.227442    1\n",
       "0.147326    1\n",
       "0.675681    1\n",
       "0.577782    1\n",
       "0.499904    1\n",
       "0.549695    1\n",
       "0.185385    1\n",
       "0.496904    1\n",
       "0.178059    1\n",
       "0.528261    1\n",
       "0.660920    1\n",
       "0.706221    1\n",
       "0.436375    1\n",
       "0.497035    1\n",
       "0.516439    1\n",
       "0.721945    1\n",
       "0.573041    1\n",
       "0.507685    1\n",
       "0.424907    1\n",
       "0.717988    1\n",
       "0.657659    1\n",
       "0.671115    1\n",
       "0.655732    1\n",
       "0.550361    1\n",
       "0.655509    1\n",
       "0.668220    1\n",
       "0.527472    1\n",
       "0.525831    1\n",
       "0.520352    1\n",
       "0.645672    1\n",
       "0.608674    1\n",
       "0.616054    1\n",
       "0.629389    1\n",
       "0.534040    1\n",
       "0.364001    1\n",
       "0.632285    1\n",
       "0.407572    1\n",
       "0.681262    1\n",
       "0.658255    1\n",
       "0.845841    1\n",
       "0.579020    1\n",
       "0.698237    1\n",
       "0.664572    1\n",
       "0.051287    1\n",
       "0.196017    1\n",
       "0.493877    1\n",
       "0.224920    1\n",
       "0.597971    1\n",
       "0.505483    1\n",
       "0.556972    1\n",
       "0.487217    1\n",
       "0.659720    1\n",
       "0.581385    1\n",
       "0.513191    1\n",
       "0.185175    1\n",
       "0.684093    1\n",
       "0.704276    1\n",
       "0.532733    1\n",
       "0.434628    1\n",
       "0.199324    1\n",
       "0.770122    1\n",
       "0.657617    1\n",
       "0.525011    1\n",
       "0.458715    1\n",
       "0.673741    1\n",
       "0.211322    1\n",
       "0.564330    1\n",
       "0.830359    1\n",
       "0.759505    1\n",
       "0.604128    1\n",
       "0.146907    1\n",
       "0.405570    1\n",
       "0.514185    1\n",
       "0.626318    1\n",
       "0.182789    1\n",
       "0.677601    1\n",
       "0.156204    1\n",
       "0.701740    1\n",
       "0.713308    1\n",
       "0.489913    1\n",
       "0.711020    1\n",
       "0.850598    1\n",
       "0.709275    1\n",
       "0.637658    1\n",
       "0.636820    1\n",
       "0.357222    1\n",
       "0.596330    1\n",
       "0.597363    1\n",
       "0.423741    1\n",
       "0.129842    1\n",
       "0.588144    1\n",
       "0.718661    1\n",
       "0.517667    1\n",
       "0.200303    1\n",
       "0.601898    1\n",
       "0.659379    1\n",
       "0.726206    1\n",
       "0.468665    1\n",
       "0.645141    1\n",
       "0.874953    1\n",
       "0.668655    1\n",
       "0.741883    1\n",
       "0.148033    1\n",
       "0.173909    1\n",
       "0.250316    1\n",
       "0.509287    1\n",
       "0.513744    1\n",
       "0.655082    1\n",
       "0.562316    1\n",
       "0.665671    1\n",
       "0.561112    1\n",
       "0.168596    1\n",
       "0.652285    1\n",
       "0.542409    1\n",
       "0.732251    1\n",
       "0.753550    1\n",
       "0.758187    1\n",
       "0.718606    1\n",
       "0.667014    1\n",
       "0.527386    1\n",
       "0.731646    1\n",
       "0.157432    1\n",
       "0.698662    1\n",
       "0.173626    1\n",
       "0.651852    1\n",
       "0.755435    1\n",
       "0.585607    1\n",
       "0.660186    1\n",
       "0.806947    1\n",
       "0.742858    1\n",
       "0.429155    1\n",
       "0.557386    1\n",
       "0.702886    1\n",
       "0.650015    1\n",
       "0.667330    1\n",
       "0.678965    1\n",
       "0.551417    1\n",
       "0.187736    1\n",
       "0.481108    1\n",
       "0.611832    1\n",
       "0.639513    1\n",
       "0.440380    1\n",
       "0.751077    1\n",
       "0.621029    1\n",
       "0.672017    1\n",
       "0.540368    1\n",
       "0.681755    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['angle'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oU-PhskZPaHD"
   },
   "source": [
    "### 3e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "deXjPTO0TAiL"
   },
   "outputs": [],
   "source": [
    "predictions_df.to_csv('/home/apyba3/mobnetv3small_angleregression_withvalidation_withpetrudata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsp7UPIJQlKB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
