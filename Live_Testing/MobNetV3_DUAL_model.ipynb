{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/MobNetV3_DUAL_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fhwRSFoj6C_"
      },
      "source": [
        "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4V83PflfFkL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP6UczzNe1l2",
        "outputId": "ae829705-2f80-4e10-d2d4-ebdd2dbb6360"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-26 13:20:10.253059: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-26 13:20:12.923004: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-26 13:20:12.927248: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-03-26 13:20:25.599060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IF_vPVifaU9V"
      },
      "outputs": [],
      "source": [
        "# makes it so pd dfs aren't truncated\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "eocC68amnhEI"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_MvRvYnfIM5"
      },
      "source": [
        "# 1) DATA PRE-PROCESSING\n",
        "\n",
        "a) Load in labels + image file paths\n",
        "\n",
        "b) combine them into one dataframe\n",
        "\n",
        "c) EDA - spotted and removed erroneous label (speed = 1.42...)\n",
        "\n",
        "- `cleaned_df` is the cleaned df with a) b) c) completed\n",
        "\n",
        "d) convert images to numerical RGB feature maps - ML algorithms only understand numerical data\n",
        "\n",
        "e) Splitting data into training and validation sets\n",
        "\n",
        "f) data augmentation applied to training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU3TvBZ5hfhX"
      },
      "source": [
        "### 1a) load in labels + image file paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "outputs": [],
      "source": [
        "#labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # tylers file path\n",
        "#labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
        "labels_file_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_norm.csv' # tyler hpc file path (mlis2 cluster)\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "outputs": [],
      "source": [
        "#image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data' # bens hpc file path\n",
        "#image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
        "image_folder_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data' # tyler hpc file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oeuvmeZaGSC"
      },
      "source": [
        "Checking labels dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "2pi13TZ2aFhO",
        "outputId": "e9f839a6-2014-4a5a-d4e7-42459a692b24"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle  speed\n",
              "image_id               \n",
              "1         0.4375    0.0\n",
              "2         0.8125    1.0\n",
              "3         0.4375    1.0\n",
              "4         0.6250    1.0\n",
              "5         0.5000    0.0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puEjGoOJaRS4"
      },
      "source": [
        "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "a1suFSK7aWKH",
        "outputId": "3970958b-3bd3-484d-bd52-bc5d3f44f6f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                             image_file_paths\n",
              "image_id                                                                                     \n",
              "1         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/1.png\n",
              "2         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/2.png\n",
              "3         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3.png\n",
              "4         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/4.png\n",
              "5         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/5.png"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imagefilepaths_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjDdyYd6cMBE"
      },
      "source": [
        "### 1b) Combine labels and image file paths into one dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6NdbonzPcLKB"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
        "merged_df['speed'] = merged_df['speed'].round(6) # to get rid of floating point errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-VstirIAdAZi",
        "outputId": "fb11c6a0-53dc-41c1-a269-bf2fc7671b2b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "1         0.4375    0.0   \n",
              "2         0.8125    1.0   \n",
              "3         0.4375    1.0   \n",
              "4         0.6250    1.0   \n",
              "5         0.5000    0.0   \n",
              "\n",
              "                                                                             image_file_paths  \n",
              "image_id                                                                                       \n",
              "1         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/1.png  \n",
              "2         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/2.png  \n",
              "3         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3.png  \n",
              "4         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/4.png  \n",
              "5         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/5.png  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8MgNoL8nfBm2",
        "outputId": "26721bbd-39d3-4f89-899f-bc6e8318e4b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3139</th>\n",
              "      <td>0.750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3139.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>0.875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3140.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3142</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3142.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3143</th>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3143.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          angle  speed  \\\n",
              "image_id                 \n",
              "3139      0.750    1.0   \n",
              "3140      0.875    1.0   \n",
              "3142      0.625    0.0   \n",
              "3143      0.625    1.0   \n",
              "\n",
              "                                                                                image_file_paths  \n",
              "image_id                                                                                          \n",
              "3139      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3139.png  \n",
              "3140      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3140.png  \n",
              "3142      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3142.png  \n",
              "3143      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3143.png  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.loc[3139:3143]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7PCxqJbmXE6"
      },
      "source": [
        "The above cell shows that:\n",
        "\n",
        " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
        "\n",
        " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3OKLcn9u0Pz"
      },
      "source": [
        "### 1c) EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWQCQrR-oCps",
        "outputId": "d56046d2-b386-41c7-d8dd-89db8d7af903"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "angle\n",
              "0.7500    2123\n",
              "0.5000    2046\n",
              "0.6875    2007\n",
              "0.6250    1963\n",
              "0.5625    1609\n",
              "0.4375    1467\n",
              "0.8125    1147\n",
              "0.3750     428\n",
              "0.8750     301\n",
              "0.3125     213\n",
              "0.2500     104\n",
              "0.1250      99\n",
              "0.1875      98\n",
              "0.9375      65\n",
              "0.0000      60\n",
              "1.0000      35\n",
              "0.0625      28\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.value_counts('angle')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4pZ65pYvdqb"
      },
      "source": [
        "note: imbalance datset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJmG7jmNkE0k"
      },
      "source": [
        "identifying the row with the erroneous speed value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "wAQnbLLeiqy2",
        "outputId": "d9e7003a-7b2c-4f78-cdb3-85267c5eaf1b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3884</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3884.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle     speed  \\\n",
              "image_id                     \n",
              "3884      0.4375  1.428571   \n",
              "\n",
              "                                                                                image_file_paths  \n",
              "image_id                                                                                          \n",
              "3884      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3884.png  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df[merged_df['speed'] == 1.428571]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMZq41-RkLz0"
      },
      "source": [
        "we want to remove this row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TDMqIiOLSKGX",
        "outputId": "31a292c6-64a8-44de-970c-75a067509e2f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3882</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3882.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3883</th>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3883.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3885</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3885.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3886</th>\n",
              "      <td>0.7500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3886.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "3882      0.5625    1.0   \n",
              "3883      0.3750    0.0   \n",
              "3885      0.0000    1.0   \n",
              "3886      0.7500    1.0   \n",
              "\n",
              "                                                                                image_file_paths  \n",
              "image_id                                                                                          \n",
              "3882      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3882.png  \n",
              "3883      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3883.png  \n",
              "3885      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3885.png  \n",
              "3886      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3886.png  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_df = merged_df[merged_df['speed'] != 1.428571]\n",
        "cleaned_df.loc[3882:3886]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di6F6km_DBmj"
      },
      "source": [
        "### 1d) convert images to numerical RGB feature maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeeBTruNCQ96",
        "outputId": "cd2c3488-8e45-453d-c2a4-8c8e6af7fa80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-26 13:21:00.247244: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        }
      ],
      "source": [
        "def process_image(image_path, resized_shape=(224, 224)):\n",
        "    # Load and preprocess the image\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, resized_shape)\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image\n",
        "\n",
        "# Creating the dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (cleaned_df[\"image_file_paths\"], cleaned_df[\"angle\"], cleaned_df[\"speed\"])\n",
        ")  # Convert pandas DataFrame to a tf.data.Dataset\n",
        "\n",
        "# Apply the map function to process images and format labels\n",
        "dataset = dataset.map(\n",
        "    lambda image_path, angle, speed: (\n",
        "        process_image(image_path),  # Process the image\n",
        "        {\"classification\": angle, \"regression\": speed}  # Format labels as a dictionary\n",
        "    )\n",
        ")\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(len(cleaned_df))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUOlsWQeVlyC"
      },
      "source": [
        "lets check and see if what we have done works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md6U_i84SiK5"
      },
      "source": [
        "### 1e) Splitting data into training and validation sets (test set is already provided in kaggle data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yYlssPh5dxaO"
      },
      "outputs": [],
      "source": [
        "# 80-20 split\n",
        "\n",
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "validation_dataset = dataset.skip(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPUE6rd8cgQN",
        "outputId": "1de1b870-2e02-4a4f-ba4c-10d340bf9d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 344, validation size: 87\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train size: {train_size}, validation size: {dataset_size - train_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcPDFG91s-NS",
        "outputId": "b37d12d5-19b7-4fd9-964e-b6d6c929dc44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_SkipDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), {'classification': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'regression': TensorSpec(shape=(None,), dtype=tf.float64, name=None)})>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ujsjhMPSw4f"
      },
      "source": [
        "### 1f) Data augmentation applied to training set\n",
        "\n",
        "Flipping or rotating the image will render the angle labels incorrect so none of that was applied to the images for this regression task\n",
        "\n",
        "- Random Brightness Adjustment\n",
        "- Random Contrast Adjustment\n",
        "- Random Hue Adjustment\n",
        "- Random Saturation Adjustment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KPVCiRePlv2X"
      },
      "outputs": [],
      "source": [
        "def augment_image(image, label):\n",
        "  seed = (6, 9)\n",
        "  image = tf.image.stateless_random_brightness(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_contrast(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_saturation(image, 0.8, 1.2, seed)\n",
        "  return image, label\n",
        "\n",
        "augmented_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.concatenate(augmented_dataset)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(cleaned_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmetmzNHTWzU"
      },
      "source": [
        "# 2) Model Building - MobileNetV3Large Transfer Learning\n",
        "\n",
        "a) Set up model architecture\n",
        "\n",
        "b) define training step\n",
        "\n",
        "c) training the model on the training set\n",
        "\n",
        "d) fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48RHLVshdX5L"
      },
      "source": [
        "### 2a) Set up model architecture\n",
        "\n",
        "- MobileNetV2 to learn lower level features\n",
        "- global average pooling layer\n",
        "- drop out layer\n",
        "- dense layer with sigmoid activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh1-U-VYeN9n",
        "outputId": "1d033cde-7ee7-48ec-8283-e8aeebbb38be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " MobilenetV3large (Function  (None, 7, 7, 960)            2996352   ['input_2[0][0]']             \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 960)                  0         ['MobilenetV3large[0][0]']    \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 960)                  0         ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  246016    ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 256)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 64)                   8256      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 64)                   0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 32)                   2080      ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " classification (Dense)      (None, 1)                    33        ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " regression (Dense)          (None, 1)                    33        ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3285666 (12.53 MB)\n",
            "Trainable params: 3261266 (12.44 MB)\n",
            "Non-trainable params: 24400 (95.31 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " MobilenetV3large (Function  (None, 7, 7, 960)            2996352   ['input_2[0][0]']             \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 960)                  0         ['MobilenetV3large[0][0]']    \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 960)                  0         ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  246016    ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 256)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 64)                   8256      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 64)                   0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 32)                   2080      ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " classification (Dense)      (None, 1)                    33        ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " regression (Dense)          (None, 1)                    33        ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3285666 (12.53 MB)\n",
            "Trainable params: 289314 (1.10 MB)\n",
            "Non-trainable params: 2996352 (11.43 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "input_layer = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = mbnet(input_layer)\n",
        "\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "\n",
        "\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "#split outputs to predict speed and angle\n",
        "classification_output = tf.keras.layers.Dense(num_classes, activation='sigmoid', name=\"classification\")(x)\n",
        "regression_output = tf.keras.layers.Dense(1, activation='linear', name=\"regression\")(x)\n",
        "\n",
        "#combine both outputs\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=[classification_output, regression_output])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss={'classification': 'binary_crossentropy', 'regression': 'mse'},\n",
        "              metrics={'classification': 'accuracy', 'regression': 'mse'})\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.build(input_layer)\n",
        "\n",
        "mbnet.trainable = False\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUMefNeTpDWF"
      },
      "source": [
        "### 2c) Training the model on the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uE2K4gVQedXN",
        "outputId": "352c2bef-8333-4714-bd09-6a3d6bb961c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-26 13:21:31.025419: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 2730 of 13792\n",
            "2025-03-26 13:21:40.981761: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 5862 of 13792\n",
            "2025-03-26 13:21:50.985681: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 9284 of 13792\n",
            "2025-03-26 13:22:00.978431: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 12700 of 13792\n",
            "2025-03-26 13:22:04.136077: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n",
            "2025-03-26 13:22:04.142229: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 1 of 13792\n",
            "2025-03-26 13:22:04.146962: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 2 of 13792\n",
            "2025-03-26 13:22:04.151659: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 3 of 13792\n",
            "2025-03-26 13:22:04.156416: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 4 of 13792\n",
            "2025-03-26 13:22:07.791874: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "688/688 [==============================] - 1202s 2s/step - loss: 0.6924 - classification_loss: 0.6453 - regression_loss: 0.0471 - classification_accuracy: 0.0055 - regression_mse: 0.0471 - val_loss: 0.8554 - val_classification_loss: 0.6690 - val_regression_loss: 0.1865 - val_classification_accuracy: 0.0029 - val_regression_mse: 0.1865\n",
            "Epoch 2/5\n",
            " 15/688 [..............................] - ETA: 21:05 - loss: 0.6661 - classification_loss: 0.6418 - regression_loss: 0.0243 - classification_accuracy: 0.0125 - regression_mse: 0.0243"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=5,\n",
        "                    batch_size=32,\n",
        "                    validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiHy6opSP2sQ"
      },
      "outputs": [],
      "source": [
        "#model.save_weights('/home/apyba3/car_frozen_regression.weights.h5')\n",
        "model.save_weights('/home/ppytr13/car_frozen_regression.weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpLHyw20P93U"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session() #Clear keras session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENHbUvQdvyFe"
      },
      "source": [
        "### 2d) fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0ek_ytyw0KB"
      },
      "source": [
        "rebuild model after clearing keras session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuKL3X-QP-Ax"
      },
      "outputs": [],
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "input_layer = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = mbnet(input_layer)\n",
        "\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "\n",
        "\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "#split outputs to predict speed and angle\n",
        "classification_output = tf.keras.layers.Dense(num_classes, activation='sigmoid', name=\"classification\")(x)\n",
        "regression_output = tf.keras.layers.Dense(1, activation='linear', name=\"regression\")(x)\n",
        "\n",
        "#combine both outputs\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=[classification_output, regression_output])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss={'classification': 'binary_crossentropy', 'regression': 'mse'},\n",
        "              metrics={'classification': 'accuracy', 'regression': 'mse'})\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.build(input_layer)\n",
        "\n",
        "mbnet.trainable = True\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oAenzEiP-C-"
      },
      "outputs": [],
      "source": [
        "#model.load_weights('/home/apyba3/car_frozen_regression.weights.h5')\n",
        "model.load_weights('/home/ppytr13/car_frozen_regression.weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWDtRxBow89t"
      },
      "source": [
        "Set up fine-tuning training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvmWxC1fP-Jd"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=5,\n",
        "                    batch_size=32,\n",
        "                    validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O14u6175RLjA"
      },
      "outputs": [],
      "source": [
        "#model.save_weights('/home/apyba3/car_unfrozen_regression.weights.h5')\n",
        "model.save_weights('/home/ppytr13/car_unfrozen_regression.weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCbo4VcLxLgQ"
      },
      "source": [
        "# 3) Test-Set Predictions\n",
        "\n",
        "a) load in test data\n",
        "\n",
        "b) convert test images to numerical RGB feature maps\n",
        "\n",
        "c) generate predictions on the test set\n",
        "\n",
        "d) correctly format the predictions into a pandas dataframe\n",
        "\n",
        "e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnygDJsKxYhA"
      },
      "source": [
        "### 3a) load in test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-e59lQQRXKK"
      },
      "outputs": [],
      "source": [
        "#image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data'\n",
        "#image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data'\n",
        "image_folder_path = '/home/ppytr13/machine-learning-in-science-ii-2025/test_data/test_data'\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'\n",
        "imagefilepaths_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-9i5trTyDTf"
      },
      "source": [
        "### 3b) convert test images to numerical RGB feature maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hT_c1s5TAR-"
      },
      "outputs": [],
      "source": [
        "def process_image_no_label(image_path, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
        "    image = tf.image.resize(image, resized_shape)  # Resize to uniform shape\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((imagefilepaths_df[\"image_file_paths\"]))\n",
        "\n",
        "test_dataset = test_dataset.map(process_image_no_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gobnK7PhyLa2"
      },
      "source": [
        "### 3c) generate predictions on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtqcOFr7TAXa"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_dataset.take(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT1LJxHTPeQT"
      },
      "source": [
        "### 3d) correctly format the predictions into a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFVWGi04fza7"
      },
      "outputs": [],
      "source": [
        "predictions_array = np.concatenate([predictions[0], predictions[1]], axis=1)\n",
        "predictions_df = pd.DataFrame(predictions_array, columns=['angle', 'speed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnO0K1rReHOT"
      },
      "outputs": [],
      "source": [
        "predictions_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij0Oo0vJFGxW"
      },
      "outputs": [],
      "source": [
        "predictions_df.loc[predictions_df['speed'] > 0.5, 'speed'] = 1\n",
        "predictions_df.loc[predictions_df['speed'] <= 0.5, 'speed'] = 0\n",
        "predictions_df['speed'] = predictions_df['speed'].astype(int)\n",
        "predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0Ss_kgSYsKY9"
      },
      "outputs": [],
      "source": [
        "predictions_df['angle'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU-PhskZPaHD"
      },
      "source": [
        "### 3e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deXjPTO0TAiL"
      },
      "outputs": [],
      "source": [
        "#predictions_df.to_csv('/home/apyba3/mbnetv3_angleregression_predictions.csv')\n",
        "predictions_df.to_csv('/home/ppytr13/mbnetv3_dual_predictions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tsp7UPIJQlKB"
      },
      "outputs": [],
      "source": [
        "model = '/home/apyba3/PICAR-autopilot/autopilot/models/BenTyler_MLiSards/finetuned_50epochs_mobnetv3small_classification_model.keras'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anEyLOllF6eY"
      },
      "source": [
        "## instead - convert to tf lite (chatgpt code - not tested yet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpc1z_n3kb/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpc1z_n3kb/assets\n",
            "2025-05-01 12:16:06.757117: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-05-01 12:16:06.757148: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-05-01 12:16:06.757352: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpc1z_n3kb\n",
            "2025-05-01 12:16:06.791948: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-05-01 12:16:06.791982: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpc1z_n3kb\n",
            "2025-05-01 12:16:06.945813: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-05-01 12:16:08.362840: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpc1z_n3kb\n",
            "2025-05-01 12:16:08.805196: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 2047843 microseconds.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized TFLite regression model saved at: /home/apyba3/PICAR-autopilot/autopilot/models/BenTyler_MLiSards/tflite_finetuned_mobnetv3small_regression.tflite\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "model_dir = '/home/apyba3/PICAR-autopilot/autopilot/models/BenTyler_MLiSards'\n",
        "regression_model_path = os.path.join(model_dir, 'regression_finetuned_50epochs_mobnetv3small_model.keras')\n",
        "tflite_output_path = os.path.join(model_dir, 'tflite_finetuned_mobnetv3small_regression.tflite')\n",
        "\n",
        "# Load the regression model\n",
        "regression_model = tf.keras.models.load_model(regression_model_path)\n",
        "\n",
        "# Define the converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(regression_model)\n",
        "\n",
        "# Enable default optimizations\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Use FP16 for smaller model size and faster inference\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model as a TFLite file\n",
        "with open(tflite_output_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Optimized TFLite regression model saved at:\", tflite_output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7zekr68a/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7zekr68a/assets\n",
            "2025-05-01 12:11:46.027086: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-05-01 12:11:46.027119: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-05-01 12:11:46.027322: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp7zekr68a\n",
            "2025-05-01 12:11:46.055983: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-05-01 12:11:46.056020: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp7zekr68a\n",
            "2025-05-01 12:11:46.195035: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-05-01 12:11:47.568531: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp7zekr68a\n",
            "2025-05-01 12:11:48.001448: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 1974124 microseconds.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized TFLite model saved at: /home/apyba3/PICAR-autopilot/autopilot/models/BenTyler_MLiSards/tflite_finetuned_mbnetv3small_classification.tflite\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "model_dir = '/home/apyba3/PICAR-autopilot/autopilot/models/BenTyler_MLiSards'\n",
        "model_path = os.path.join(model_dir, 'finetuned_50epochs_mobnetv3small_classification_model.keras')\n",
        "tflite_output_path = os.path.join(model_dir, 'tflite_finetuned_mbnetv3small_classification.tflite')\n",
        "\n",
        "# Load the model\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Define the converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Enable default optimizations\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Use FP16 for smaller model size and faster inference\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model as a TFLite file\n",
        "with open(tflite_output_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Optimized TFLite model saved at:\", tflite_output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'call'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m converter\u001b[38;5;241m.\u001b[39mtarget_spec\u001b[38;5;241m.\u001b[39msupported_types \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mfloat16]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Convert the model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Save the model as a TFLite file\u001b[39;00m\n\u001b[1;32m     21\u001b[0m tflite_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/apyba3/mobnetv3small_dual_model.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/car_env/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:1065\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1064\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1065\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/car_env/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:1042\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[1;32m   1041\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[0;32m-> 1042\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
            "File \u001b[0;32m~/anaconda3/envs/car_env/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:1531\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[1;32m   1528\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n\u001b[1;32m   1530\u001b[0m graph_def, input_tensors, output_tensors, frozen_func \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1531\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_freeze_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1532\u001b[0m )\n\u001b[1;32m   1534\u001b[0m graph_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_tf_model(\n\u001b[1;32m   1535\u001b[0m     graph_def, input_tensors, output_tensors, frozen_func\n\u001b[1;32m   1536\u001b[0m )\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(TFLiteKerasModelConverterV2, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[1;32m   1539\u001b[0m     graph_def, input_tensors, output_tensors\n\u001b[1;32m   1540\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/envs/car_env/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n\u001b[0;32m--> 215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/car_env/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
            "File \u001b[0;32m~/anaconda3/envs/car_env/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:1468\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._freeze_keras_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1462\u001b[0m input_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;66;03m# If the model's call is not a `tf.function`, then we need to first get its\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;66;03m# input signature from `model_input_signature` method. We can't directly\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;66;03m# call `trace_model_call` because otherwise the batch dimension is set\u001b[39;00m\n\u001b[1;32m   1466\u001b[0m \u001b[38;5;66;03m# to None.\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;66;03m# Once we have better support for dynamic shapes, we can remove this.\u001b[39;00m\n\u001b[0;32m-> 1468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m, _def_function\u001b[38;5;241m.\u001b[39mFunction):\n\u001b[1;32m   1469\u001b[0m   \u001b[38;5;66;03m# Pass `keep_original_batch_size=True` will ensure that we get an input\u001b[39;00m\n\u001b[1;32m   1470\u001b[0m   \u001b[38;5;66;03m# signature including the batch dimension specified by the user.\u001b[39;00m\n\u001b[1;32m   1471\u001b[0m   \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[1;32m   1472\u001b[0m   input_signature \u001b[38;5;241m=\u001b[39m _model_input_signature(\n\u001b[1;32m   1473\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keras_model, keep_original_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m   )\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'call'"
          ]
        }
      ],
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# model = '/home/apyba3/PICAR-autopilot/autopilot/models/BenTyler_MLiSards/finetuned_50epochs_mobnetv3small_classification_model.keras'\n",
        "\n",
        "# # Define the converter\n",
        "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# # Enable default optimizations\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# # Specify fixed input shape\n",
        "# converter._experimental_fixed_input_shape = {\"serving_default_input\": [1, 300, 244, 3]}  # Batch size 1\n",
        "\n",
        "# # Use FP16 for smaller model size and faster inference\n",
        "# converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "# # Convert the model\n",
        "# tflite_model = converter.convert()\n",
        "\n",
        "# # Save the model as a TFLite file\n",
        "# tflite_model_path = '/home/apyba3/mobnetv3small_dual_model.tflite'\n",
        "# with open(tflite_model_path, 'wb') as f:\n",
        "#     f.write(tflite_model)\n",
        "\n",
        "# print(\"Optimized TFLite model saved at:\", tflite_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vv1ojQPF-LD"
      },
      "outputs": [],
      "source": [
        "# Define the converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Enable optimizations for smaller size and faster inference\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# If your inputs have fixed shapes, specify them for further optimization\n",
        "converter.target_spec.supported_types = [tf.float16]  # Optional: FP16 for faster inference\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_path = '/home/ppytr13/mbnetv3_dual_model.tflite'\n",
        "\n",
        "# Save the model as a TFLite file\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "car_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
