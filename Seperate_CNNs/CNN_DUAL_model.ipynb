{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/CNN_DUAL_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fhwRSFoj6C_"
      },
      "source": [
        "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4V83PflfFkL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kP6UczzNe1l2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IF_vPVifaU9V"
      },
      "outputs": [],
      "source": [
        "# makes it so pd dfs aren't truncated\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "eocC68amnhEI"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_MvRvYnfIM5"
      },
      "source": [
        "# 1) DATA PRE-PROCESSING\n",
        "\n",
        "a) Load in labels + image file paths\n",
        "\n",
        "b) combine them into one dataframe\n",
        "\n",
        "c) EDA - spotted and removed erroneous label (speed = 1.42...)\n",
        "\n",
        "- `cleaned_df` is the cleaned df with a) b) c) completed\n",
        "\n",
        "d) convert images to numerical RGB feature maps - ML algorithms only understand numerical data\n",
        "\n",
        "e) Splitting data into training and validation sets\n",
        "\n",
        "f) data augmentation applied to training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU3TvBZ5hfhX"
      },
      "source": [
        "### 1a) load in labels + image file paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "outputs": [],
      "source": [
        "#labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # tylers file path\n",
        "#labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
        "labels_file_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_norm.csv' # tyler hpc file path (mlis2 cluster)\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "outputs": [],
      "source": [
        "#image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data' # bens hpc file path\n",
        "#image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
        "image_folder_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data' # tyler hpc file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oeuvmeZaGSC"
      },
      "source": [
        "Checking labels dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "2pi13TZ2aFhO",
        "outputId": "7ca9f5f8-c089-4e25-9807-dfd140381483"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle  speed\n",
              "image_id               \n",
              "1         0.4375    0.0\n",
              "2         0.8125    1.0\n",
              "3         0.4375    1.0\n",
              "4         0.6250    1.0\n",
              "5         0.5000    0.0"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puEjGoOJaRS4"
      },
      "source": [
        "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "a1suFSK7aWKH",
        "outputId": "18fac753-1f24-413b-daad-1971eb2f3b15"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                             image_file_paths\n",
              "image_id                                                                                     \n",
              "1         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/1.png\n",
              "2         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/2.png\n",
              "3         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3.png\n",
              "4         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/4.png\n",
              "5         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/5.png"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imagefilepaths_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjDdyYd6cMBE"
      },
      "source": [
        "### 1b) Combine labels and image file paths into one dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6NdbonzPcLKB"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
        "merged_df['speed'] = merged_df['speed'].round(6) # to get rid of floating point errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-VstirIAdAZi",
        "outputId": "8e931623-be6a-4846-f7ba-05f41d1e9ced"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "1         0.4375    0.0   \n",
              "2         0.8125    1.0   \n",
              "3         0.4375    1.0   \n",
              "4         0.6250    1.0   \n",
              "5         0.5000    0.0   \n",
              "\n",
              "                                                                             image_file_paths  \n",
              "image_id                                                                                       \n",
              "1         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/1.png  \n",
              "2         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/2.png  \n",
              "3         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3.png  \n",
              "4         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/4.png  \n",
              "5         /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/5.png  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8MgNoL8nfBm2",
        "outputId": "2289083b-3ece-4234-ee87-e8735cf4dc1e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3139</th>\n",
              "      <td>0.750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3139.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>0.875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3140.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3142</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3142.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3143</th>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3143.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          angle  speed  \\\n",
              "image_id                 \n",
              "3139      0.750    1.0   \n",
              "3140      0.875    1.0   \n",
              "3142      0.625    0.0   \n",
              "3143      0.625    1.0   \n",
              "\n",
              "                                                                                image_file_paths  \n",
              "image_id                                                                                          \n",
              "3139      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3139.png  \n",
              "3140      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3140.png  \n",
              "3142      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3142.png  \n",
              "3143      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3143.png  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.loc[3139:3143]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7PCxqJbmXE6"
      },
      "source": [
        "The above cell shows that:\n",
        "\n",
        " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
        "\n",
        " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3OKLcn9u0Pz"
      },
      "source": [
        "### 1c) EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWQCQrR-oCps",
        "outputId": "38100106-c050-4395-dcd2-727998d2f17a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "angle\n",
              "0.7500    2123\n",
              "0.5000    2046\n",
              "0.6875    2007\n",
              "0.6250    1963\n",
              "0.5625    1609\n",
              "0.4375    1467\n",
              "0.8125    1147\n",
              "0.3750     428\n",
              "0.8750     301\n",
              "0.3125     213\n",
              "0.2500     104\n",
              "0.1250      99\n",
              "0.1875      98\n",
              "0.9375      65\n",
              "0.0000      60\n",
              "1.0000      35\n",
              "0.0625      28\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.value_counts('angle')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4pZ65pYvdqb"
      },
      "source": [
        "note: imbalance datset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJmG7jmNkE0k"
      },
      "source": [
        "identifying the row with the erroneous speed value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "wAQnbLLeiqy2",
        "outputId": "295dffb7-4737-4979-effb-cb653880fa07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3884</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3884.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle     speed  \\\n",
              "image_id                     \n",
              "3884      0.4375  1.428571   \n",
              "\n",
              "                                                                                image_file_paths  \n",
              "image_id                                                                                          \n",
              "3884      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3884.png  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df[merged_df['speed'] == 1.428571]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMZq41-RkLz0"
      },
      "source": [
        "we want to remove this row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TDMqIiOLSKGX",
        "outputId": "cc38c0a4-9f6c-41dc-f288-d0e4a138866c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3882</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3882.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3883</th>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3883.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3885</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3885.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3886</th>\n",
              "      <td>0.7500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3886.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "3882      0.5625    1.0   \n",
              "3883      0.3750    0.0   \n",
              "3885      0.0000    1.0   \n",
              "3886      0.7500    1.0   \n",
              "\n",
              "                                                                                image_file_paths  \n",
              "image_id                                                                                          \n",
              "3882      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3882.png  \n",
              "3883      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3883.png  \n",
              "3885      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3885.png  \n",
              "3886      /home/ppytr13/machine-learning-in-science-ii-2025/training_data/training_data/3886.png  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_df = merged_df[merged_df['speed'] != 1.428571]\n",
        "cleaned_df.loc[3882:3886]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di6F6km_DBmj"
      },
      "source": [
        "### 1d) convert images to numerical RGB feature maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oeeBTruNCQ96"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def process_image(image_path, label, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, resized_shape)\n",
        "    image = image / 255.0  # Normalise pixel values to [0,1]\n",
        "    return image, label\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"speed\"])) # Convert pd df into a tf ds\n",
        "\n",
        "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(len(cleaned_df))\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def process_image(image_path, label, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, resized_shape)\n",
        "    image = image / 255.0  # Normalise pixel values to [0,1]\n",
        "    return image, label\n",
        "\n",
        "dataset2 = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"speed\"])) # Convert pd df into a tf ds\n",
        "\n",
        "dataset2 = dataset2.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset2 = dataset2.cache()\n",
        "dataset2 = dataset2.shuffle(len(cleaned_df))\n",
        "dataset2 = dataset2.batch(BATCH_SIZE)\n",
        "dataset2 = dataset2.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUOlsWQeVlyC"
      },
      "source": [
        "lets check and see if what we have done works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md6U_i84SiK5"
      },
      "source": [
        "### 1e) Splitting data into training and validation sets (test set is already provided in kaggle data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYlssPh5dxaO"
      },
      "outputs": [],
      "source": [
        "# 80-20 split\n",
        "\n",
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "validation_dataset = dataset.skip(train_size)\n",
        "\n",
        "dataset_size2 = tf.data.experimental.cardinality(dataset2).numpy()\n",
        "train_size2 = int(0.8 * dataset_size2)\n",
        "\n",
        "train_dataset2 = dataset.take(train_size2)\n",
        "validation_dataset2 = dataset.skip(train_size2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPUE6rd8cgQN",
        "outputId": "d6107991-7af9-4bf5-e020-56a8d40456ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 344, validation size: 87\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train size: {train_size}, validation size: {dataset_size - train_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcPDFG91s-NS",
        "outputId": "2a200ba4-26c3-4d33-af2f-010b8d010fea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_SkipDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ujsjhMPSw4f"
      },
      "source": [
        "### 1f) Data augmentation applied to training set\n",
        "\n",
        "Flipping or rotating the image will render the angle labels incorrect so none of that was applied to the images for this regression task\n",
        "\n",
        "- Random Brightness Adjustment\n",
        "- Random Contrast Adjustment\n",
        "- Random Hue Adjustment\n",
        "- Random Saturation Adjustment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPVCiRePlv2X"
      },
      "outputs": [],
      "source": [
        "def augment_image(image, label):\n",
        "  seed = (6, 9)\n",
        "  image = tf.image.stateless_random_brightness(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_contrast(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_saturation(image, 0.8, 1.2, seed)\n",
        "  return image, label\n",
        "\n",
        "augmented_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.concatenate(augmented_dataset)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(cleaned_df))\n",
        "\n",
        "augmented_dataset2 = train_dataset2.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset2 = train_dataset2.concatenate(augmented_dataset2)\n",
        "train_dataset2 = train_dataset2.shuffle(buffer_size=len(cleaned_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmetmzNHTWzU"
      },
      "source": [
        "# 2) Model Building - MobileNetV3Large Transfer Learning\n",
        "\n",
        "a) Set up model architecture\n",
        "\n",
        "b) define training step\n",
        "\n",
        "c) training the model on the training set\n",
        "\n",
        "d) fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48RHLVshdX5L"
      },
      "source": [
        "### 2a) Set up classification architecture\n",
        "\n",
        "- MobileNetV2 to learn lower level features\n",
        "- global average pooling layer\n",
        "- drop out layer\n",
        "- dense layer with sigmoid activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "dropoutrate = 0.2\n",
        "input_shape = (224,224,3)\n",
        "num_classes = 1 # we're only predicting the prob of the positive class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02gR58Z7zYqX",
        "outputId": "e1beef06-1e6f-4601-c5b5-b3b6c2ebf2c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 111, 111, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 32)                0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               4224      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " classification (Dense)      (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15489 (60.50 KB)\n",
            "Trainable params: 15489 (60.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_layer = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x) #experiment with removing this\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "# Only the classification output\n",
        "classification_output = tf.keras.layers.Dense(num_classes, activation='sigmoid', name=\"classification\")(x)\n",
        "\n",
        "# Model with just the classification output\n",
        "class_model = tf.keras.Model(inputs=input_layer, outputs=classification_output)\n",
        "\n",
        "class_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics='accuracy')\n",
        "\n",
        "class_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUMefNeTpDWF"
      },
      "source": [
        "### 2c) Training the model on the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uE2K4gVQedXN",
        "outputId": "617bce02-d694-4979-f97a-48d54e602452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 13:57:39.451676: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 2627 of 13792\n",
            "2025-05-07 13:57:49.458513: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 5780 of 13792\n",
            "2025-05-07 13:57:59.451430: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 9184 of 13792\n",
            "2025-05-07 13:58:09.457971: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 12590 of 13792\n",
            "2025-05-07 13:58:12.589149: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n",
            "2025-05-07 13:58:12.594886: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 1 of 13792\n",
            "2025-05-07 13:58:12.600633: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 2 of 13792\n",
            "2025-05-07 13:58:12.607679: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 3 of 13792\n",
            "2025-05-07 13:58:12.613136: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 4 of 13792\n",
            "2025-05-07 13:58:17.247119: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "688/688 [==============================] - 230s 264ms/step - loss: 0.5585 - accuracy: 0.7566 - val_loss: 0.5663 - val_accuracy: 0.7507\n",
            "Epoch 2/50\n",
            "688/688 [==============================] - 178s 253ms/step - loss: 0.5580 - accuracy: 0.7547 - val_loss: 0.5596 - val_accuracy: 0.7532\n",
            "Epoch 3/50\n",
            "688/688 [==============================] - 173s 246ms/step - loss: 0.5577 - accuracy: 0.7549 - val_loss: 0.5595 - val_accuracy: 0.7550\n",
            "Epoch 4/50\n",
            "688/688 [==============================] - 172s 245ms/step - loss: 0.5587 - accuracy: 0.7537 - val_loss: 0.5628 - val_accuracy: 0.7507\n",
            "Epoch 5/50\n",
            "688/688 [==============================] - 171s 244ms/step - loss: 0.5566 - accuracy: 0.7557 - val_loss: 0.5501 - val_accuracy: 0.7611\n",
            "Epoch 6/50\n",
            "688/688 [==============================] - 181s 257ms/step - loss: 0.5587 - accuracy: 0.7536 - val_loss: 0.5718 - val_accuracy: 0.7421\n",
            "Epoch 7/50\n",
            "688/688 [==============================] - 172s 245ms/step - loss: 0.5560 - accuracy: 0.7560 - val_loss: 0.5779 - val_accuracy: 0.7371\n",
            "Epoch 8/50\n",
            "688/688 [==============================] - 173s 246ms/step - loss: 0.5594 - accuracy: 0.7530 - val_loss: 0.5545 - val_accuracy: 0.7575\n",
            "Epoch 9/50\n",
            "688/688 [==============================] - 172s 245ms/step - loss: 0.5606 - accuracy: 0.7518 - val_loss: 0.5450 - val_accuracy: 0.7654\n",
            "Epoch 10/50\n",
            "688/688 [==============================] - 173s 246ms/step - loss: 0.5549 - accuracy: 0.7570 - val_loss: 0.5828 - val_accuracy: 0.7320\n",
            "Epoch 11/50\n",
            "688/688 [==============================] - 173s 246ms/step - loss: 0.5594 - accuracy: 0.7529 - val_loss: 0.5607 - val_accuracy: 0.7518\n",
            "Epoch 12/50\n",
            "688/688 [==============================] - 172s 244ms/step - loss: 0.5598 - accuracy: 0.7525 - val_loss: 0.5494 - val_accuracy: 0.7615\n",
            "Epoch 13/50\n",
            "688/688 [==============================] - 172s 245ms/step - loss: 0.5579 - accuracy: 0.7541 - val_loss: 0.5651 - val_accuracy: 0.7475\n",
            "Epoch 14/50\n",
            "688/688 [==============================] - 173s 246ms/step - loss: 0.5587 - accuracy: 0.7535 - val_loss: 0.5567 - val_accuracy: 0.7550\n",
            "Epoch 15/50\n",
            "688/688 [==============================] - 171s 244ms/step - loss: 0.5568 - accuracy: 0.7551 - val_loss: 0.5477 - val_accuracy: 0.7629\n",
            "Epoch 16/50\n",
            "688/688 [==============================] - 172s 245ms/step - loss: 0.5576 - accuracy: 0.7545 - val_loss: 0.5691 - val_accuracy: 0.7439\n",
            "Epoch 17/50\n",
            "688/688 [==============================] - 171s 243ms/step - loss: 0.5589 - accuracy: 0.7533 - val_loss: 0.5620 - val_accuracy: 0.7504\n",
            "Epoch 18/50\n",
            "688/688 [==============================] - 172s 244ms/step - loss: 0.5593 - accuracy: 0.7530 - val_loss: 0.5527 - val_accuracy: 0.7586\n",
            "Epoch 19/50\n",
            "688/688 [==============================] - 174s 247ms/step - loss: 0.5572 - accuracy: 0.7549 - val_loss: 0.5568 - val_accuracy: 0.7550\n",
            "Epoch 20/50\n",
            "688/688 [==============================] - 172s 244ms/step - loss: 0.5575 - accuracy: 0.7546 - val_loss: 0.5683 - val_accuracy: 0.7446\n",
            "Epoch 21/50\n",
            "688/688 [==============================] - 172s 244ms/step - loss: 0.5573 - accuracy: 0.7548 - val_loss: 0.5659 - val_accuracy: 0.7468\n",
            "Epoch 22/50\n",
            "688/688 [==============================] - 171s 244ms/step - loss: 0.5574 - accuracy: 0.7546 - val_loss: 0.5465 - val_accuracy: 0.7640\n",
            "Epoch 23/50\n",
            "688/688 [==============================] - 172s 244ms/step - loss: 0.5554 - accuracy: 0.7565 - val_loss: 0.5531 - val_accuracy: 0.7583\n",
            "Epoch 24/50\n",
            "688/688 [==============================] - 173s 247ms/step - loss: 0.5579 - accuracy: 0.7542 - val_loss: 0.5524 - val_accuracy: 0.7590\n",
            "Epoch 25/50\n",
            "688/688 [==============================] - 172s 245ms/step - loss: 0.5594 - accuracy: 0.7528 - val_loss: 0.5679 - val_accuracy: 0.7450\n",
            "Epoch 26/50\n",
            "688/688 [==============================] - 172s 245ms/step - loss: 0.5594 - accuracy: 0.7530 - val_loss: 0.5588 - val_accuracy: 0.7536\n",
            "Epoch 27/50\n",
            "688/688 [==============================] - 172s 245ms/step - loss: 0.5610 - accuracy: 0.7513 - val_loss: 0.5416 - val_accuracy: 0.7701\n",
            "Epoch 28/50\n",
            "688/688 [==============================] - 172s 245ms/step - loss: 0.5561 - accuracy: 0.7557 - val_loss: 0.5618 - val_accuracy: 0.7507\n",
            "Epoch 29/50\n",
            "688/688 [==============================] - 173s 246ms/step - loss: 0.5591 - accuracy: 0.7532 - val_loss: 0.5727 - val_accuracy: 0.7410\n",
            "Epoch 30/50\n",
            "688/688 [==============================] - 172s 245ms/step - loss: 0.5553 - accuracy: 0.7565 - val_loss: 0.5551 - val_accuracy: 0.7565\n",
            "Epoch 31/50\n",
            "688/688 [==============================] - 183s 261ms/step - loss: 0.5591 - accuracy: 0.7531 - val_loss: 0.5484 - val_accuracy: 0.7629\n",
            "Epoch 32/50\n",
            "397/688 [================>.............] - ETA: 1:07 - loss: 0.5580 - accuracy: 0.7541"
          ]
        }
      ],
      "source": [
        "history = class_model.fit(train_dataset,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiHy6opSP2sQ"
      },
      "outputs": [],
      "source": [
        "#model.save_weights('/home/apyba3/cnn.weights.h5')\n",
        "#model.save_weights('/home/ppytr13/cnn.weights.h5')\n",
        "class_model.save('/home/ppytr13/PICAR-autopilot-1/Seperate_CNNs/class_cnn.weights.h5')\n",
        "class_model.save('/home/ppytr13/PICAR-autopilot-1/Seperate_CNNs/class_cnn.weights.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_layer = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x) #experiment with removing this\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(dropoutrate)(x)\n",
        "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "# Only the classification output\n",
        "regression_output = tf.keras.layers.Dense(num_classes, activation='linear', name=\"regression\")(x)\n",
        "\n",
        "# Model with just the classification output\n",
        "reg_model = tf.keras.Model(inputs=input_layer, outputs=regression_output)\n",
        "\n",
        "reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics='mse')\n",
        "\n",
        "reg_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCbo4VcLxLgQ"
      },
      "source": [
        "# 3) Test-Set Predictions\n",
        "\n",
        "a) load in test data\n",
        "\n",
        "b) convert test images to numerical RGB feature maps\n",
        "\n",
        "c) generate predictions on the test set\n",
        "\n",
        "d) correctly format the predictions into a pandas dataframe\n",
        "\n",
        "e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = reg_model.fit(train_dataset2,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=validation_dataset2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reg_model.save('/home/ppytr13/PICAR-autopilot-1/Seperate_CNNs/reg_cnn.weights.h5')\n",
        "reg_model.save('/home/ppytr13/PICAR-autopilot-1/Seperate_CNNs/reg_cnn.weights.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnygDJsKxYhA"
      },
      "source": [
        "### 3a) load in test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-9i5trTyDTf"
      },
      "source": [
        "### 3b) convert test images to numerical RGB feature maps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gobnK7PhyLa2"
      },
      "source": [
        "### 3c) generate predictions on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT1LJxHTPeQT"
      },
      "source": [
        "### 3d) correctly format the predictions into a pandas dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU-PhskZPaHD"
      },
      "source": [
        "### 3e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deXjPTO0TAiL"
      },
      "outputs": [],
      "source": [
        "#predictions_df.to_csv('/home/apyba3/mbnetv3_angleregression_predictions.csv')\n",
        "#predictions_df.to_csv('/home/ppytr13/cnn_dual_predictions.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anEyLOllF6eY"
      },
      "source": [
        "## instead - convert to tf lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vv1ojQPF-LD",
        "outputId": "1d0ddd0a-4028-4fcd-fdc6-f2d57a482e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpqs37wijn/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpqs37wijn/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized TFLite model saved at: /home/ppytr13/PICAR-autopilot-1/autopilot/models/BenTyler_Dual_head/CNN.tflite\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-01 16:21:40.894066: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-05-01 16:21:40.894090: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-05-01 16:21:40.894247: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpqs37wijn\n",
            "2025-05-01 16:21:40.895676: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-05-01 16:21:40.895693: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpqs37wijn\n",
            "2025-05-01 16:21:40.900173: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-05-01 16:21:40.948508: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpqs37wijn\n",
            "2025-05-01 16:21:40.963207: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 68960 microseconds.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Enable default optimizations\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Specify fixed input shape\n",
        "converter._experimental_fixed_input_shape = {\"serving_default_input\": [1, 224, 224, 3]}  # Batch size 1\n",
        "\n",
        "# Use FP16 for smaller model size and faster inference\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model as a TFLite file\n",
        "tflite_model_path = '/home/ppytr13/PICAR-autopilot-1/autopilot/models/BenTyler_Dual_head/CNN.tflite'\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Optimized TFLite model saved at:\", tflite_model_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "car_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
