{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/petru_dataResNet50_regression_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
      ],
      "metadata": {
        "id": "-fhwRSFoj6C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "g4V83PflfFkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP6UczzNe1l2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "print(platform.system())"
      ],
      "metadata": {
        "id": "O24_U-m8q-xv",
        "outputId": "f2298893-2e7e-4b8f-cc38-0caeb1a6a670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# makes it so pd dfs aren't truncated\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "IF_vPVifaU9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eocC68amnhEI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) DATA PRE-PROCESSING\n",
        "\n",
        "a) Load in kaggle data labels + image file paths\n",
        "\n",
        "b) combine kaggle data labels and image file paths into one dataframe\n",
        "\n",
        "c) load in the extra 486 image file paths\n",
        "\n",
        "d) extract the speed and angle labels from the file path names\n",
        "\n",
        "e) store that extra data in a pandas df and do the value normalisation\n",
        "\n",
        "f) merge the kaggle and extra data dfs\n",
        "\n",
        "g) EDA\n",
        "\n",
        "h) convert the images to numerical RGB feature maps\n",
        "\n",
        "i) split data into training-validation sets\n",
        "\n",
        "j) data augmentation applied to training set"
      ],
      "metadata": {
        "id": "-_MvRvYnfIM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a) load in kaggle data labels + image file paths"
      ],
      "metadata": {
        "id": "HU3TvBZ5hfhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # tylers file path\n",
        "labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
        "# labels_file_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_norm.csv' # tyler hpc file path (mlis2 cluster)\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ],
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data' # OG data ben hpc file path (mlis2 cluster)\n",
        "# image_folder_path = '/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data'\n",
        "# image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ],
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking labels dataframe"
      ],
      "metadata": {
        "id": "0oeuvmeZaGSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pi13TZ2aFhO",
        "outputId": "fc675bb2-271b-48fd-a6c3-43834afb4500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed\n",
              "image_id               \n",
              "1         0.4375    0.0\n",
              "2         0.8125    1.0\n",
              "3         0.4375    1.0\n",
              "4         0.6250    1.0\n",
              "5         0.5000    0.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
      ],
      "metadata": {
        "id": "puEjGoOJaRS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1suFSK7aWKH",
        "outputId": "c3cc2d29-d759-48ff-b92c-77dbd178f295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                      image_file_paths\n",
              "image_id                                                                                              \n",
              "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png\n",
              "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png\n",
              "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png\n",
              "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/4.png\n",
              "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/5.png"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b) Combine the kaggle labels and image file paths into one dataframe"
      ],
      "metadata": {
        "id": "CjDdyYd6cMBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
        "kaggle_df['speed'] = kaggle_df['speed'].round(6) # to get rid of floating point errors"
      ],
      "metadata": {
        "id": "6NdbonzPcLKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VstirIAdAZi",
        "outputId": "c03ff707-9e8d-4c3a-8965-f795919ace21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "13794     0.6250    1.0   \n",
              "13795     0.4375    1.0   \n",
              "13796     0.5625    0.0   \n",
              "13797     0.6250    0.0   \n",
              "13798     0.6875    1.0   \n",
              "\n",
              "                                                                                          image_file_paths  \n",
              "image_id                                                                                                    \n",
              "13794     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13794.png  \n",
              "13795     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13795.png  \n",
              "13796     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13796.png  \n",
              "13797     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png  \n",
              "13798     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13794</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13794.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13795</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13795.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13796</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13796.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13797</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13798</th>\n",
              "      <td>0.6875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_df.loc[3139:3143]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MgNoL8nfBm2",
        "outputId": "924e7562-25a4-4223-8305-c3fd02452846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          angle  speed  \\\n",
              "image_id                 \n",
              "3139      0.750    1.0   \n",
              "3140      0.875    1.0   \n",
              "3142      0.625    0.0   \n",
              "3143      0.625    1.0   \n",
              "\n",
              "                                                                                         image_file_paths  \n",
              "image_id                                                                                                   \n",
              "3139      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3139.png  \n",
              "3140      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3140.png  \n",
              "3142      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3142.png  \n",
              "3143      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3143.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3139</th>\n",
              "      <td>0.750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3139.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>0.875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3140.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3142</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3142.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3143</th>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3143.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above cell shows that:\n",
        "\n",
        " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
        "\n",
        " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
      ],
      "metadata": {
        "id": "U7PCxqJbmXE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c) load in the extra 486 labels image file paths"
      ],
      "metadata": {
        "id": "zOEWqBUYX6DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extradata_folder_path = '/home/apyba3/petru_data'\n",
        "\n",
        "extradata_file_paths = [\n",
        "    os.path.join(extradata_folder_path, f)\n",
        "    for f in os.listdir(extradata_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]"
      ],
      "metadata": {
        "id": "wvsDiCCLOvvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1d) extract the speed and angle labels from the file path names"
      ],
      "metadata": {
        "id": "I4ofcGILO4et"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "image file path name follows the pattern: `randomnumber_angle_speed`"
      ],
      "metadata": {
        "id": "fFsEI4MBRf2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regex pattern to extract angle and speed values\n",
        "pattern = r'(\\d+)_([\\d]+)_([\\d]+)\\.png'\n",
        "\n",
        "angle_value = []\n",
        "speed_value = []\n",
        "\n",
        "# Loop through file paths and extract angle and speed values\n",
        "for file_path in extradata_file_paths:\n",
        "    match = re.search(pattern, file_path)\n",
        "    if match:\n",
        "        # Extract random number, angle, and speed values\n",
        "        random_number = match.group(1)\n",
        "        angle_value.append(int(match.group(2)))\n",
        "        speed_value.append(int(match.group(3)))"
      ],
      "metadata": {
        "id": "mY5-HDp-PJY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking it has stored the labels correctly (check if the angle_value order matches that of the file path)"
      ],
      "metadata": {
        "id": "4F8qIQJ8Y3t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(angle_value[:3])\n",
        "print(image_file_paths[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf1bChw_OvsT",
        "outputId": "bdf648d9-3ab3-403e-c977-0c938ae1bf18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[95, 100, 80]\n",
            "['/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png', '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png', '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1e) store that extra data in a pandas df and do the value normalisation"
      ],
      "metadata": {
        "id": "XyvljUTBZP0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extradata_df = pd.DataFrame({\n",
        "    'angle': angle_value,\n",
        "    'speed': speed_value,\n",
        "    'image_file_paths': extradata_file_paths\n",
        "})\n",
        "\n",
        "# conversions (see kaggle data section)\n",
        "extradata_df.loc[extradata_df['speed'] > 0, 'speed'] = 1\n",
        "extradata_df['speed'] = pd.to_numeric(extradata_df['speed'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "extradata_df['angle'] = (extradata_df['angle'] - 50)/80\n",
        "\n",
        "extradata_df.index = pd.RangeIndex(start=13799, stop=13799 + len(extradata_df), step=1)\n",
        "extradata_df.index.name = 'image_id'\n",
        "\n",
        "extradata_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tse95lu1OvnY",
        "outputId": "90ed60a7-5f9c-4901-f7ed-7442d739ccfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed                                  image_file_paths\n",
              "image_id                                                                 \n",
              "13799     0.5625      0    /home/apyba3/petru_data/1712918428740_95_0.png\n",
              "13800     0.6250      1  /home/apyba3/petru_data/1712923220525_100_50.png\n",
              "13801     0.3750      1   /home/apyba3/petru_data/1712923068961_80_35.png\n",
              "13802     0.6875      0   /home/apyba3/petru_data/1712921566265_105_0.png\n",
              "13803     0.2500      1   /home/apyba3/petru_data/1712915924250_70_35.png"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13799</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>0</td>\n",
              "      <td>/home/apyba3/petru_data/1712918428740_95_0.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13800</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1</td>\n",
              "      <td>/home/apyba3/petru_data/1712923220525_100_50.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13801</th>\n",
              "      <td>0.3750</td>\n",
              "      <td>1</td>\n",
              "      <td>/home/apyba3/petru_data/1712923068961_80_35.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13802</th>\n",
              "      <td>0.6875</td>\n",
              "      <td>0</td>\n",
              "      <td>/home/apyba3/petru_data/1712921566265_105_0.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13803</th>\n",
              "      <td>0.2500</td>\n",
              "      <td>1</td>\n",
              "      <td>/home/apyba3/petru_data/1712915924250_70_35.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1f) merge the kaggle and extra data dfs"
      ],
      "metadata": {
        "id": "qv0MwDKsbOef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.concat([kaggle_df, extradata_df])\n",
        "merged_df.loc[13797:13800]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZMZPUn4b3Kc",
        "outputId": "86bd34db-0b48-442e-b5b2-5ff322d0764b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "13797     0.6250    0.0   \n",
              "13798     0.6875    1.0   \n",
              "13799     0.5625    0.0   \n",
              "13800     0.6250    1.0   \n",
              "\n",
              "                                                                                          image_file_paths  \n",
              "image_id                                                                                                    \n",
              "13797     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png  \n",
              "13798     /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png  \n",
              "13799                                                       /home/apyba3/petru_data/1712918428740_95_0.png  \n",
              "13800                                                     /home/apyba3/petru_data/1712923220525_100_50.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13797</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13797.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13798</th>\n",
              "      <td>0.6875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/13798.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13799</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/petru_data/1712918428740_95_0.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13800</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/petru_data/1712923220525_100_50.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1g) EDA - angle column"
      ],
      "metadata": {
        "id": "h3OKLcn9u0Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.value_counts('angle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWQCQrR-oCps",
        "outputId": "88bb4558-2c8a-482b-de5d-8f7876ed9bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "angle\n",
              "0.5000    2172\n",
              "0.7500    2172\n",
              "0.6875    2049\n",
              "0.6250    2000\n",
              "0.5625    1644\n",
              "0.4375    1520\n",
              "0.8125    1162\n",
              "0.3750     447\n",
              "0.8750     308\n",
              "0.3125     229\n",
              "0.1875     119\n",
              "0.2500     118\n",
              "0.1250     114\n",
              "0.0000      75\n",
              "0.9375      74\n",
              "0.0625      38\n",
              "1.0000      38\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note: imbalance datset"
      ],
      "metadata": {
        "id": "K4pZ65pYvdqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to remove the row containing the erroneous 1.428571 speed value"
      ],
      "metadata": {
        "id": "zMZq41-RkLz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = merged_df[merged_df['angle'] != 1.428571]"
      ],
      "metadata": {
        "id": "TDMqIiOLSKGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1h) convert images to numerical RGB feature maps"
      ],
      "metadata": {
        "id": "Di6F6km_DBmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path, label, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, resized_shape)\n",
        "    image = image / 255.0  # Normalise pixel values to [0,1]\n",
        "    return image, label\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"angle\"])) # Convert pd df into a tf ds\n",
        "\n",
        "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(len(cleaned_df))\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oeeBTruNCQ96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets check and see if what we have done works"
      ],
      "metadata": {
        "id": "pUOlsWQeVlyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in dataset.take(1):\n",
        "    print(images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "jBTNjNhMVk2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00f1443-c179-43a2-e6fd-7cc90ff698f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 224, 224, 3) (16,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1i) Splitting data into training and validation sets (test set is already provided in kaggle data)"
      ],
      "metadata": {
        "id": "Md6U_i84SiK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80-20 split\n",
        "\n",
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)"
      ],
      "metadata": {
        "id": "yYlssPh5dxaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train size: {train_size}, validation size: {dataset_size - train_size}\")"
      ],
      "metadata": {
        "id": "qPUE6rd8cgQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a418b177-e08d-481c-d272-b9b7494882d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 714, validation size: 179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1j) Data Augmentation applied to training set\n",
        "\n",
        "- Random Brightness Adjustment\n",
        "- Random Contrast Adjustment\n",
        "- Random Hue Adjustment\n",
        "- Random Saturation Adjustment\n",
        "- Random Horizontal Flip\n",
        "- Random Vertical Flip\n",
        "\n"
      ],
      "metadata": {
        "id": "0ujsjhMPSw4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_image(image, label):\n",
        "  seed = (6, 9)\n",
        "  image = tf.image.stateless_random_brightness(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_contrast(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_saturation(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_flip_left_right(image, seed)\n",
        "  image = tf.image.stateless_random_flip_up_down(image, seed)\n",
        "  return image, label\n",
        "\n",
        "# Create a dataset of augmented images from the original train_dataset\n",
        "# augmented_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "augmented_dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Concatenate the original and augmented datasets\n",
        "# train_dataset = train_dataset.concatenate(augmented_dataset)\n",
        "dataset = dataset.concatenate(augmented_dataset)\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "# train_dataset = train_dataset.shuffle(buffer_size=len(cleaned_df))\n",
        "dataset = dataset.shuffle(buffer_size=len(cleaned_df))"
      ],
      "metadata": {
        "id": "T9r811eWsYfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "count how many images are in the training set - 22016 with no extradata and 80-20 split"
      ],
      "metadata": {
        "id": "ZOqizFg7rvKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_images = 0\n",
        "for image_batch, _ in dataset:\n",
        "    total_images += image_batch.shape[0]  # Add the batch size\n",
        "\n",
        "print(f\"Total number of images in train_dataset: {total_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjlyfjAxLsrC",
        "outputId": "14dc79ee-e1b4-4c37-bfb1-b6525bc586c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-23 00:27:03.246354: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:72: Filling up shuffle buffer (this may take a while): 1635 of 14279\n",
            "2025-03-23 00:27:04.746377: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images in train_dataset: 28558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-23 00:27:05.222019: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking to see if whats been done was successful or needs debugging"
      ],
      "metadata": {
        "id": "HEdi-dUCTND1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, axarr = plt.subplots(1,10)\n",
        "\n",
        "i = 0\n",
        "for image_batch, label_batch in dataset.take(1):  # Take one batch\n",
        "    for image in image_batch:  # Iterate through images in the batch\n",
        "        if i < 10:  # Only display the first 5 images\n",
        "            print('image shape: ', np.shape(image))\n",
        "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
        "            axarr[i].imshow(image)\n",
        "            axarr[i].axis('off')\n",
        "            i += 1\n",
        "        else:\n",
        "            break  # Stop after displaying 5 images\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OeboVhsQKGFS",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9c6bb08-d7ce-4951-b621-6775a6ee3bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-23 00:27:15.555156: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:72: Filling up shuffle buffer (this may take a while): 1755 of 14279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape:  (224, 224, 3)\n",
            "label: 0.625\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.5625\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.625\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.625\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.6875\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.5\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.625\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.5\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.5625\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.6875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-23 00:27:15.843059: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Model Building - ResNet50 Transfer Learning"
      ],
      "metadata": {
        "id": "cmetmzNHTWzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a) Set up model architecture"
      ],
      "metadata": {
        "id": "48RHLVshdX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "input_shape = (224,224,3)"
      ],
      "metadata": {
        "id": "aHjqXG1jSnCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 29:\n",
        "resnet50 = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=input_shape\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  resnet50,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.trainable = True  # Make the entire model trainable\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "ZPso3wBuN9L3",
        "outputId": "ef11a9ff-7117-4836-dd78-9bcadac15995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,155,521\u001b[0m (92.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,155,521</span> (92.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,102,401\u001b[0m (91.94 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,102,401</span> (91.94 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss=tf.keras.losses.MeanSquaredError(),\n",
        ")"
      ],
      "metadata": {
        "id": "Ca0JFQuuN8oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ModelCheckpoint callback\n",
        "checkpoint_filepath = '/home/apyba3/ResNet50/resnet50checkpoint.keras'\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    save_best_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Training loop\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=50,\n",
        "    batch_size=1,\n",
        "    callbacks=[model_checkpoint]  # Include the ModelCheckpoint callback\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WPTNOtr7WjLS",
        "outputId": "63cf5fac-6100-43db-dadd-47da686c9712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-23 00:31:39.730708: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at xla_ops.cc:577 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
            "%cudnn-conv-bias-activation.198 = (f32[16,64,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,3,224,224]{3,2,1,0} %transpose.587, f32[64,3,7,7]{3,2,1,0} %transpose.588, f32[64]{0} %arg3.4), window={size=7x7 stride=2x2 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/resnet50_1/conv1_conv_1/convolution\" source_file=\"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\n",
            "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes.\n",
            "\n",
            "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_2757321/876782938.py\", line 13, in <module>\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.198 = (f32[16,64,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,3,224,224]{3,2,1,0} %transpose.587, f32[64,3,7,7]{3,2,1,0} %transpose.588, f32[64]{0} %arg3.4), window={size=7x7 stride=2x2 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/resnet50_1/conv1_conv_1/convolution\" source_file=\"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_195744]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[116], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m      4\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mcheckpoint_filepath,\n\u001b[1;32m      5\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Include the ModelCheckpoint callback\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_2757321/876782938.py\", line 13, in <module>\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.198 = (f32[16,64,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,3,224,224]{3,2,1,0} %transpose.587, f32[64,3,7,7]{3,2,1,0} %transpose.588, f32[64]{0} %arg3.4), window={size=7x7 stride=2x2 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/resnet50_1/conv1_conv_1/convolution\" source_file=\"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_195744]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropoutrate = 0.2\n",
        "# num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "# input_shape = (224,224,3)\n",
        "\n",
        "# mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "#     input_shape=input_shape,\n",
        "#     include_top=False,\n",
        "#     weights='imagenet',\n",
        "#     minimalistic=False\n",
        "# )\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#   mbnet,\n",
        "#   tf.keras.layers.GlobalAveragePooling2D(),\n",
        "#   tf.keras.layers.Dropout(dropoutrate),\n",
        "#   tf.keras.layers.Dense(256, activation='relu'),\n",
        "#   tf.keras.layers.Dropout(dropoutrate),\n",
        "#   tf.keras.layers.Dense(128, activation='relu'),\n",
        "#   tf.keras.layers.Dropout(dropoutrate),\n",
        "#   tf.keras.layers.Dense(64, activation='relu'),\n",
        "#   tf.keras.layers.Dropout(dropoutrate),\n",
        "#   tf.keras.layers.Dense(32, activation='relu'),\n",
        "#   tf.keras.layers.Dense(1, activation='linear')\n",
        "# ])\n",
        "\n",
        "# model.build()\n",
        "\n",
        "# mbnet.trainable = False # freeze the first layers to the imagenet weights\n",
        "\n",
        "# model.summary() # print the model"
      ],
      "metadata": {
        "id": "Eh1-U-VYeN9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pQKOwRuWhUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) Define training step"
      ],
      "metadata": {
        "id": "3iuqe2Xwpu7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.001 #learning rate\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser\n",
        "\n",
        "@tf.function\n",
        "def train_step( model, X , Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model( X )\n",
        "        Y = tf.cast(Y, tf.float32)\n",
        "        current_loss = tf.reduce_mean(tf.losses.MeanSquaredError()( Y,  pred))\n",
        "\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients( zip( grads , model.trainable_variables) )\n",
        "    current_MSE = tf.reduce_mean(tf.square(Y-pred))\n",
        "    return(current_loss, current_MSE)"
      ],
      "metadata": {
        "id": "9AErZvcTeX-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2c) Training the model on the training set"
      ],
      "metadata": {
        "id": "bUMefNeTpDWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 50\n",
        "\n",
        "tloss = []\n",
        "tMSE = []\n",
        "vloss = []\n",
        "vMSE = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_MSEs = []\n",
        "    for image_batch, label_batch in dataset:\n",
        "        loss, MSE = train_step(model, image_batch, label_batch)\n",
        "        batch_losses.append(loss)\n",
        "        batch_MSEs.append(MSE)\n",
        "\n",
        "    # Calculate average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses)\n",
        "    avg_MSE = tf.reduce_mean(batch_MSEs)\n",
        "    tloss.append(avg_loss)\n",
        "    tMSE.append(avg_MSE)\n",
        "\n",
        "    # # Validation\n",
        "    # val_batch_losses = []\n",
        "    # val_batch_MSEs = []\n",
        "    # for image_batch, label_batch in validation_dataset:\n",
        "    #     val_loss, val_MSE = train_step(model, image_batch, label_batch)\n",
        "    #     val_batch_losses.append(val_loss)\n",
        "    #     val_batch_MSEs.append(val_MSE)\n",
        "\n",
        "    # # Calculate average validation metrics\n",
        "    # avg_val_loss = tf.reduce_mean(val_batch_losses)\n",
        "    # avg_val_MSE = tf.reduce_mean(val_batch_MSEs)\n",
        "    # vloss.append(avg_val_loss)\n",
        "    # vMSE.append(avg_val_MSE)\n",
        "\n",
        "    # Print metrics every 10 iterations\n",
        "    # if it % 10 == 0:  # Check if (it + 1) is divisible by 10\n",
        "    #     tf.print('iter: {}, train_loss: {:.3f}, train_MSE: {:.3f}, val_loss: {:.3f}, val_MSE: {:.3f}'.format(\n",
        "    #         it, avg_loss, avg_MSE, avg_val_loss, avg_val_MSE))\n",
        "    if it % 10 == 0:  # Check if (it + 1) is divisible by 10\n",
        "        tf.print('iter: {}, train_loss: {:.3f}, train_MSE: {:.3f}'.format(\n",
        "            it, avg_loss, avg_MSE))"
      ],
      "metadata": {
        "id": "uE2K4gVQedXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "88cee586-6240-4e5c-9abd-491c3c58423a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-23 00:09:45.535640: W tensorflow/core/kernels/conv_ops_gpu.cc:330] None of the algorithms provided by cuDNN frontend heuristics worked; trying fallback algorithms.  Conv: batch: 16\n",
            "in_depths: 64\n",
            "out_depths: 256\n",
            "in: 56\n",
            "in: 56\n",
            "data_format: 1\n",
            "filter: 1\n",
            "filter: 1\n",
            "filter: 64\n",
            "dilation: 1\n",
            "dilation: 1\n",
            "stride: 1\n",
            "stride: 1\n",
            "padding: 0\n",
            "padding: 0\n",
            "dtype: DT_FLOAT\n",
            "group_count: 1\n",
            "device_identifier: \"sm_7.5 with 11539054592B RAM, 68 cores, 1545000KHz clock, 7000000KHz mem clock, 5767168B L2$\"\n",
            "version: 3\n",
            "\n",
            "2025-03-23 00:09:45.536293: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at conv_ops_impl.h:1204 : NOT_FOUND: No algorithm worked!  Error messages:\n",
            "  Profiling failure on CUDNN engine eng1{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes.\n",
            "  Profiling failure on CUDNN engine eng28{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n",
            "  Profiling failure on CUDNN engine eng0{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n",
            "  Profiling failure on CUDNN engine eng4{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 96993280 bytes.\n",
            "  Profiling failure on CUDNN engine eng3{k11=2}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 605093888 bytes.\n",
            "2025-03-23 00:09:45.536330: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: NOT_FOUND: No algorithm worked!  Error messages:\n",
            "  Profiling failure on CUDNN engine eng1{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes.\n",
            "  Profiling failure on CUDNN engine eng28{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n",
            "  Profiling failure on CUDNN engine eng0{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n",
            "  Profiling failure on CUDNN engine eng4{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 96993280 bytes.\n",
            "  Profiling failure on CUDNN engine eng3{k11=2}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 605093888 bytes.\n",
            "\t [[{{node sequential_2_1/resnet50_1/conv2_block1_0_conv_1/convolution}}]]\n",
            "2025-03-23 00:09:45.539707: W tensorflow/core/kernels/conv_ops_gpu.cc:330] None of the algorithms provided by cuDNN frontend heuristics worked; trying fallback algorithms.  Conv: batch: 16\n",
            "in_depths: 64\n",
            "out_depths: 256\n",
            "in: 56\n",
            "in: 56\n",
            "data_format: 1\n",
            "filter: 1\n",
            "filter: 1\n",
            "filter: 64\n",
            "dilation: 1\n",
            "dilation: 1\n",
            "stride: 1\n",
            "stride: 1\n",
            "padding: 0\n",
            "padding: 0\n",
            "dtype: DT_FLOAT\n",
            "group_count: 1\n",
            "device_identifier: \"sm_7.5 with 11539054592B RAM, 68 cores, 1545000KHz clock, 7000000KHz mem clock, 5767168B L2$\"\n",
            "version: 3\n",
            "\n",
            "2025-03-23 00:09:45.540143: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at conv_ops_impl.h:1204 : NOT_FOUND: No algorithm worked!  Error messages:\n",
            "  Profiling failure on CUDNN engine eng1{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes.\n",
            "  Profiling failure on CUDNN engine eng28{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n",
            "  Profiling failure on CUDNN engine eng0{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n",
            "  Profiling failure on CUDNN engine eng4{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 96993280 bytes.\n",
            "  Profiling failure on CUDNN engine eng3{k11=2}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 605093888 bytes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Graph execution error:\n\nDetected at node sequential_2_1/resnet50_1/conv2_block1_0_conv_1/convolution defined at (most recent call last):\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_2757321/373689020.py\", line 13, in <module>\n\n  File \"/tmp/ipykernel_2757321/961140981.py\", line 7, in train_step\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/models/sequential.py\", line 213, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/models/functional.py\", line 182, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/models/functional.py\", line 584, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/models/functional.py\", line 182, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/models/functional.py\", line 584, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 243, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 233, in convolution_op\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/nn.py\", line 901, in conv\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py\", line 258, in conv\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py\", line 231, in _conv\n\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine eng1{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes.\n  Profiling failure on CUDNN engine eng28{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine eng0{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine eng4{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 96993280 bytes.\n  Profiling failure on CUDNN engine eng3{k11=2}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 605093888 bytes.\n\t [[{{node sequential_2_1/resnet50_1/conv2_block1_0_conv_1/convolution}}]] [Op:__inference_train_step_64327]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[43], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m batch_MSEs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch, label_batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m---> 13\u001b[0m     loss, MSE \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     batch_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     15\u001b[0m     batch_MSEs\u001b[38;5;241m.\u001b[39mappend(MSE)\n",
            "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node sequential_2_1/resnet50_1/conv2_block1_0_conv_1/convolution defined at (most recent call last):\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_2757321/373689020.py\", line 13, in <module>\n\n  File \"/tmp/ipykernel_2757321/961140981.py\", line 7, in train_step\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/models/sequential.py\", line 213, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/models/functional.py\", line 182, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/models/functional.py\", line 584, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/models/functional.py\", line 182, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/models/functional.py\", line 584, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 243, in call\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 233, in convolution_op\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/ops/nn.py\", line 901, in conv\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py\", line 258, in conv\n\n  File \"/home/apyba3/anaconda3/envs/mlis2cluster/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py\", line 231, in _conv\n\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine eng1{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777472 bytes.\n  Profiling failure on CUDNN engine eng28{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine eng0{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine eng4{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 96993280 bytes.\n  Profiling failure on CUDNN engine eng3{k11=2}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 605093888 bytes.\n\t [[{{node sequential_2_1/resnet50_1/conv2_block1_0_conv_1/convolution}}]] [Op:__inference_train_step_64327]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/home/apyba3/car_frozen_regression_resnet50.weights.h5')\n",
        "# model.save_weights('/home/ppytr13/car_frozen.weights.h5')"
      ],
      "metadata": {
        "id": "FiHy6opSP2sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session() #Clear keras session"
      ],
      "metadata": {
        "id": "FpLHyw20P93U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2d) fine-tuning"
      ],
      "metadata": {
        "id": "ENHbUvQdvyFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rebuild model after clearing keras session"
      ],
      "metadata": {
        "id": "h0ek_ytyw0KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = True # UNFREEZE mbnet layers\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "ZuKL3X-QP-Ax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "61256e01-6d81-434a-9ec9-a6321024f1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m)      │     \u001b[38;5;34m2,996,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m246,016\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">246,016</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,285,633\u001b[0m (12.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,285,633</span> (12.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,261,233\u001b[0m (12.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,261,233</span> (12.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,400\u001b[0m (95.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,400</span> (95.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/home/apyba3/car_frozen_regression_mobv3.weights.h5')\n",
        "# model.load_weights('/home/ppytr13/car_frozen.weights.h5')"
      ],
      "metadata": {
        "id": "8oAenzEiP-C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up fine-tuning training"
      ],
      "metadata": {
        "id": "XWDtRxBow89t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.0001 #deliberately smaller learning rate for fine tuning\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser"
      ],
      "metadata": {
        "id": "JQvDo1RVP-Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step( model, X , Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model( X )\n",
        "        Y = tf.cast(Y, tf.float32)\n",
        "        current_loss = tf.reduce_mean(tf.losses.MeanSquaredError()( Y,  pred))\n",
        "\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients( zip( grads , model.trainable_variables) )\n",
        "    current_MSE = tf.reduce_mean(tf.square(Y-pred))\n",
        "    return(current_loss, current_MSE)"
      ],
      "metadata": {
        "id": "-mwoRy9saOM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 30\n",
        "\n",
        "tloss = []\n",
        "tMSE = []\n",
        "vloss = []\n",
        "vMSE = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_MSEs = []\n",
        "    for image_batch, label_batch in dataset:\n",
        "        loss, MSE = train_step(model, image_batch, label_batch)\n",
        "        batch_losses.append(loss)\n",
        "        batch_MSEs.append(MSE)\n",
        "\n",
        "    # Calculate average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses)\n",
        "    avg_MSE = tf.reduce_mean(batch_MSEs)\n",
        "    tloss.append(avg_loss)\n",
        "    tMSE.append(avg_MSE)\n",
        "\n",
        "    # # Validation\n",
        "    # val_batch_losses = []\n",
        "    # val_batch_MSEs = []\n",
        "    # for image_batch, label_batch in validation_dataset:\n",
        "    #     val_loss, val_MSE = train_step(model, image_batch, label_batch)\n",
        "    #     val_batch_losses.append(val_loss)\n",
        "    #     val_batch_MSEs.append(val_MSE)\n",
        "\n",
        "    # # Calculate average validation metrics\n",
        "    # avg_val_loss = tf.reduce_mean(val_batch_losses)\n",
        "    # avg_val_MSE = tf.reduce_mean(val_batch_MSEs)\n",
        "    # vloss.append(avg_val_loss)\n",
        "    # vMSE.append(avg_val_MSE)\n",
        "\n",
        "    # Print metrics every 10 iterations\n",
        "    # if it % 10 == 0:  # Check if (it + 1) is divisible by 10\n",
        "    #     tf.print('iter: {}, train_loss: {:.3f}, train_MSE: {:.3f}, val_loss: {:.3f}, val_MSE: {:.3f}'.format(\n",
        "    #         it, avg_loss, avg_MSE, avg_val_loss, avg_val_MSE))\n",
        "    if it % 10 == 0:  # Check if (it + 1) is divisible by 10\n",
        "        tf.print('iter: {}, train_loss: {:.3f}, train_MSE: {:.3f}'.format(\n",
        "            it, avg_loss, avg_MSE))"
      ],
      "metadata": {
        "id": "ZvmWxC1fP-Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c9e120-a20f-403f-81b7-7f3a945165c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-22 22:01:20.252811: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 828 of 14279\n",
            "2025-03-22 22:01:21.427303: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "W0000 00:00:1742680895.375777 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.380414 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.381100 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.381733 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.408531 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.409401 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.410236 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.411449 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.449882 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.450926 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.451947 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.453134 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.536514 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.537339 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.538052 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.539111 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.540028 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.540795 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.541756 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.581242 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.582587 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.583450 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.593289 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.716471 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.717089 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.717631 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.718163 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.718716 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.719300 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.720024 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.720852 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.721455 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.722053 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.722732 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.723441 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.726554 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.727075 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.727548 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.728045 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.728516 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.728988 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.729504 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.730023 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.730627 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.731339 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.732221 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.749743 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.797727 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.798242 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.798727 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.799186 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.799651 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.800213 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.800755 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.801292 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.801864 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.802438 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.802999 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.803566 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.805671 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.806164 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.806618 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.807168 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.807951 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.808645 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.811410 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.811897 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.812355 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.812777 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.813204 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.813638 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.814162 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.814711 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.815252 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.815818 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.816361 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.816904 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.817446 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.819407 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.819867 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.820299 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.820748 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.821190 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.821670 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.822629 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.823293 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.823799 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.837511 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.838053 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.838567 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.839085 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.839614 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.840167 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.840895 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.841733 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.842299 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.842850 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.843489 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.844152 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.846802 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.847294 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.847765 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.848248 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.848718 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.849191 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.849681 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.850183 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.850770 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.851428 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.852140 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.854934 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.855372 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.855806 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.856241 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.856656 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.857076 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.857527 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.857975 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.858421 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.858924 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.859428 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.859940 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.860427 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.862180 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.862606 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.863032 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.863517 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.864027 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.864483 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.865149 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.865726 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.866395 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.869268 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.869703 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.870114 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.870535 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.870946 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.871358 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.871833 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.872291 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.872739 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.873245 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.873723 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.874208 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.874688 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.876441 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.876869 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.877278 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.877705 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.878129 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.878575 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.879297 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.879832 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.880300 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.880932 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.893214 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.893932 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.894606 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.895264 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.896032 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.896771 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.898179 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.899917 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.900812 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.901688 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.902841 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.907839 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.908474 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.909066 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.909676 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.910267 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.910872 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.911486 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.912164 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.912814 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.913477 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.914211 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.918628 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.919241 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.919831 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.920423 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.921147 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.921814 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.923317 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.924552 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.925375 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.926188 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.927230 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.929836 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.930399 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.930938 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.931490 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.932019 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.932547 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.933171 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.933836 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.934515 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.935200 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.936252 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.941310 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.943157 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.943701 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.944237 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.944849 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.945425 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.946912 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.948130 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.948831 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.949529 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.950422 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.951523 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.955318 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.955846 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.956350 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.956849 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.957341 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.957842 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.958397 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.959002 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.959622 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.960219 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.961095 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.964626 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.965056 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.965464 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.965877 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.966295 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.966714 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.967129 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.967485 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.967857 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.968242 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.968626 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.969013 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.969370 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.970994 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.971347 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.971714 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.972107 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.972495 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.972855 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.973264 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.973722 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.974103 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.974586 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.975003 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.978454 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.978841 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.979215 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.979592 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.979958 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.980303 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.980653 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.981001 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.981348 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.981706 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.982064 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.982420 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.982776 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.985914 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.986287 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.986654 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.987003 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.987349 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.987722 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.988076 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.988542 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.988942 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.989323 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.989689 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.990102 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.992381 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.993042 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.993469 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.993894 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.994322 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.994771 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.995734 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.996894 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.997386 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.997867 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.998504 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680895.999225 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.001601 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.002034 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.002444 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.002889 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.003289 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.003692 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.004107 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.004544 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.005008 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.005503 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.005925 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.008428 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.008815 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.009187 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.009558 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.009957 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.010331 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.011300 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.012420 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.012816 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.013209 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.013797 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.014469 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.016491 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.016866 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.017230 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.017590 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.017950 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.018309 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.018696 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.019097 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.019505 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.019911 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.020700 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.022711 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.023098 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.023463 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.023858 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.024237 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.024624 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.025585 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.026713 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.027125 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.027511 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.028105 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.028768 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.030688 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.031058 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.031426 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.031820 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.032190 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.032554 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.032941 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.033311 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.033690 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.034093 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.034845 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.037176 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.037579 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.037953 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.038327 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.038730 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.039120 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.040235 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.041175 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.041586 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.042014 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.042594 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.043260 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.045223 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.045608 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.045974 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.046338 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.046696 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.047056 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.047444 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.047853 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.048243 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.048659 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.049447 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.051402 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.051789 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.052163 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.052538 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.052912 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.053300 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.054261 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.055390 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.055834 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.056238 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.056823 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.057484 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.059421 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.059798 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.060171 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.060541 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.060907 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.061271 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.061661 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.062043 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.062424 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.062800 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.063618 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.066230 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.066619 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.066994 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.067369 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.067772 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.068166 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.069282 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.070229 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.070645 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.071054 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.071637 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.072310 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.074311 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.074695 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.075072 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.075428 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.075816 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.076184 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.076581 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.076972 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.077370 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.077769 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.078606 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.080704 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.081646 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.082120 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.082594 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.083170 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.083719 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.084437 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.084900 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.085750 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.086810 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.087273 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.088227 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.090676 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.091098 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.091502 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.091940 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.092335 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.092729 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.093150 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.093572 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.094008 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.094565 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.095995 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.097730 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.098177 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.098591 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.099003 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.099514 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.099989 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.100908 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.102039 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.102517 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.102984 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.103601 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.104355 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.106290 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.106689 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.107059 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.107433 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.107836 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.108218 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.108641 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.109074 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.109502 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.109933 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.112203 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.112552 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.112881 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.113206 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.113531 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.113862 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.114218 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.114577 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.114943 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.115288 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.115627 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.115985 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.116329 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.117937 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.118291 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.118622 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.118996 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.119340 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.119710 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.120059 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.120404 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.120756 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.121109 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.121460 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.121832 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.123596 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.123982 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.124313 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.124642 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.124972 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.125312 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.125645 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.125985 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.126317 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.126654 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.127006 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.127371 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.127740 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.128099 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.129749 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.130113 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.130445 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.130785 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.131123 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.131468 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.131826 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.132182 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.132560 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.132916 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.133259 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.133605 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.135444 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.135947 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.136362 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.136775 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.137232 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.137684 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.138303 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.138717 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.139425 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.140124 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.140552 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.141499 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.143811 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.144197 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.144571 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.144964 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.145334 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.145705 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.146090 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.146480 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.146874 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.147329 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.152091 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.152505 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.152903 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.153302 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.153811 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.154266 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.155176 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.156307 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.156761 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.157182 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.157785 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.158596 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.160459 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.160834 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.161197 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.161559 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.161927 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.162294 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.162681 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.163104 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.163522 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.163953 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.165995 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.166351 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.166682 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.167013 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.167343 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.167692 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.168042 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.168381 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.168712 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.169049 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.169388 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.169727 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.170071 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.171687 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.172074 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.172438 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.172792 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.173126 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.173467 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.173813 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.174171 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.174543 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.174912 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.175255 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.175650 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.177307 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.177670 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.177999 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.178331 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.178655 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.178990 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.179329 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.179688 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.180054 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.180417 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.180757 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.181089 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.181430 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.181770 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.183386 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.183746 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.184093 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.184430 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.184771 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.185112 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.185448 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.185798 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.186176 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.186513 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.186849 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.187213 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.190293 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.190938 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.191562 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.192120 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.192740 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.193354 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.193929 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.194708 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.195625 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.196621 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.197246 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.198402 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.200681 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.201102 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.201508 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.201985 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.202407 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.202831 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.203290 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.203739 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.204198 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.204824 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.207134 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.207776 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.208405 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.208972 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.209626 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.210252 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.211057 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.212137 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.212894 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.214011 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.215017 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.216210 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.218746 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.219193 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.219602 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.220035 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.220479 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.220932 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.221479 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.222036 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.222578 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.223145 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.225941 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.227606 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.228159 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.228776 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.229389 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.230002 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.230729 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.231329 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.232279 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.233201 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.234262 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.235505 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.237686 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.238122 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.238527 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.238937 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.239347 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.239782 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.240310 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.240845 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.241367 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.241912 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.244431 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.248377 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.249393 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.250435 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.251795 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.253078 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.254496 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.256162 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.258306 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.259749 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.261187 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.262621 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.265754 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.266347 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.266933 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.267567 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.268208 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.269040 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.269713 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.270467 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.271174 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.272515 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.275754 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.276230 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.276687 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.277141 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.277726 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.278350 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.280198 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.281156 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.282232 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.283295 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.284856 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.286973 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.289563 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.290026 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.290471 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.290955 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.291441 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.292007 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.292732 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.293254 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.293788 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.294308 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.296853 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.298900 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.299499 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.300444 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.301487 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.302550 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.303581 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.305377 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.306639 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680896.308189 2746579 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.885385 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.885934 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.886393 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.886837 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.887284 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.887733 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.888176 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.888629 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.889086 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.889553 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.890032 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.890535 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.892134 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.892620 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.893106 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.893589 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.894097 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.894614 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.895222 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.895756 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.897622 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.898064 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.898490 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.898914 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.899352 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.899795 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.900259 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.900751 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.901194 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.901633 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.902079 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.902528 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.904635 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.905073 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.905497 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.905927 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.906352 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.906788 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.907220 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.907663 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.908168 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.908623 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.909099 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.911152 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.911568 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.911971 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.912366 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.912766 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.913163 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.913576 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.913981 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.914393 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.914818 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.915248 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.915672 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.916104 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.917177 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.917588 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.918001 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.918460 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.918971 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.919762 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.921559 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.921986 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.922386 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.922778 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.923172 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.923573 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.923989 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.924402 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.924816 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.925247 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.925671 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.926096 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.926519 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.927975 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.928379 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.928768 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.929187 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.929611 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.930027 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.930484 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.930983 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.931471 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.934654 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.935087 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.935506 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.935925 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.936360 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.936795 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.937259 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.937749 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.938177 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.938610 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.939048 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.939494 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.941435 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.941873 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.942301 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.942715 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.943157 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.943571 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.943996 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.944429 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.944870 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.945344 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.945838 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.947779 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.948189 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.948592 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.948993 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.949391 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.949794 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.950196 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.950598 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.950998 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.951409 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.951818 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.952234 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.952647 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.954045 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.954470 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.954879 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.955361 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.955847 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.956288 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.956766 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.957426 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.957933 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.960396 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.960803 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.961198 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.961596 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.961993 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.962390 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.962793 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.963193 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.963593 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.964005 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.964415 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.964829 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.965241 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.966698 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.967116 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.967508 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.967924 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.968341 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.968743 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.969176 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.969637 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.970093 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.970587 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.973291 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.973747 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.974182 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.974619 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.975101 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.975639 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.976121 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.976729 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.977192 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.977859 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.978317 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.979094 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.981265 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.981758 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.982224 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.982681 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.983159 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.983639 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.984126 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.984661 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.985211 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.985755 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.986365 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.988507 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.988972 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.989416 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.989860 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.990395 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.990881 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.991373 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.991990 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.992452 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.993114 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.993601 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.994359 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.996524 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.996972 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.997402 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.997830 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.998262 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.998690 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.999130 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680954.999586 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.000056 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.000530 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.001105 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.004042 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.004496 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.004928 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.005361 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.005869 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.006323 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.006789 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.007344 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.007779 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.008446 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.008894 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.009660 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.011701 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.012132 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.012554 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.012981 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.013401 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.013823 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.014250 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.014688 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.015134 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.015571 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.016066 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.018138 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.018545 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.018940 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.019337 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.019732 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.020132 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.020521 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.020909 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.021298 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.021693 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.022089 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.022483 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.022879 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.024373 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.024789 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.025185 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.025643 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.026104 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.026532 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.026980 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.027481 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.027953 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.028552 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.029031 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.031144 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.031566 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.031959 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.032358 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.032753 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.033141 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.033529 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.033918 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.034307 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.034704 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.035102 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.035498 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.035893 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.037580 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.038002 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.038401 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.038816 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.039230 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.039652 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.040055 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.040466 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.040890 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.041334 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.041775 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.042216 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.044434 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.044888 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.045322 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.045761 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.046207 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.046672 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.047189 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.047631 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.048192 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.048872 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.049328 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.050115 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.051829 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.052301 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.052758 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.053194 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.053638 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.054074 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.054530 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.055025 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.055436 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.056079 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.057600 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.057964 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.058311 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.058659 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.059006 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.059370 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.059709 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.060060 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.060473 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.060921 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.061453 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.062051 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.063752 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.064115 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.064453 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.064791 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.065127 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.065467 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.065816 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.066157 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.066499 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.066843 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.067275 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.069145 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.069513 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.069859 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.070226 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.070577 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.070923 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.071266 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.071610 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.072021 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.072461 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.073002 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.073390 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.075287 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.075651 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.075992 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.076338 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.076685 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.077042 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.077403 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.077742 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.078082 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.078440 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.078884 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.081095 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.081459 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.081802 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.082146 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.082493 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.082855 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.083200 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.083552 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.083962 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.084402 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.084933 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.085531 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.087795 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.088182 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.088562 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.088953 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.089342 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.089726 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.090117 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.090460 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.090803 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.091149 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.091584 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.093448 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.093816 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.094160 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.094524 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.094874 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.095218 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.095561 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.095904 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.096315 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.096752 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.097292 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.097683 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.099603 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.099961 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.100306 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.100655 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.101002 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.101361 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.101726 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.102068 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.102414 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.102777 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.103233 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.104733 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.105101 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.105449 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.105795 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.106141 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.106504 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.106852 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.107205 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.107614 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.108059 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.108592 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.109188 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.110897 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.111256 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.111590 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.111929 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.112268 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.112612 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.112958 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.113294 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.113633 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.113976 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.114419 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.116317 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.116726 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.117114 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.117503 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.117890 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.118282 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.118844 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.119218 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.119883 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.120364 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.120776 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.121699 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.124099 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.124471 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.124832 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.125195 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.125546 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.125899 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.126253 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.126622 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.126980 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.127369 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.127972 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.129634 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.130037 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.130423 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.130816 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.131232 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.131612 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.132509 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.133627 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.134027 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.134399 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.134961 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.135648 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.137273 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.137620 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.137951 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.138289 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.138626 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.138962 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.139304 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.139649 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.139992 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.140337 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.142101 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.142455 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.142777 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.143098 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.143418 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.143739 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.144062 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.144383 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.144706 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.145027 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.145352 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.145682 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.146010 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.147572 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.147927 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.148256 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.148611 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.148941 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.149274 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.149614 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.149952 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.150296 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.150639 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.150987 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.151343 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.152973 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.153316 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.153638 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.153958 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.154280 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.154602 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.154924 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.155247 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.155571 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.155891 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.156211 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.156534 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.156861 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.157187 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.158753 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.159094 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.159418 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.159752 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.160084 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.160417 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.160740 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.161067 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.161398 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.161755 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.162084 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.162427 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.164145 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.164547 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.164938 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.165329 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.165700 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.166074 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.166641 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.167020 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.167684 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.168093 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.168508 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.169435 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.171700 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.172068 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.172414 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.172762 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.173103 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.173442 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.173781 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.174129 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.174473 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.174833 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.177440 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.177854 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.178247 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.178639 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.179056 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.179437 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.180326 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.181441 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.181818 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.182179 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.182747 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.183435 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.185040 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.185380 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.185712 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.186048 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.186384 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.186719 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.187055 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.187398 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.187732 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.188077 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.189803 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.190145 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.190467 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.190787 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.191111 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.191433 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.191754 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.192078 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.192400 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.192724 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.193044 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.193366 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.193692 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.195222 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.195576 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.195897 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.196242 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.196568 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.196899 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.197236 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.197585 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.197922 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.198256 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.198596 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.198932 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.200528 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.200869 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.201191 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.201511 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.201830 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.202152 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.202473 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.202797 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.203119 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.203442 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.203765 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.204088 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.204415 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.204741 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.206279 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.206618 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.206942 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.207274 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.207604 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.207933 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.208260 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.208586 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.208916 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.209275 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.209600 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.209940 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.211576 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.212183 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.212767 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.213148 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.213556 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.213949 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.214530 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.215005 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.215419 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.216001 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.216662 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.218759 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.219131 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.219480 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.219845 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.220198 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.220549 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.220904 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.221261 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.221615 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.222013 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.223483 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.224084 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.224667 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.225054 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.225473 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.226057 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.226520 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.226997 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.227602 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.228352 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.228914 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.231022 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.231387 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.231730 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.232081 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.232439 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.232793 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.233168 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.233549 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.233925 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.234302 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.236296 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.236726 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.237127 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.237500 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.238083 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.238665 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.239247 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.239852 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.240603 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.241544 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.241985 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.243755 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.244119 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.244457 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.244807 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.245154 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.245503 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.245874 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.246243 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.246613 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.246988 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.248876 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.249372 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.249833 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.250351 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.250939 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.251589 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.252323 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.253303 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.254459 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.255120 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.256506 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.257889 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.260540 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.260938 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.261324 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.261722 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.262118 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.262564 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.262975 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.263388 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.263794 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.264353 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.266062 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.266518 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.266946 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.267376 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.267761 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.268159 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.268813 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.269429 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.270133 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.270641 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.271573 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.273508 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.273889 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.274241 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.274610 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.274973 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.275353 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.275772 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.276142 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.276521 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.276889 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.278593 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.279000 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.279392 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.280029 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.280743 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.281237 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.281880 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
            "W0000 00:00:1742680955.282812 2746581 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0, train_loss: 0.010, train_MSE: 0.041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-22 22:02:52.241115: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 880 of 14279\n",
            "2025-03-22 22:02:52.406457: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:04:01.975434: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 892 of 14279\n",
            "2025-03-22 22:04:01.984276: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:05:08.117576: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 876 of 14279\n",
            "2025-03-22 22:05:08.356575: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:06:14.493340: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 878 of 14279\n",
            "2025-03-22 22:06:14.652245: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:07:23.826546: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 877 of 14279\n",
            "2025-03-22 22:07:24.071193: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:08:28.107993: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 892 of 14279\n",
            "2025-03-22 22:08:28.116123: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:09:34.598452: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 877 of 14279\n",
            "2025-03-22 22:09:34.855787: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:10:42.321944: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 891 of 14279\n",
            "2025-03-22 22:10:42.331621: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:11:49.161522: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 887 of 14279\n",
            "2025-03-22 22:11:49.201187: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:12:55.693316: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 891 of 14279\n",
            "2025-03-22 22:12:55.696173: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 10, train_loss: 0.006, train_MSE: 0.044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-22 22:13:53.448689: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 22:14:03.617502: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 883 of 14279\n",
            "2025-03-22 22:14:03.707885: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:15:11.508634: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 877 of 14279\n",
            "2025-03-22 22:15:11.688805: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:16:20.426104: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 884 of 14279\n",
            "2025-03-22 22:16:20.489405: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:17:27.990124: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 892 of 14279\n",
            "2025-03-22 22:17:27.990220: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:18:34.386824: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 877 of 14279\n",
            "2025-03-22 22:18:34.591272: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:19:42.875951: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 883 of 14279\n",
            "2025-03-22 22:19:42.970456: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:20:48.009196: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 892 of 14279\n",
            "2025-03-22 22:20:48.009315: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:21:56.479593: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 878 of 14279\n",
            "2025-03-22 22:21:56.679902: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:23:02.973615: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 886 of 14279\n",
            "2025-03-22 22:23:03.010496: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:24:10.885128: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 875 of 14279\n",
            "2025-03-22 22:24:11.088484: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 20, train_loss: 0.005, train_MSE: 0.044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-22 22:26:24.262512: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 874 of 14279\n",
            "2025-03-22 22:26:24.543423: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:27:31.000347: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 863 of 14279\n",
            "2025-03-22 22:27:31.559734: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:28:38.807451: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 874 of 14279\n",
            "2025-03-22 22:28:39.122210: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:29:46.380778: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 869 of 14279\n",
            "2025-03-22 22:29:46.770154: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:30:54.585779: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 858 of 14279\n",
            "2025-03-22 22:30:55.166868: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:32:01.802232: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 844 of 14279\n",
            "2025-03-22 22:32:02.820309: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:33:10.297465: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 876 of 14279\n",
            "2025-03-22 22:33:10.524747: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
            "2025-03-22 22:34:20.525911: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:12: Filling up shuffle buffer (this may take a while): 853 of 14279\n",
            "2025-03-22 22:34:21.398526: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('car_unfrozen_regression_mobv3.weights.h5')\n",
        "# model.save_weights('/home/ppytr13/car_unfrozen.weights.h5')"
      ],
      "metadata": {
        "id": "O14u6175RLjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Test-Set Predictions\n",
        "\n",
        "a) load in test data\n",
        "\n",
        "b) convert test images to numerical RGB feature maps\n",
        "\n",
        "c) generate predictions on the test set\n",
        "\n",
        "d) correctly format the predictions into a pandas dataframe\n",
        "\n",
        "e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ],
      "metadata": {
        "id": "GCbo4VcLxLgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3a) load in test data"
      ],
      "metadata": {
        "id": "HnygDJsKxYhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data'\n",
        "# image_folder_path = '/home/ppyt13/machine-learning-in-science-ii-2025/test_data/test_data' # tylers file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'\n",
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "id": "W-e59lQQRXKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "aa8566ec-e472-47a6-c7a0-92266b567a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                              image_file_paths\n",
              "image_id                                                                                      \n",
              "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/1.png\n",
              "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/2.png\n",
              "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/3.png\n",
              "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/4.png\n",
              "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/5.png"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3b) convert test images to numerical RGB feature maps"
      ],
      "metadata": {
        "id": "t-9i5trTyDTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image_no_label(image_path, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
        "    image = tf.image.resize(image, resized_shape)  # Resize to uniform shape\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((imagefilepaths_df[\"image_file_paths\"]))\n",
        "\n",
        "test_dataset = test_dataset.map(process_image_no_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "3hT_c1s5TAR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3c) generate predictions on test set"
      ],
      "metadata": {
        "id": "gobnK7PhyLa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "NtqcOFr7TAXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b4c96b-51bf-4e1c-e1b6-e8cde1321984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "I0000 00:00:1742682921.026793 2746582 service.cc:146] XLA service 0x7fb015a9b510 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1742682921.026938 2746582 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
            "I0000 00:00:1742682921.026947 2746582 service.cc:154]   StreamExecutor device (1): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
            "2025-03-22 22:35:21.566490: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:51\u001b[0m 7s/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "I0000 00:00:1742682927.198671 2746582 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 251ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3d) correctly format the predictions into a pandas dataframe"
      ],
      "metadata": {
        "id": "zT1LJxHTPeQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = pd.DataFrame(predictions, columns=['angle'])"
      ],
      "metadata": {
        "id": "pFVWGi04fza7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "OnO0K1rReHOT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d9cebb2e-3d36-4c7a-b024-eabb646e3bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      angle\n",
              "0  0.564235\n",
              "1  0.770255\n",
              "2  0.089251\n",
              "3  0.105641\n",
              "4  0.157410"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.564235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.770255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.089251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.105641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.157410</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df['angle'].value_counts()"
      ],
      "metadata": {
        "id": "4CcRKL9KTAfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277533cd-06aa-4709-d44e-9027cc7e9438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "angle\n",
              " 0.104878    1\n",
              " 0.564235    1\n",
              " 0.770255    1\n",
              " 0.089251    1\n",
              " 0.105641    1\n",
              " 0.157410    1\n",
              " 0.733514    1\n",
              " 0.720006    1\n",
              " 0.775421    1\n",
              " 0.595013    1\n",
              " 0.495358    1\n",
              " 0.482492    1\n",
              " 0.741372    1\n",
              " 0.467921    1\n",
              " 0.547928    1\n",
              " 0.273957    1\n",
              " 0.662391    1\n",
              " 0.518453    1\n",
              " 0.729182    1\n",
              " 0.438258    1\n",
              " 0.100113    1\n",
              " 0.917309    1\n",
              " 0.083302    1\n",
              " 0.250500    1\n",
              " 0.733548    1\n",
              " 0.725242    1\n",
              " 0.781992    1\n",
              " 0.627124    1\n",
              " 0.737834    1\n",
              " 0.537647    1\n",
              " 0.646249    1\n",
              " 0.700442    1\n",
              " 0.734939    1\n",
              " 0.086361    1\n",
              " 0.522180    1\n",
              " 0.695654    1\n",
              " 0.570149    1\n",
              " 0.489313    1\n",
              " 0.693735    1\n",
              " 0.591150    1\n",
              " 0.283893    1\n",
              " 0.803771    1\n",
              " 0.779166    1\n",
              " 0.816172    1\n",
              " 0.622035    1\n",
              " 0.448835    1\n",
              " 0.672856    1\n",
              " 0.501566    1\n",
              " 0.628237    1\n",
              " 0.318401    1\n",
              " 0.786581    1\n",
              " 0.506678    1\n",
              " 0.641919    1\n",
              " 0.056355    1\n",
              " 0.157306    1\n",
              " 0.049518    1\n",
              " 0.534424    1\n",
              " 0.201620    1\n",
              " 0.514681    1\n",
              " 0.437292    1\n",
              " 0.475499    1\n",
              " 0.479032    1\n",
              " 0.492126    1\n",
              " 0.195413    1\n",
              " 0.578841    1\n",
              " 0.276897    1\n",
              " 0.486753    1\n",
              " 0.433259    1\n",
              " 0.793278    1\n",
              " 0.246585    1\n",
              " 0.534787    1\n",
              " 0.732252    1\n",
              " 0.774183    1\n",
              " 0.673986    1\n",
              " 0.644497    1\n",
              " 0.304146    1\n",
              " 0.437928    1\n",
              " 0.698094    1\n",
              " 0.462068    1\n",
              " 0.693832    1\n",
              " 0.718600    1\n",
              " 0.695712    1\n",
              " 0.672986    1\n",
              " 0.769024    1\n",
              " 0.706931    1\n",
              " 0.475417    1\n",
              " 0.791767    1\n",
              " 0.739276    1\n",
              " 0.720626    1\n",
              " 0.668491    1\n",
              " 0.548136    1\n",
              " 0.627893    1\n",
              " 0.623526    1\n",
              " 0.596189    1\n",
              " 0.841857    1\n",
              " 0.683620    1\n",
              " 0.383508    1\n",
              " 0.551374    1\n",
              " 0.665541    1\n",
              " 0.490072    1\n",
              " 0.760093    1\n",
              " 0.758959    1\n",
              " 0.441760    1\n",
              " 0.514447    1\n",
              " 0.703191    1\n",
              " 0.486968    1\n",
              " 0.612734    1\n",
              " 0.509691    1\n",
              " 0.767972    1\n",
              " 0.751072    1\n",
              " 0.423360    1\n",
              " 0.551084    1\n",
              " 0.322527    1\n",
              " 0.614648    1\n",
              " 0.512390    1\n",
              " 0.178737    1\n",
              " 0.805164    1\n",
              " 0.236259    1\n",
              " 0.696928    1\n",
              " 0.463993    1\n",
              " 0.358613    1\n",
              " 0.652805    1\n",
              " 0.484027    1\n",
              " 0.643102    1\n",
              " 0.393538    1\n",
              " 0.513937    1\n",
              " 0.750436    1\n",
              " 0.673247    1\n",
              " 0.586237    1\n",
              " 0.506481    1\n",
              " 0.584516    1\n",
              " 0.573122    1\n",
              " 0.689512    1\n",
              " 0.170842    1\n",
              " 0.530358    1\n",
              " 0.316194    1\n",
              " 0.504660    1\n",
              " 0.767040    1\n",
              " 0.416758    1\n",
              " 0.497179    1\n",
              " 0.774083    1\n",
              " 0.623741    1\n",
              " 0.775810    1\n",
              " 0.693345    1\n",
              " 0.418253    1\n",
              " 0.685169    1\n",
              " 0.463556    1\n",
              " 0.680771    1\n",
              " 0.051314    1\n",
              " 0.730466    1\n",
              " 0.490016    1\n",
              " 0.098002    1\n",
              " 0.264771    1\n",
              " 0.514643    1\n",
              " 0.690929    1\n",
              " 0.345023    1\n",
              " 0.410248    1\n",
              " 0.748002    1\n",
              " 0.487623    1\n",
              " 0.484681    1\n",
              " 0.485288    1\n",
              " 0.793969    1\n",
              " 0.327963    1\n",
              " 0.611073    1\n",
              " 0.720098    1\n",
              " 0.448240    1\n",
              " 0.453849    1\n",
              " 0.465460    1\n",
              " 0.637591    1\n",
              " 0.779405    1\n",
              " 0.508005    1\n",
              " 0.378434    1\n",
              " 0.608414    1\n",
              " 0.187870    1\n",
              " 0.533000    1\n",
              " 0.508389    1\n",
              "-0.013185    1\n",
              " 0.729536    1\n",
              " 0.517252    1\n",
              " 0.545081    1\n",
              " 0.677584    1\n",
              " 0.757755    1\n",
              " 0.631351    1\n",
              " 0.017407    1\n",
              " 0.872068    1\n",
              " 0.444923    1\n",
              " 0.724984    1\n",
              " 0.780860    1\n",
              " 0.677935    1\n",
              " 0.413000    1\n",
              " 0.742207    1\n",
              " 0.662560    1\n",
              " 0.723962    1\n",
              " 0.638516    1\n",
              " 0.680596    1\n",
              " 0.687654    1\n",
              " 0.368845    1\n",
              " 0.763382    1\n",
              " 0.648521    1\n",
              " 0.485744    1\n",
              " 0.032067    1\n",
              " 0.674194    1\n",
              " 0.783880    1\n",
              " 0.646678    1\n",
              " 0.668063    1\n",
              " 0.454303    1\n",
              " 0.758877    1\n",
              " 0.543036    1\n",
              " 0.517610    1\n",
              " 0.795606    1\n",
              " 0.635058    1\n",
              " 0.168759    1\n",
              " 0.699676    1\n",
              " 0.755121    1\n",
              " 0.508658    1\n",
              " 0.499475    1\n",
              " 0.537312    1\n",
              " 0.458462    1\n",
              " 0.474053    1\n",
              " 0.174115    1\n",
              " 0.492204    1\n",
              " 0.055272    1\n",
              " 0.547937    1\n",
              "-0.025087    1\n",
              " 0.748369    1\n",
              " 0.774277    1\n",
              " 0.478990    1\n",
              " 0.602425    1\n",
              " 0.229235    1\n",
              " 0.622515    1\n",
              " 0.414795    1\n",
              " 0.577582    1\n",
              " 0.387399    1\n",
              " 0.737907    1\n",
              " 0.688237    1\n",
              " 0.742206    1\n",
              " 0.440364    1\n",
              " 0.088092    1\n",
              " 0.487907    1\n",
              " 0.454843    1\n",
              " 0.789424    1\n",
              " 0.485722    1\n",
              " 0.706262    1\n",
              " 0.780705    1\n",
              " 0.734151    1\n",
              " 0.725481    1\n",
              " 0.743154    1\n",
              " 0.016681    1\n",
              " 0.175738    1\n",
              " 0.807743    1\n",
              " 0.061421    1\n",
              " 0.781983    1\n",
              " 0.709588    1\n",
              " 0.544996    1\n",
              " 0.764043    1\n",
              " 0.541136    1\n",
              " 0.534861    1\n",
              " 0.742428    1\n",
              " 0.193395    1\n",
              " 0.627375    1\n",
              " 0.712932    1\n",
              " 0.186096    1\n",
              " 0.770764    1\n",
              " 0.136640    1\n",
              " 0.746449    1\n",
              " 0.705050    1\n",
              " 0.632968    1\n",
              " 0.119031    1\n",
              " 0.765530    1\n",
              " 0.690629    1\n",
              " 0.787263    1\n",
              " 0.700087    1\n",
              " 0.577763    1\n",
              " 0.709563    1\n",
              " 0.643772    1\n",
              " 0.868198    1\n",
              " 0.692787    1\n",
              " 0.790524    1\n",
              " 0.592768    1\n",
              " 0.704258    1\n",
              " 0.629913    1\n",
              " 0.799421    1\n",
              " 0.125538    1\n",
              " 0.472944    1\n",
              " 0.466568    1\n",
              " 0.635931    1\n",
              " 0.934011    1\n",
              " 0.106038    1\n",
              " 0.791838    1\n",
              " 0.756115    1\n",
              " 0.243623    1\n",
              " 0.502331    1\n",
              " 0.632479    1\n",
              " 0.401946    1\n",
              " 0.853662    1\n",
              " 0.652364    1\n",
              " 0.180575    1\n",
              " 0.571161    1\n",
              " 0.779435    1\n",
              " 0.683084    1\n",
              " 0.482322    1\n",
              " 0.743044    1\n",
              " 0.807463    1\n",
              " 0.494689    1\n",
              " 0.524235    1\n",
              " 0.499253    1\n",
              " 0.446907    1\n",
              " 0.517932    1\n",
              " 0.505003    1\n",
              " 0.630738    1\n",
              " 0.515496    1\n",
              " 0.529878    1\n",
              " 0.458271    1\n",
              " 0.621343    1\n",
              " 0.606616    1\n",
              " 0.769101    1\n",
              " 0.396050    1\n",
              " 0.669299    1\n",
              " 0.487085    1\n",
              " 0.687514    1\n",
              " 0.442559    1\n",
              " 0.730639    1\n",
              " 0.538528    1\n",
              " 0.689870    1\n",
              " 0.703744    1\n",
              " 0.610389    1\n",
              " 0.705087    1\n",
              " 0.197248    1\n",
              " 0.328071    1\n",
              " 0.733492    1\n",
              " 0.780645    1\n",
              " 0.506202    1\n",
              " 0.756245    1\n",
              " 0.551424    1\n",
              " 0.030560    1\n",
              " 0.791635    1\n",
              " 0.785867    1\n",
              " 0.793837    1\n",
              " 0.795755    1\n",
              " 0.555126    1\n",
              " 0.770451    1\n",
              " 0.162460    1\n",
              " 0.460805    1\n",
              " 0.499839    1\n",
              " 0.539891    1\n",
              " 0.515294    1\n",
              " 0.716127    1\n",
              " 0.736958    1\n",
              " 0.492506    1\n",
              " 0.445714    1\n",
              " 0.506459    1\n",
              " 0.005055    1\n",
              " 0.764967    1\n",
              " 0.486450    1\n",
              " 0.701713    1\n",
              " 0.638801    1\n",
              " 0.668314    1\n",
              " 0.419545    1\n",
              " 0.714878    1\n",
              " 0.767198    1\n",
              " 0.509403    1\n",
              " 0.490748    1\n",
              " 0.455353    1\n",
              " 0.554862    1\n",
              " 0.480164    1\n",
              " 0.375268    1\n",
              " 0.750220    1\n",
              " 0.774378    1\n",
              " 0.839660    1\n",
              " 0.600761    1\n",
              " 0.913212    1\n",
              " 0.523369    1\n",
              " 0.602830    1\n",
              " 0.779647    1\n",
              " 0.538816    1\n",
              " 0.509530    1\n",
              " 0.460755    1\n",
              " 0.446291    1\n",
              " 0.555167    1\n",
              " 0.308709    1\n",
              " 0.570323    1\n",
              " 0.512538    1\n",
              " 0.568748    1\n",
              " 0.714993    1\n",
              " 0.094930    1\n",
              " 0.722438    1\n",
              " 0.789495    1\n",
              " 0.544349    1\n",
              " 0.094123    1\n",
              " 0.713342    1\n",
              " 0.540670    1\n",
              " 0.730917    1\n",
              " 0.280450    1\n",
              " 0.719076    1\n",
              " 0.128978    1\n",
              " 0.402144    1\n",
              " 0.496036    1\n",
              " 0.627452    1\n",
              " 0.159382    1\n",
              " 0.514249    1\n",
              " 0.531356    1\n",
              " 0.487710    1\n",
              " 0.430977    1\n",
              " 0.127330    1\n",
              " 0.378623    1\n",
              " 0.901913    1\n",
              " 0.594010    1\n",
              " 0.479441    1\n",
              " 0.705711    1\n",
              " 0.721091    1\n",
              " 0.536565    1\n",
              " 0.010137    1\n",
              " 0.461162    1\n",
              " 0.473683    1\n",
              " 0.721573    1\n",
              " 0.144151    1\n",
              " 0.485748    1\n",
              " 0.069607    1\n",
              " 0.185539    1\n",
              " 0.733820    1\n",
              " 0.790522    1\n",
              " 0.495512    1\n",
              " 0.705517    1\n",
              " 0.093651    1\n",
              " 0.709541    1\n",
              " 0.645040    1\n",
              " 0.550258    1\n",
              " 0.548476    1\n",
              " 0.672055    1\n",
              " 0.710921    1\n",
              " 0.772837    1\n",
              " 0.383845    1\n",
              " 0.654422    1\n",
              " 0.416751    1\n",
              " 0.490984    1\n",
              " 0.453387    1\n",
              " 0.718415    1\n",
              " 0.782249    1\n",
              " 0.555897    1\n",
              " 0.785871    1\n",
              " 0.702714    1\n",
              " 0.682557    1\n",
              " 0.766726    1\n",
              " 0.327673    1\n",
              " 0.850512    1\n",
              " 0.570804    1\n",
              " 0.690137    1\n",
              " 0.506911    1\n",
              " 0.074745    1\n",
              " 0.501079    1\n",
              " 0.657560    1\n",
              " 0.022867    1\n",
              " 0.721640    1\n",
              " 0.685322    1\n",
              " 0.221849    1\n",
              " 0.627428    1\n",
              " 0.750456    1\n",
              " 0.728933    1\n",
              " 0.683302    1\n",
              " 0.490000    1\n",
              " 0.512144    1\n",
              " 0.661400    1\n",
              " 0.756203    1\n",
              " 0.687848    1\n",
              " 0.256435    1\n",
              " 0.400986    1\n",
              " 0.574745    1\n",
              " 0.178138    1\n",
              " 0.530228    1\n",
              " 0.776509    1\n",
              " 0.624851    1\n",
              " 0.544613    1\n",
              " 0.729931    1\n",
              " 0.862564    1\n",
              " 0.642748    1\n",
              " 0.620544    1\n",
              " 0.618212    1\n",
              " 0.701669    1\n",
              " 0.519451    1\n",
              " 0.454259    1\n",
              " 0.768531    1\n",
              " 0.688414    1\n",
              " 0.746185    1\n",
              " 0.468966    1\n",
              " 0.416236    1\n",
              " 0.693569    1\n",
              " 0.542594    1\n",
              " 0.235648    1\n",
              " 0.681599    1\n",
              " 0.123132    1\n",
              " 0.612500    1\n",
              " 0.499920    1\n",
              " 0.777044    1\n",
              " 0.474263    1\n",
              " 0.459797    1\n",
              " 0.630335    1\n",
              " 0.262866    1\n",
              " 0.515805    1\n",
              " 0.226382    1\n",
              " 0.675891    1\n",
              " 0.807016    1\n",
              " 0.416911    1\n",
              " 0.807285    1\n",
              " 0.482325    1\n",
              " 0.706514    1\n",
              " 0.583981    1\n",
              " 0.708726    1\n",
              " 0.445150    1\n",
              " 0.722282    1\n",
              " 0.645656    1\n",
              " 0.534748    1\n",
              " 0.802367    1\n",
              " 0.735876    1\n",
              " 0.777075    1\n",
              " 0.512516    1\n",
              " 0.266641    1\n",
              " 0.664998    1\n",
              " 0.463371    1\n",
              " 0.505867    1\n",
              " 0.620731    1\n",
              " 0.449927    1\n",
              " 0.608765    1\n",
              " 0.734872    1\n",
              " 0.206026    1\n",
              " 0.758665    1\n",
              " 0.005771    1\n",
              " 0.547217    1\n",
              " 0.591140    1\n",
              " 0.723974    1\n",
              " 0.320030    1\n",
              " 0.631754    1\n",
              " 0.419728    1\n",
              " 0.474892    1\n",
              " 0.566629    1\n",
              " 0.745458    1\n",
              " 0.626563    1\n",
              " 0.722622    1\n",
              " 0.682297    1\n",
              " 0.398527    1\n",
              " 0.525636    1\n",
              " 0.746181    1\n",
              " 0.435346    1\n",
              " 0.537222    1\n",
              " 0.675208    1\n",
              " 0.459381    1\n",
              " 0.504757    1\n",
              " 0.514880    1\n",
              " 0.523090    1\n",
              " 0.036485    1\n",
              " 0.480226    1\n",
              " 0.697847    1\n",
              " 0.501784    1\n",
              " 0.492422    1\n",
              " 0.735485    1\n",
              " 0.666796    1\n",
              " 0.719900    1\n",
              " 0.698659    1\n",
              " 0.499673    1\n",
              " 0.403829    1\n",
              " 0.093503    1\n",
              " 0.188458    1\n",
              " 0.739906    1\n",
              " 0.144482    1\n",
              " 0.796067    1\n",
              " 0.197891    1\n",
              " 0.684740    1\n",
              " 0.893117    1\n",
              " 0.576359    1\n",
              " 0.475374    1\n",
              " 0.788742    1\n",
              " 0.439425    1\n",
              " 0.475015    1\n",
              " 0.793503    1\n",
              " 0.492601    1\n",
              " 0.712735    1\n",
              " 0.542492    1\n",
              " 0.731429    1\n",
              " 0.542219    1\n",
              " 0.262068    1\n",
              " 0.663813    1\n",
              " 0.479286    1\n",
              " 0.471000    1\n",
              " 0.843365    1\n",
              " 0.666942    1\n",
              " 0.508051    1\n",
              " 0.677716    1\n",
              " 0.199621    1\n",
              "-0.046672    1\n",
              " 0.467630    1\n",
              " 0.432895    1\n",
              " 0.126831    1\n",
              " 0.647905    1\n",
              " 0.639932    1\n",
              " 0.545140    1\n",
              " 0.689215    1\n",
              " 0.507894    1\n",
              " 0.827115    1\n",
              " 0.767734    1\n",
              " 0.212317    1\n",
              " 0.905387    1\n",
              " 0.832215    1\n",
              " 0.713098    1\n",
              " 0.463295    1\n",
              " 0.439990    1\n",
              " 0.604782    1\n",
              " 0.500359    1\n",
              " 0.757206    1\n",
              " 0.444060    1\n",
              " 0.717695    1\n",
              " 0.197593    1\n",
              " 0.437554    1\n",
              " 0.526291    1\n",
              " 0.789126    1\n",
              " 0.516371    1\n",
              " 0.621221    1\n",
              " 0.750970    1\n",
              " 0.235992    1\n",
              " 0.521309    1\n",
              " 0.114949    1\n",
              " 0.818083    1\n",
              " 0.643489    1\n",
              " 0.537987    1\n",
              " 0.623936    1\n",
              " 0.728751    1\n",
              " 0.731789    1\n",
              " 0.770246    1\n",
              " 0.477696    1\n",
              " 0.497030    1\n",
              " 0.500503    1\n",
              " 0.101856    1\n",
              " 0.795558    1\n",
              " 0.573725    1\n",
              " 0.254037    1\n",
              " 0.699469    1\n",
              " 0.083149    1\n",
              " 0.784491    1\n",
              " 0.778022    1\n",
              " 0.470570    1\n",
              " 0.715558    1\n",
              " 0.626995    1\n",
              " 0.508935    1\n",
              " 0.459571    1\n",
              " 0.269000    1\n",
              " 0.460321    1\n",
              " 0.387114    1\n",
              " 0.707439    1\n",
              " 0.473774    1\n",
              " 0.593863    1\n",
              " 0.392632    1\n",
              " 0.500669    1\n",
              " 0.725801    1\n",
              " 0.704700    1\n",
              " 0.697771    1\n",
              " 0.645875    1\n",
              " 0.642329    1\n",
              " 0.435052    1\n",
              " 0.517906    1\n",
              " 0.529146    1\n",
              " 0.645045    1\n",
              " 0.631314    1\n",
              " 0.652345    1\n",
              " 0.448474    1\n",
              " 0.540842    1\n",
              " 0.751087    1\n",
              " 0.784689    1\n",
              " 0.685056    1\n",
              " 0.618593    1\n",
              " 0.717553    1\n",
              " 0.421104    1\n",
              " 0.153347    1\n",
              " 0.185024    1\n",
              " 0.687335    1\n",
              " 0.494889    1\n",
              " 0.635313    1\n",
              " 0.493652    1\n",
              " 0.397493    1\n",
              " 0.690362    1\n",
              " 0.646307    1\n",
              " 0.698533    1\n",
              " 0.366030    1\n",
              " 0.754316    1\n",
              " 0.484033    1\n",
              " 0.750251    1\n",
              " 0.410072    1\n",
              " 0.315044    1\n",
              " 0.733844    1\n",
              " 0.652365    1\n",
              " 0.573988    1\n",
              " 0.698090    1\n",
              " 0.702560    1\n",
              " 0.225671    1\n",
              " 0.478830    1\n",
              " 0.452450    1\n",
              " 0.498696    1\n",
              " 0.212590    1\n",
              " 0.746235    1\n",
              " 0.683859    1\n",
              " 0.612627    1\n",
              " 0.460987    1\n",
              " 0.204597    1\n",
              " 0.781372    1\n",
              " 0.690569    1\n",
              " 0.677785    1\n",
              " 0.680968    1\n",
              " 0.012956    1\n",
              " 0.481912    1\n",
              " 0.506799    1\n",
              " 0.518532    1\n",
              " 0.291283    1\n",
              " 0.619541    1\n",
              " 0.228035    1\n",
              " 0.560621    1\n",
              " 0.661272    1\n",
              " 0.089182    1\n",
              " 0.730529    1\n",
              " 0.700143    1\n",
              " 0.067457    1\n",
              " 0.737358    1\n",
              " 0.070569    1\n",
              " 0.082164    1\n",
              " 0.332229    1\n",
              " 0.425309    1\n",
              " 0.523173    1\n",
              " 0.560191    1\n",
              " 0.579639    1\n",
              " 0.397887    1\n",
              " 0.216272    1\n",
              " 0.295631    1\n",
              " 0.710036    1\n",
              " 0.696200    1\n",
              " 0.495588    1\n",
              " 0.769416    1\n",
              " 0.284792    1\n",
              " 0.409301    1\n",
              " 0.124638    1\n",
              " 0.517770    1\n",
              " 0.536884    1\n",
              " 0.493251    1\n",
              " 0.765900    1\n",
              " 0.330584    1\n",
              " 0.241291    1\n",
              " 0.580844    1\n",
              " 0.491606    1\n",
              " 0.122136    1\n",
              " 0.669699    1\n",
              " 0.520626    1\n",
              " 0.737162    1\n",
              " 0.729291    1\n",
              " 0.702802    1\n",
              " 0.604369    1\n",
              " 0.760012    1\n",
              " 0.546413    1\n",
              " 0.638811    1\n",
              " 0.691020    1\n",
              " 0.565364    1\n",
              " 0.754154    1\n",
              " 0.614076    1\n",
              " 0.499654    1\n",
              " 0.209326    1\n",
              " 0.389776    1\n",
              " 0.731526    1\n",
              " 0.915863    1\n",
              " 0.667997    1\n",
              " 0.339403    1\n",
              " 0.691155    1\n",
              " 0.799735    1\n",
              " 0.475950    1\n",
              " 0.283578    1\n",
              " 0.820692    1\n",
              " 0.326624    1\n",
              " 0.536632    1\n",
              " 0.509301    1\n",
              " 0.418944    1\n",
              " 0.521456    1\n",
              " 0.598905    1\n",
              " 0.462802    1\n",
              " 0.134819    1\n",
              " 0.721769    1\n",
              " 0.526563    1\n",
              " 0.777222    1\n",
              " 0.810658    1\n",
              " 0.486825    1\n",
              " 0.704377    1\n",
              " 0.726183    1\n",
              " 0.176748    1\n",
              " 0.479741    1\n",
              " 0.176752    1\n",
              " 0.802552    1\n",
              " 0.745165    1\n",
              " 0.723167    1\n",
              " 0.678157    1\n",
              " 0.453289    1\n",
              " 0.480869    1\n",
              " 0.497871    1\n",
              " 0.919139    1\n",
              " 0.135268    1\n",
              " 0.522461    1\n",
              " 0.767957    1\n",
              " 0.452482    1\n",
              " 0.485223    1\n",
              " 0.723094    1\n",
              " 0.564697    1\n",
              " 0.713067    1\n",
              " 0.957137    1\n",
              " 0.716349    1\n",
              " 0.804660    1\n",
              " 0.255511    1\n",
              " 0.153023    1\n",
              " 0.726499    1\n",
              " 0.798671    1\n",
              " 0.677380    1\n",
              " 0.697593    1\n",
              " 0.594368    1\n",
              " 0.681758    1\n",
              " 0.728465    1\n",
              " 0.508802    1\n",
              " 0.719866    1\n",
              " 0.752657    1\n",
              " 0.765456    1\n",
              " 0.716143    1\n",
              " 0.509590    1\n",
              " 0.773111    1\n",
              " 0.536758    1\n",
              " 0.615093    1\n",
              " 0.593533    1\n",
              " 0.769701    1\n",
              " 0.723722    1\n",
              " 0.168085    1\n",
              " 0.550339    1\n",
              " 0.826861    1\n",
              " 0.616608    1\n",
              " 0.436093    1\n",
              " 0.509343    1\n",
              " 0.414020    1\n",
              " 0.696538    1\n",
              " 0.034896    1\n",
              " 0.722732    1\n",
              " 0.208633    1\n",
              " 0.399050    1\n",
              " 0.516727    1\n",
              " 0.789616    1\n",
              " 0.473219    1\n",
              " 0.738219    1\n",
              " 0.523022    1\n",
              " 0.537906    1\n",
              " 0.552390    1\n",
              " 0.716355    1\n",
              " 0.463542    1\n",
              " 0.510374    1\n",
              " 0.758849    1\n",
              " 0.462469    1\n",
              " 0.518853    1\n",
              " 0.269666    1\n",
              " 0.734502    1\n",
              " 0.677725    1\n",
              " 0.263601    1\n",
              " 0.374753    1\n",
              " 0.743167    1\n",
              " 0.761569    1\n",
              " 0.317838    1\n",
              " 0.765475    1\n",
              " 0.445875    1\n",
              " 0.515576    1\n",
              " 0.737463    1\n",
              " 0.717153    1\n",
              " 0.696376    1\n",
              " 0.463455    1\n",
              " 0.162503    1\n",
              " 0.738612    1\n",
              " 0.489192    1\n",
              " 0.501030    1\n",
              " 0.651697    1\n",
              " 0.471983    1\n",
              " 0.330145    1\n",
              " 0.219098    1\n",
              " 0.655650    1\n",
              " 0.539293    1\n",
              " 0.487960    1\n",
              " 0.525529    1\n",
              " 0.125429    1\n",
              " 0.410701    1\n",
              " 0.277493    1\n",
              " 0.527563    1\n",
              " 0.708413    1\n",
              " 0.718535    1\n",
              " 0.446097    1\n",
              " 0.523222    1\n",
              " 0.417825    1\n",
              " 0.668447    1\n",
              " 0.536841    1\n",
              " 0.522674    1\n",
              " 0.418494    1\n",
              " 0.625317    1\n",
              " 0.536493    1\n",
              " 0.722028    1\n",
              " 0.740887    1\n",
              " 0.508200    1\n",
              " 0.713758    1\n",
              " 0.740912    1\n",
              " 0.490050    1\n",
              " 0.474312    1\n",
              " 0.473828    1\n",
              " 0.699189    1\n",
              " 0.508292    1\n",
              " 0.774069    1\n",
              " 0.578934    1\n",
              " 0.523648    1\n",
              " 0.467919    1\n",
              " 0.712721    1\n",
              " 0.416632    1\n",
              " 0.770449    1\n",
              " 0.827184    1\n",
              " 0.844754    1\n",
              " 0.643082    1\n",
              " 0.752936    1\n",
              " 0.714645    1\n",
              " 0.030760    1\n",
              " 0.223922    1\n",
              " 0.456027    1\n",
              " 0.343496    1\n",
              " 0.597007    1\n",
              " 0.520721    1\n",
              " 0.609377    1\n",
              " 0.510767    1\n",
              " 0.704472    1\n",
              " 0.619752    1\n",
              " 0.512048    1\n",
              " 0.148164    1\n",
              " 0.710578    1\n",
              " 0.713250    1\n",
              " 0.527923    1\n",
              " 0.443350    1\n",
              " 0.096297    1\n",
              " 0.738063    1\n",
              " 0.703849    1\n",
              " 0.545080    1\n",
              " 0.510112    1\n",
              " 0.688238    1\n",
              " 0.211413    1\n",
              " 0.638797    1\n",
              " 0.981424    1\n",
              " 0.930441    1\n",
              " 0.620121    1\n",
              " 0.276741    1\n",
              " 0.267584    1\n",
              " 0.546594    1\n",
              " 0.854561    1\n",
              " 0.133269    1\n",
              " 0.678929    1\n",
              " 0.139228    1\n",
              " 0.105175    1\n",
              " 0.778058    1\n",
              " 0.621196    1\n",
              " 0.704587    1\n",
              " 0.905067    1\n",
              " 0.660875    1\n",
              " 0.686046    1\n",
              " 0.845265    1\n",
              " 0.515306    1\n",
              " 0.504032    1\n",
              " 0.681040    1\n",
              " 0.380692    1\n",
              " 0.535330    1\n",
              " 0.647598    1\n",
              " 0.772418    1\n",
              " 0.482014    1\n",
              "-0.015193    1\n",
              " 0.626963    1\n",
              " 0.637804    1\n",
              " 0.617012    1\n",
              " 0.546965    1\n",
              " 0.568548    1\n",
              " 0.519240    1\n",
              " 0.706117    1\n",
              " 0.807963    1\n",
              "-0.005357    1\n",
              " 0.198957    1\n",
              " 0.647099    1\n",
              " 0.506390    1\n",
              " 0.545105    1\n",
              " 0.619864    1\n",
              " 0.788832    1\n",
              " 0.668499    1\n",
              " 0.741013    1\n",
              " 0.119418    1\n",
              " 0.624594    1\n",
              " 0.508859    1\n",
              " 0.766421    1\n",
              " 0.738361    1\n",
              " 0.829003    1\n",
              " 0.731611    1\n",
              " 0.730013    1\n",
              " 0.545433    1\n",
              " 0.695468    1\n",
              " 0.199733    1\n",
              " 0.799715    1\n",
              " 0.033227    1\n",
              " 0.695210    1\n",
              " 0.766251    1\n",
              " 0.629730    1\n",
              " 0.753577    1\n",
              " 0.833198    1\n",
              " 0.665365    1\n",
              " 0.770607    1\n",
              " 0.535777    1\n",
              " 0.801589    1\n",
              " 0.604892    1\n",
              " 0.731256    1\n",
              " 0.838283    1\n",
              " 0.580408    1\n",
              " 0.068974    1\n",
              " 0.493879    1\n",
              " 0.618466    1\n",
              " 0.761040    1\n",
              " 0.470717    1\n",
              " 0.749776    1\n",
              " 0.651038    1\n",
              " 0.762141    1\n",
              " 0.599394    1\n",
              " 0.691719    1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ],
      "metadata": {
        "id": "oU-PhskZPaHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.to_csv('/home/apyba3/mbnetv3_angleregression_predictions_novalidation_extraaug_petru.csv')"
      ],
      "metadata": {
        "id": "deXjPTO0TAiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsp7UPIJQlKB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}