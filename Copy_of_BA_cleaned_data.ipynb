{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/Copy_of_BA_cleaned_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# remember to switch to t4 gpu"
      ],
      "metadata": {
        "id": "-fhwRSFoj6C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "g4V83PflfFkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "TQaguh4pClYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy tensorflow scikit-learn matplotlib\n"
      ],
      "metadata": {
        "id": "m5KXVTl2DFBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow  # For image processing\n"
      ],
      "metadata": {
        "id": "BNgqD_58D-XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP6UczzNe1l2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) DATA PRE-PROCESSING\n",
        "\n",
        "a) Load in labels + image file paths\n",
        "\n",
        "b) combine them into one dataframe\n",
        "\n",
        "c) EDA - spotted and removed erroneous label (speed = 1.42...)\n",
        "\n",
        "## `cleaned_df` is the final df with all of this completed"
      ],
      "metadata": {
        "id": "-_MvRvYnfIM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "imfZR11CjvO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a) load in labels + image file paths"
      ],
      "metadata": {
        "id": "HU3TvBZ5hfhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dir_path = \"/Users/jmarsh/Library/Mobile Documents/com~apple~CloudDocs/UoN MCiS/MLiS part 2\"\n",
        "\n",
        "# List all files in the directory\n",
        "print(os.listdir(dir_path))\n"
      ],
      "metadata": {
        "id": "FJRJLdjlEWqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/Users/jmarsh/Documents/machine-learning-in-science-ii-2025/training_data/training_data\""
      ],
      "metadata": {
        "id": "HtqesjGfGazt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_file_path = \"/Users/jmarsh/Documents/machine-learning-in-science-ii-2025/training_norm.csv\"\n",
        "#labels_file_path = '/content/drive/MyDrive/0. MSc MLiS/google SPRINGrary/Mobile Documents/com~apple~CloudDocs/ SEMESTER/1. PHYS4036 MLiS2/MLiS2 Project/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv'\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ],
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image_folder_path = '/content/drive/MyDrive/0. MSc MLiS/google SPRING SEMESTER/1. PHYS4036 MLiS2/MLiS2 Project/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data'\n",
        "image_folder_path = '/Users/jmarsh/Documents/machine-learning-in-science-ii-2025/training_data/training_data'\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ],
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking labels dataframe"
      ],
      "metadata": {
        "id": "0oeuvmeZaGSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.head()"
      ],
      "metadata": {
        "id": "2pi13TZ2aFhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
      ],
      "metadata": {
        "id": "puEjGoOJaRS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "id": "a1suFSK7aWKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b) Combine labels and image file paths into one dataframe"
      ],
      "metadata": {
        "id": "CjDdyYd6cMBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
        "merged_df['speed'] = merged_df['speed'].round(6) # to get rid of floating point errors"
      ],
      "metadata": {
        "id": "6NdbonzPcLKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head()"
      ],
      "metadata": {
        "id": "-VstirIAdAZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.loc[3139:3143]"
      ],
      "metadata": {
        "id": "8MgNoL8nfBm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above cell shows that:\n",
        "\n",
        " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
        "\n",
        " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
      ],
      "metadata": {
        "id": "U7PCxqJbmXE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c) EDA"
      ],
      "metadata": {
        "id": "h3OKLcn9u0Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.value_counts('speed')"
      ],
      "metadata": {
        "id": "IWQCQrR-oCps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "note: imbalance datset"
      ],
      "metadata": {
        "id": "K4pZ65pYvdqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "identifying the row with the erroneous speed value"
      ],
      "metadata": {
        "id": "xJmG7jmNkE0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df[merged_df['speed'] == 1.428571]"
      ],
      "metadata": {
        "id": "wAQnbLLeiqy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to remove this row"
      ],
      "metadata": {
        "id": "zMZq41-RkLz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = merged_df[merged_df['speed'] != 1.428571]\n",
        "cleaned_df.loc[3882:3886]"
      ],
      "metadata": {
        "id": "TDMqIiOLSKGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## convert from pandas to tf\n"
      ],
      "metadata": {
        "id": "Di6F6km_DBmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
        "    image = tf.image.resize(image, (128, 128))  # Resize to uniform shape\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image, label\n",
        "\n",
        "# Convert DataFrame into a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"speed\"]))\n",
        "\n",
        "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(len(cleaned_df))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "for images, labels in dataset.take(1):\n",
        "    print(images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "oeeBTruNCQ96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "# Split into training and test sets\n",
        "train_dataset = dataset.take(train_size)\n",
        "validation_dataset = dataset.skip(train_size)\n",
        "\n",
        "#not using test set as kaggle is our test set\n",
        "\n",
        "print(f\"Train size: {train_size}, Test size: {dataset_size - train_size}\")"
      ],
      "metadata": {
        "id": "yYlssPh5dxaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataset.take(1):\n",
        "    print(batch)"
      ],
      "metadata": {
        "id": "OeboVhsQKGFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 2\n",
        "input_shape = (128,128,3)\n",
        "\n",
        "mbnet =  tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = False # freeze the first layers to the imagenet weights\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "Eh1-U-VYeN9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  tape.reset() #this resets the gradient tape"
      ],
      "metadata": {
        "id": "DX-wcs04eUTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.001 #learning rate\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser\n",
        "\n",
        "@tf.function\n",
        "def train_step( model, X , Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model( X )\n",
        "        current_loss = tf.reduce_mean(tf.losses.categorical_crossentropy( Y,  pred))\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients( zip( grads , model.trainable_variables) )\n",
        "    current_accuracy = tf.reduce_mean(tf.metrics.categorical_accuracy(Y, pred))\n",
        "    return(current_loss, current_accuracy)"
      ],
      "metadata": {
        "id": "9AErZvcTeX-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 20\n",
        "\n",
        "tloss = []\n",
        "tacc = []\n",
        "vloss = []\n",
        "vacc = []\n",
        "\n",
        "for it in range(niter):\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "      #for image, label in zip(image_batch, label_batch):\n",
        "        #print(image)\n",
        "        #print(label)\n",
        "        #print(image.shape, label.shape)\n",
        "\n",
        "        loss, acc = train_step(model, image_batch, tf.one_hot(tf.cast(label_batch, dtype=tf.int32), depth=2)) #run training\n",
        "\n",
        "\n",
        "    if it % 10 == 0: #log training metrics\n",
        "      tf.print('iter: ',it, ', loss: {:.3f}, acc: {:.3f}'.format(loss, acc))\n",
        "      tloss.append(loss)\n",
        "      tacc.append(acc)\n",
        "'we should probably switch to balanced accuracy as eval method due to unbalanced data'\n",
        "#commented out validation for now as it prints for each batch not each epoch massively slowwing process\n",
        "'''\n",
        "    if it % 50 == 0: #log validation metrics\n",
        "      for val_image, val_label in validation_dataset:\n",
        "        val_pred = model(val_image)\n",
        "        val_int=tf.cast(val_label, dtype=tf.int32)\n",
        "        val_loss = tf.reduce_mean(tf.losses.categorical_crossentropy(tf.one_hot(val_int,depth=2) , val_pred))\n",
        "        val_acc = tf.reduce_mean(tf.metrics.categorical_accuracy(tf.one_hot(val_int,depth=2) , val_pred))\n",
        "        tf.print('iter: ',it, ', validation loss: {:.3f}, validation acc: {:.3f}'.format(val_loss, val_acc))\n",
        "        vloss.append(val_loss)\n",
        "        vacc.append(val_acc)\n",
        "'''"
      ],
      "metadata": {
        "id": "uE2K4gVQedXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "f, axarr = plt.subplots(1,10)\n",
        "\n",
        "i = 0\n",
        "for image_batch, label_batch in dataset.take(1):  # Take one batch\n",
        "    for image in image_batch:  # Iterate through images in the batch\n",
        "        if i < 10:  # Only display the first 5 images\n",
        "            print('image shape: ', np.shape(image))\n",
        "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
        "            axarr[i].imshow(image)\n",
        "            axarr[i].axis('off')\n",
        "            i += 1\n",
        "        else:\n",
        "            break  # Stop after displaying 5 images"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "bU7lQg55Mgqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# add data augmentation steps here"
      ],
      "metadata": {
        "id": "mUBDSjsLNMmT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2sK8FpOKw_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transfer learning here"
      ],
      "metadata": {
        "id": "ynpaLJEeNRtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "#installing the extra packages that we need\n",
        "\n",
        "\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0  # Normalize pixel values\n",
        "\n",
        "# convert labells to the categorical format\n",
        "num_classes = 10\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "# load pre-trained MobileNetV2 model without top layers\n",
        "base_model = MobileNetV2(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "# adding customn layers on top\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# compileing model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# training model\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# plot accuracy and loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "plt.show()\n",
        "\n",
        "# evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "id": "BWQC4CWwNXV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "image_folder = \"/Users/jmarsh/Documents/machine-learning-in-science-ii-2025/training_data/training_data\"\n",
        "label_file = \"/Users/jmarsh/Documents/machine-learning-in-science-ii-2025/training_norm.csv\"\n",
        "\n",
        "\n",
        "def load_data(image_folder, label_file):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    with open(label_file, 'r') as f:\n",
        "        # Skips the headder\n",
        "        next(f)\n",
        "\n",
        "        for line in f:\n",
        "            parts = line.strip().split(',')\n",
        "            image_path = os.path.join(image_folder, parts[0])  # Assuming first column is image filename\n",
        "\n",
        "            try:\n",
        "                steering_angle = float(parts[1])\n",
        "                speed = float(parts[2])  # Assuming third column is speed\n",
        "            except ValueError:\n",
        "                print(f\"Skipping invalid line: {line.strip()}\")  # Skip lines with invalid data\n",
        "                continue\n",
        "\n",
        "            # Check if the image exists\n",
        "            if not os.path.exists(image_path):\n",
        "                print(f\"Image not found: {image_path}\")\n",
        "                continue  # Skip if the image doesn't exist\n",
        "\n",
        "            img = cv2.imread(image_path)\n",
        "\n",
        "            # Check if the image was loaded properly\n",
        "            if img is None:\n",
        "                print(f\"Failed to load image: {image_path}\")\n",
        "                continue  # Skip if the image is invalid\n",
        "\n",
        "            img = cv2.resize(img, (128, 128))  # are we doing 320 x 320 ?\n",
        "            img = img / 255.0  # normalize pixel value. also not sure if this is the correct normalisation?\n",
        "\n",
        "            images.append(img)\n",
        "            labels.append([steering_angle, speed])\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "# Loaddoming images and labels\n",
        "X, y = load_data(image_folder, label_file)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "split = int(0.8 * len(X))\n",
        "X_train, X_val = X[:split], X[split:]\n",
        "y_train, y_val = y[:split], y[split:]\n",
        "\n",
        "# define the CNN model for regression\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(2)  # Output two values: [steering_angle, speed]\n",
        "])\n",
        "\n",
        "# Compilee the model for regression\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"/Users/jmarsh/Documents/machine-learning-in-science-ii-2025/autonomous_driving_model.h5\")\n",
        "\n",
        "print(\"Model training complete and saved as 'autonomous_driving_model.h5'.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Ik1Nv-FaMrqQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}