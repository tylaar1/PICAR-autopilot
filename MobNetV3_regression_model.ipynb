{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/MobNetV3_regression_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
      ],
      "metadata": {
        "id": "-fhwRSFoj6C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "g4V83PflfFkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP6UczzNe1l2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56330d25-f725-4dc6-c9cc-b9449e86b133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-10 18:29:13.224997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-03-10 18:29:13.241001: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-03-10 18:29:13.245701: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-10 18:29:13.261927: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# makes it so pd dfs aren't truncated\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "IF_vPVifaU9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eocC68amnhEI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) DATA PRE-PROCESSING\n",
        "\n",
        "a) Load in labels + image file paths\n",
        "\n",
        "b) combine them into one dataframe\n",
        "\n",
        "c) EDA - spotted and removed erroneous label (speed = 1.42...)\n",
        "\n",
        "- `cleaned_df` is the cleaned df with a) b) c) completed\n",
        "\n",
        "d) convert images to numerical RGB feature maps - ML algorithms only understand numerical data\n",
        "\n",
        "e) Splitting data into training and validation sets\n",
        "\n",
        "f) data augmentation applied to training set"
      ],
      "metadata": {
        "id": "-_MvRvYnfIM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a) load in labels + image file paths"
      ],
      "metadata": {
        "id": "HU3TvBZ5hfhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # tylers file path\n",
        "labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ],
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data' # bens hpc file path\n",
        "# image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ],
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking labels dataframe"
      ],
      "metadata": {
        "id": "0oeuvmeZaGSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "2pi13TZ2aFhO",
        "outputId": "be64eecc-d0f4-462e-e21b-77ce64cd8fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed\n",
              "image_id               \n",
              "1         0.4375    0.0\n",
              "2         0.8125    1.0\n",
              "3         0.4375    1.0\n",
              "4         0.6250    1.0\n",
              "5         0.5000    0.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
      ],
      "metadata": {
        "id": "puEjGoOJaRS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "a1suFSK7aWKH",
        "outputId": "5767f1a8-6c8a-4385-c48a-d27bdc4f509a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                      image_file_paths\n",
              "image_id                                                                                              \n",
              "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png\n",
              "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png\n",
              "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png\n",
              "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/4.png\n",
              "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/5.png"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b) Combine labels and image file paths into one dataframe"
      ],
      "metadata": {
        "id": "CjDdyYd6cMBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
        "merged_df['speed'] = merged_df['speed'].round(6) # to get rid of floating point errors"
      ],
      "metadata": {
        "id": "6NdbonzPcLKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-VstirIAdAZi",
        "outputId": "ca8d869b-4f72-4d5d-f52a-328e23b61005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "1         0.4375    0.0   \n",
              "2         0.8125    1.0   \n",
              "3         0.4375    1.0   \n",
              "4         0.6250    1.0   \n",
              "5         0.5000    0.0   \n",
              "\n",
              "                                                                                      image_file_paths  \n",
              "image_id                                                                                                \n",
              "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png  \n",
              "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png  \n",
              "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png  \n",
              "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/4.png  \n",
              "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/5.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.loc[3139:3143]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8MgNoL8nfBm2",
        "outputId": "e901ab53-6b7f-48bb-afa3-19149ce15551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          angle  speed  \\\n",
              "image_id                 \n",
              "3139      0.750    1.0   \n",
              "3140      0.875    1.0   \n",
              "3142      0.625    0.0   \n",
              "3143      0.625    1.0   \n",
              "\n",
              "                                                                                         image_file_paths  \n",
              "image_id                                                                                                   \n",
              "3139      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3139.png  \n",
              "3140      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3140.png  \n",
              "3142      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3142.png  \n",
              "3143      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3143.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3139</th>\n",
              "      <td>0.750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3139.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>0.875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3140.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3142</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3142.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3143</th>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3143.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above cell shows that:\n",
        "\n",
        " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
        "\n",
        " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
      ],
      "metadata": {
        "id": "U7PCxqJbmXE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c) EDA"
      ],
      "metadata": {
        "id": "h3OKLcn9u0Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.value_counts('angle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWQCQrR-oCps",
        "outputId": "83658a88-47e4-453b-ebaf-03b7255e1b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "angle\n",
              "0.7500    2123\n",
              "0.5000    2046\n",
              "0.6875    2007\n",
              "0.6250    1963\n",
              "0.5625    1609\n",
              "0.4375    1467\n",
              "0.8125    1147\n",
              "0.3750     428\n",
              "0.8750     301\n",
              "0.3125     213\n",
              "0.2500     104\n",
              "0.1250      99\n",
              "0.1875      98\n",
              "0.9375      65\n",
              "0.0000      60\n",
              "1.0000      35\n",
              "0.0625      28\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note: imbalance datset"
      ],
      "metadata": {
        "id": "K4pZ65pYvdqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "identifying the row with the erroneous speed value"
      ],
      "metadata": {
        "id": "xJmG7jmNkE0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df[merged_df['speed'] == 1.428571]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "wAQnbLLeiqy2",
        "outputId": "d828636e-4a29-484b-b611-a153dfb34857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle     speed  \\\n",
              "image_id                     \n",
              "3884      0.4375  1.428571   \n",
              "\n",
              "                                                                                         image_file_paths  \n",
              "image_id                                                                                                   \n",
              "3884      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3884.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3884</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3884.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to remove this row"
      ],
      "metadata": {
        "id": "zMZq41-RkLz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = merged_df[merged_df['speed'] != 1.428571]\n",
        "cleaned_df.loc[3882:3886]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TDMqIiOLSKGX",
        "outputId": "dc7bf407-83e5-4a74-9bd7-f17b8adf6f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "3882      0.5625    1.0   \n",
              "3883      0.3750    0.0   \n",
              "3885      0.0000    1.0   \n",
              "3886      0.7500    1.0   \n",
              "\n",
              "                                                                                         image_file_paths  \n",
              "image_id                                                                                                   \n",
              "3882      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3882.png  \n",
              "3883      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3883.png  \n",
              "3885      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3885.png  \n",
              "3886      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3886.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3882</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3882.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3883</th>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3883.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3885</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3885.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3886</th>\n",
              "      <td>0.7500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3886.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1d) convert images to numerical RGB feature maps"
      ],
      "metadata": {
        "id": "Di6F6km_DBmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path, label, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, resized_shape)\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image, label\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"angle\"])) # Convert pd df into a tf ds\n",
        "\n",
        "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(len(cleaned_df))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oeeBTruNCQ96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets check and see if what we have done works"
      ],
      "metadata": {
        "id": "pUOlsWQeVlyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in dataset.take(1):\n",
        "    print(images.shape, labels.shape)\n",
        "    print(labels)"
      ],
      "metadata": {
        "id": "jBTNjNhMVk2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd3f3d9-6652-4230-932f-7c969012e92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3) (32,)\n",
            "tf.Tensor(\n",
            "[0.6875 0.4375 0.5    0.5625 0.4375 0.4375 0.6875 0.75   0.75   0.4375\n",
            " 0.8125 0.6875 0.75   0.5    0.5625 0.4375 0.6875 0.5    0.5625 0.625\n",
            " 0.4375 0.6875 0.5625 0.5625 0.75   0.5    0.625  0.75   0.5    0.8125\n",
            " 0.6875 0.75  ], shape=(32,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1e) Splitting data into training and validation sets (test set is already provided in kaggle data)"
      ],
      "metadata": {
        "id": "Md6U_i84SiK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80-20 split\n",
        "\n",
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "validation_dataset = dataset.skip(train_size)"
      ],
      "metadata": {
        "id": "yYlssPh5dxaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train size: {train_size}, validation size: {dataset_size - train_size}\")"
      ],
      "metadata": {
        "id": "qPUE6rd8cgQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31bd2a99-d9c2-406a-baea-3c43d80072bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 344, validation size: 87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcPDFG91s-NS",
        "outputId": "1bded818-6991-4362-f8b0-d19dff91e122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_SkipDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1f) Data augmentation applied to training set\n",
        "\n",
        "Flipping or rotating the image will render the angle labels incorrect so none of that was applied to the images for this regression task\n",
        "\n",
        "- Random Brightness Adjustment\n",
        "- Random Contrast Adjustment\n",
        "- Random Hue Adjustment\n",
        "- Random Saturation Adjustment\n"
      ],
      "metadata": {
        "id": "0ujsjhMPSw4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#only performing augmentation on training data as want validation/test data to reflect kaggle test set\n",
        "seed = (6,9)\n",
        "train_dataset = train_dataset.map(\n",
        "      lambda image, label: (tf.image.stateless_random_brightness(image, 0.2,seed),label)\n",
        ").map(\n",
        "      lambda image, label: (tf.image.stateless_random_contrast(image,0.8,1.2,seed),label)\n",
        ").map(\n",
        "      lambda image, label: (tf.image.stateless_random_hue(image,0.2,seed),label)\n",
        ").map(\n",
        "      lambda image, label: (tf.image.stateless_random_saturation(image,0.8,1.2,seed),label)\n",
        ").take(5\n",
        ")"
      ],
      "metadata": {
        "id": "T9r811eWsYfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking to see if whats been done was successful or needs debugging"
      ],
      "metadata": {
        "id": "HEdi-dUCTND1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, axarr = plt.subplots(1,10)\n",
        "\n",
        "i = 0\n",
        "for image_batch, label_batch in dataset.take(1):  # Take one batch\n",
        "    for image in image_batch:  # Iterate through images in the batch\n",
        "        if i < 10:  # Only display the first 5 images\n",
        "            print('image shape: ', np.shape(image))\n",
        "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
        "            axarr[i].imshow(image)\n",
        "            axarr[i].axis('off')\n",
        "            i += 1\n",
        "        else:\n",
        "            break  # Stop after displaying 5 images\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "OeboVhsQKGFS",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "outputId": "0846cd25-61f6-4100-947b-25079cd75323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape:  (224, 224, 3)\n",
            "label: 0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape:  (224, 224, 3)\n",
            "label: 0.625\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.75\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.75\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.5625\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.625\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.8125\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.75\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.5\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Model Building - MobileNetV3Large Transfer Learning\n",
        "\n",
        "a) Set up model architecture\n",
        "\n",
        "b) define training step\n",
        "\n",
        "c) training the model on the training set\n",
        "\n",
        "d) fine-tuning"
      ],
      "metadata": {
        "id": "cmetmzNHTWzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a) Set up model architecture\n",
        "\n",
        "- MobileNetV2 to learn lower level features\n",
        "- global average pooling layer\n",
        "- drop out layer\n",
        "- dense layer with sigmoid activation"
      ],
      "metadata": {
        "id": "48RHLVshdX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = False # freeze the first layers to the imagenet weights\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "Eh1-U-VYeN9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "fac693b5-3ed3-4e01-f9af-2c00eb673d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m)      │     \u001b[38;5;34m2,996,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m246,016\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">246,016</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,285,633\u001b[0m (12.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,285,633</span> (12.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m289,281\u001b[0m (1.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">289,281</span> (1.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,996,352\u001b[0m (11.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> (11.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) Define training step\n",
        "\n",
        "- adam optimiser\n",
        "- binary cross entropy loss function"
      ],
      "metadata": {
        "id": "3iuqe2Xwpu7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.001 #learning rate\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser\n",
        "\n",
        "@tf.function\n",
        "def train_step( model, X , Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model( X )\n",
        "        Y = tf.cast(Y, tf.float32)\n",
        "        current_loss = tf.reduce_mean(tf.losses.MeanSquaredError()( Y,  pred))\n",
        "\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients( zip( grads , model.trainable_variables) )\n",
        "    current_MSE = tf.reduce_mean(tf.square(Y-pred))\n",
        "    return(current_loss, current_MSE)"
      ],
      "metadata": {
        "id": "9AErZvcTeX-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2c) Training the model on the training set"
      ],
      "metadata": {
        "id": "bUMefNeTpDWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 200\n",
        "\n",
        "tloss = []\n",
        "tMSE = []\n",
        "vloss = []\n",
        "vMSE = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_MSEs = []\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "        loss, MSE = train_step(model, image_batch, label_batch)\n",
        "        batch_losses.append(loss)\n",
        "        batch_MSEs.append(MSE)\n",
        "\n",
        "    # Calculate average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses)\n",
        "    avg_MSE = tf.reduce_mean(batch_MSEs)\n",
        "    tloss.append(avg_loss)\n",
        "    tMSE.append(avg_MSE)\n",
        "\n",
        "    # Validation\n",
        "    val_batch_losses = []\n",
        "    val_batch_MSEs = []\n",
        "    for image_batch, label_batch in validation_dataset:\n",
        "        val_loss, val_MSE = train_step(model, image_batch, label_batch)\n",
        "        val_batch_losses.append(val_loss)\n",
        "        val_batch_MSEs.append(val_MSE)\n",
        "\n",
        "    # Calculate average validation metrics\n",
        "    avg_val_loss = tf.reduce_mean(val_batch_losses)\n",
        "    avg_val_MSE = tf.reduce_mean(val_batch_MSEs)\n",
        "    vloss.append(avg_val_loss)\n",
        "    vMSE.append(avg_val_MSE)\n",
        "\n",
        "    # Print metrics every 10 iterations\n",
        "    if it % 10 == 0:  # Check if (it + 1) is divisible by 10\n",
        "        tf.print('iter: {}, train_loss: {:.3f}, train_MSE: {:.3f}, val_loss: {:.3f}, val_MSE: {:.3f}'.format(\n",
        "            it, avg_loss, avg_MSE, avg_val_loss, avg_val_MSE))"
      ],
      "metadata": {
        "id": "uE2K4gVQedXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "d08b219d-dbee-48c0-a25a-6798863f9719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0, train_loss: 0.178, train_MSE: 0.179, val_loss: 0.017, val_MSE: 0.038\n",
            "iter: 10, train_loss: 0.010, train_MSE: 0.041, val_loss: 0.010, val_MSE: 0.040\n",
            "iter: 20, train_loss: 0.009, train_MSE: 0.035, val_loss: 0.009, val_MSE: 0.038\n",
            "iter: 30, train_loss: 0.007, train_MSE: 0.044, val_loss: 0.007, val_MSE: 0.039\n",
            "iter: 40, train_loss: 0.007, train_MSE: 0.042, val_loss: 0.007, val_MSE: 0.041\n",
            "iter: 50, train_loss: 0.008, train_MSE: 0.042, val_loss: 0.007, val_MSE: 0.039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-10 19:41:14.271478: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 60, train_loss: 0.007, train_MSE: 0.035, val_loss: 0.007, val_MSE: 0.042\n",
            "iter: 70, train_loss: 0.010, train_MSE: 0.037, val_loss: 0.007, val_MSE: 0.040\n",
            "iter: 80, train_loss: 0.008, train_MSE: 0.039, val_loss: 0.007, val_MSE: 0.041\n",
            "iter: 90, train_loss: 0.008, train_MSE: 0.046, val_loss: 0.007, val_MSE: 0.040\n",
            "iter: 100, train_loss: 0.006, train_MSE: 0.037, val_loss: 0.007, val_MSE: 0.040\n",
            "iter: 110, train_loss: 0.006, train_MSE: 0.045, val_loss: 0.006, val_MSE: 0.041\n",
            "iter: 120, train_loss: 0.011, train_MSE: 0.046, val_loss: 0.006, val_MSE: 0.040\n",
            "iter: 130, train_loss: 0.010, train_MSE: 0.046, val_loss: 0.006, val_MSE: 0.042\n",
            "iter: 140, train_loss: 0.007, train_MSE: 0.052, val_loss: 0.006, val_MSE: 0.043\n",
            "iter: 150, train_loss: 0.009, train_MSE: 0.044, val_loss: 0.006, val_MSE: 0.042\n",
            "iter: 160, train_loss: 0.005, train_MSE: 0.036, val_loss: 0.007, val_MSE: 0.043\n",
            "iter: 170, train_loss: 0.005, train_MSE: 0.043, val_loss: 0.006, val_MSE: 0.040\n",
            "iter: 180, train_loss: 0.006, train_MSE: 0.049, val_loss: 0.006, val_MSE: 0.041\n",
            "iter: 190, train_loss: 0.007, train_MSE: 0.040, val_loss: 0.006, val_MSE: 0.040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/home/apyba3/car_frozen_regression.weights.h5')"
      ],
      "metadata": {
        "id": "FiHy6opSP2sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session() #Clear keras session"
      ],
      "metadata": {
        "id": "FpLHyw20P93U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2d) fine-tuning"
      ],
      "metadata": {
        "id": "ENHbUvQdvyFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rebuild model after clearing keras session"
      ],
      "metadata": {
        "id": "h0ek_ytyw0KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = True # UNFREEZE mbnet layers\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "ZuKL3X-QP-Ax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "9a52dc4c-36cb-42ae-8e26-ab3af8630641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m)      │     \u001b[38;5;34m2,996,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m246,016\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">246,016</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,285,633\u001b[0m (12.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,285,633</span> (12.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,261,233\u001b[0m (12.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,261,233</span> (12.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,400\u001b[0m (95.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,400</span> (95.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/home/apyba3/car_frozen_regression.weights.h5')"
      ],
      "metadata": {
        "id": "8oAenzEiP-C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up fine-tuning training"
      ],
      "metadata": {
        "id": "XWDtRxBow89t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.001 #learning rate\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser\n",
        "\n",
        "@tf.function\n",
        "def train_step( model, X , Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model( X )\n",
        "        Y = tf.cast(Y, tf.float32)\n",
        "        current_loss = tf.reduce_mean(tf.losses.MeanSquaredError()( Y,  pred))\n",
        "\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients( zip( grads , model.trainable_variables) )\n",
        "    current_MSE = tf.reduce_mean(tf.square(Y-pred))\n",
        "    return(current_loss, current_MSE)"
      ],
      "metadata": {
        "id": "mqiTgnUxb2fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 200\n",
        "\n",
        "tloss = []\n",
        "tMSE = []\n",
        "vloss = []\n",
        "vMSE = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_MSEs = []\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "        loss, MSE = train_step(model, image_batch, label_batch)\n",
        "        batch_losses.append(loss)\n",
        "        batch_MSEs.append(MSE)\n",
        "\n",
        "    # Calculate average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses)\n",
        "    avg_MSE = tf.reduce_mean(batch_MSEs)\n",
        "    tloss.append(avg_loss)\n",
        "    tMSE.append(avg_MSE)\n",
        "\n",
        "    # Validation\n",
        "    val_batch_losses = []\n",
        "    val_batch_MSEs = []\n",
        "    for image_batch, label_batch in validation_dataset:\n",
        "        val_loss, val_MSE = train_step(model, image_batch, label_batch)\n",
        "        val_batch_losses.append(val_loss)\n",
        "        val_batch_MSEs.append(val_MSE)\n",
        "\n",
        "    # Calculate average validation metrics\n",
        "    avg_val_loss = tf.reduce_mean(val_batch_losses)\n",
        "    avg_val_MSE = tf.reduce_mean(val_batch_MSEs)\n",
        "    vloss.append(avg_val_loss)\n",
        "    vMSE.append(avg_val_MSE)\n",
        "\n",
        "    # Print metrics every 10 iterations\n",
        "    if it % 10 == 0:  # Check if (it + 1) is divisible by 10\n",
        "        tf.print('iter: {}, train_loss: {:.3f}, train_MSE: {:.3f}, val_loss: {:.3f}, val_MSE: {:.3f}'.format(\n",
        "            it, avg_loss, avg_MSE, avg_val_loss, avg_val_MSE))"
      ],
      "metadata": {
        "id": "ZvmWxC1fP-Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bdc5fd-1211-499d-fe9a-e75f5fa91a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0, train_loss: 875230720.000, train_MSE: 875232256.000, val_loss: 769831.250, val_MSE: 769831.250\n",
            "iter: 10, train_loss: 0.147, train_MSE: 0.160, val_loss: 0.122, val_MSE: 0.133\n",
            "iter: 20, train_loss: 0.252, train_MSE: 0.268, val_loss: 0.121, val_MSE: 0.134\n",
            "iter: 30, train_loss: 0.020, train_MSE: 0.039, val_loss: 0.127, val_MSE: 0.143\n",
            "iter: 40, train_loss: 0.113, train_MSE: 0.113, val_loss: 0.102, val_MSE: 0.102\n",
            "iter: 50, train_loss: 0.102, train_MSE: 0.102, val_loss: 0.101, val_MSE: 0.101\n",
            "iter: 60, train_loss: 0.100, train_MSE: 0.100, val_loss: 0.103, val_MSE: 0.103\n",
            "iter: 70, train_loss: 0.122, train_MSE: 0.122, val_loss: 0.103, val_MSE: 0.103\n",
            "iter: 80, train_loss: 0.105, train_MSE: 0.105, val_loss: 0.103, val_MSE: 0.103\n",
            "iter: 90, train_loss: 0.107, train_MSE: 0.107, val_loss: 0.103, val_MSE: 0.103\n",
            "iter: 100, train_loss: 0.106, train_MSE: 0.106, val_loss: 0.101, val_MSE: 0.101\n",
            "iter: 110, train_loss: 0.106, train_MSE: 0.106, val_loss: 0.101, val_MSE: 0.101\n",
            "iter: 120, train_loss: 0.104, train_MSE: 0.104, val_loss: 0.103, val_MSE: 0.103\n",
            "iter: 130, train_loss: 0.109, train_MSE: 0.109, val_loss: 0.100, val_MSE: 0.100\n",
            "iter: 140, train_loss: 0.118, train_MSE: 0.118, val_loss: 0.101, val_MSE: 0.101\n",
            "iter: 150, train_loss: 0.095, train_MSE: 0.095, val_loss: 0.100, val_MSE: 0.100\n",
            "iter: 160, train_loss: 0.110, train_MSE: 0.110, val_loss: 0.099, val_MSE: 0.099\n",
            "iter: 170, train_loss: 0.097, train_MSE: 0.097, val_loss: 0.096, val_MSE: 0.096\n",
            "iter: 180, train_loss: 0.088, train_MSE: 0.088, val_loss: 0.095, val_MSE: 0.095\n",
            "iter: 190, train_loss: 0.081, train_MSE: 0.081, val_loss: 0.092, val_MSE: 0.092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/home/apyba3/car_unfrozen_regression.weights.h5')"
      ],
      "metadata": {
        "id": "O14u6175RLjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Test-Set Predictions\n",
        "\n",
        "a) load in test data\n",
        "\n",
        "b) convert test images to numerical RGB feature maps\n",
        "\n",
        "c) generate predictions on the test set\n",
        "\n",
        "d) correctly format the predictions into a pandas dataframe\n",
        "\n",
        "e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ],
      "metadata": {
        "id": "GCbo4VcLxLgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3a) load in test data"
      ],
      "metadata": {
        "id": "HnygDJsKxYhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data'\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'\n",
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "id": "W-e59lQQRXKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "9830c8fa-dfdc-4020-db67-6b8c6b7fad0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                              image_file_paths\n",
              "image_id                                                                                      \n",
              "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/1.png\n",
              "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/2.png\n",
              "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/3.png\n",
              "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/4.png\n",
              "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/5.png"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3b) convert test images to numerical RGB feature maps"
      ],
      "metadata": {
        "id": "t-9i5trTyDTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image_no_label(image_path, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
        "    image = tf.image.resize(image, resized_shape)  # Resize to uniform shape\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((imagefilepaths_df[\"image_file_paths\"]))\n",
        "\n",
        "test_dataset = test_dataset.map(process_image_no_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "3hT_c1s5TAR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3c) generate predictions on test set"
      ],
      "metadata": {
        "id": "gobnK7PhyLa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "NtqcOFr7TAXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1dfa25-d0d7-4dac-e498-dc55213e5fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3d) correctly format the predictions into a pandas dataframe"
      ],
      "metadata": {
        "id": "zT1LJxHTPeQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = pd.DataFrame(predictions, columns=['angle'])"
      ],
      "metadata": {
        "id": "pFVWGi04fza7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "OnO0K1rReHOT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "87d98e1b-2102-4e15-ae6a-e1910334d7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     angle\n",
              "0  0.35509\n",
              "1  0.35509\n",
              "2  0.35509\n",
              "3  0.35509\n",
              "4  0.35509"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.35509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.35509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.35509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.35509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.35509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df['angle'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ss_kgSYsKY9",
        "outputId": "4015f7b8-bafa-475e-9fe0-d87be3db8c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "angle\n",
              "0.35509    1020\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sigmoid output is between [0,1]"
      ],
      "metadata": {
        "id": "sftRAg6PPnsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df[predictions_df['speed'] > 0.5] = 1\n",
        "predictions_df[predictions_df['speed'] < 0.5] = 0"
      ],
      "metadata": {
        "id": "AQ7of6YqeNJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaggle expects integers for the speed column"
      ],
      "metadata": {
        "id": "qWghSOvSPs2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df['speed'] = predictions_df['speed'].astype(int)"
      ],
      "metadata": {
        "id": "sSUAR4u0TAdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jRGM4-OiPKAQ",
        "outputId": "71f1de5b-e8c7-49a4-8d14-573deff5f031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   speed\n",
              "0      0\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df['speed'].value_counts()"
      ],
      "metadata": {
        "id": "4CcRKL9KTAfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8db31b-04d3-4368-e0b6-5a9dbf679f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "speed\n",
              "1    708\n",
              "0    312\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ],
      "metadata": {
        "id": "oU-PhskZPaHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.to_csv('/home/apyba3/mbnetv3_speedclassification_predictions.csv')"
      ],
      "metadata": {
        "id": "deXjPTO0TAiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsp7UPIJQlKB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}