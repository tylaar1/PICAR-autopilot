{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/GuidedGradCAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
      ],
      "metadata": {
        "id": "-fhwRSFoj6C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "g4V83PflfFkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kP6UczzNe1l2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "print(platform.system())"
      ],
      "metadata": {
        "id": "O24_U-m8q-xv",
        "outputId": "f2bdff39-3f0a-4656-ded2-cfcd2dfe399e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# makes it so pd dfs aren't truncated\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "IF_vPVifaU9V"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eocC68amnhEI",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd014c72-13cf-4fb1-e2e2-68f25a08275a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) DATA PRE-PROCESSING\n",
        "\n",
        "a) Load in labels + image file paths\n",
        "\n",
        "b) combine them into one dataframe\n",
        "\n",
        "c) EDA - spotted and removed erroneous label (speed = 1.42...)\n",
        "\n",
        "- `cleaned_df` is the cleaned df with a) b) c) completed\n",
        "\n",
        "d) convert images to numerical RGB feature maps - ML algorithms only understand numerical data\n",
        "\n",
        "e) Splitting data into training and validation sets\n",
        "\n",
        "f) data augmentation applied to training set"
      ],
      "metadata": {
        "id": "-_MvRvYnfIM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a) load in labels + image file paths"
      ],
      "metadata": {
        "id": "HU3TvBZ5hfhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # tylers file path\n",
        "labels_file_path = '/content/drive/MyDrive/0. MSc MLiS/google SPRING SEMESTER/1. PHYS4036 MLiS2/MLiS2 Project/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
        "#labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
        "# labels_file_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_norm.csv' # tyler hpc file path (mlis2 cluster)\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ],
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data' # ben hpc file path (mlis2 cluster)\n",
        "# image_folder_path = '/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data'\n",
        "image_folder_path = '/content/drive/MyDrive/0. MSc MLiS/google SPRING SEMESTER/1. PHYS4036 MLiS2/MLiS2 Project/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data'\n",
        "# image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ],
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking labels dataframe"
      ],
      "metadata": {
        "id": "0oeuvmeZaGSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "2pi13TZ2aFhO",
        "outputId": "10a5f4e0-5415-48c9-e6ad-99ff0569d564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed\n",
              "image_id               \n",
              "1         0.4375    0.0\n",
              "2         0.8125    1.0\n",
              "3         0.4375    1.0\n",
              "4         0.6250    1.0\n",
              "5         0.5000    0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ef8faf3-1df2-4c96-ad6e-bc0fef7d58b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ef8faf3-1df2-4c96-ad6e-bc0fef7d58b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ef8faf3-1df2-4c96-ad6e-bc0fef7d58b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ef8faf3-1df2-4c96-ad6e-bc0fef7d58b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-56b21a99-5d9f-4315-a389-2dac2c141167\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56b21a99-5d9f-4315-a389-2dac2c141167')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-56b21a99-5d9f-4315-a389-2dac2c141167 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df",
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 13793,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3983,\n        \"min\": 1,\n        \"max\": 13798,\n        \"num_unique_values\": 13793,\n        \"samples\": [\n          2486,\n          7115,\n          748\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"angle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15555820377620463,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.4375,\n          0.8125,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4305956548518498,\n        \"min\": 0.0,\n        \"max\": 1.42857142857143,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0,\n          1.42857142857143\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
      ],
      "metadata": {
        "id": "puEjGoOJaRS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "a1suFSK7aWKH",
        "outputId": "01952708-c62b-4ca7-9f79-51d9dd837340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                       image_file_paths\n",
              "image_id                                                                                               \n",
              "8          /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8.png\n",
              "9          /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/9.png\n",
              "14        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/14.png\n",
              "15        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/15.png\n",
              "16        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/16.png"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38bd8b14-5869-48c7-b83e-f5aff23ae1f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/9.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/14.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/15.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/16.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38bd8b14-5869-48c7-b83e-f5aff23ae1f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38bd8b14-5869-48c7-b83e-f5aff23ae1f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38bd8b14-5869-48c7-b83e-f5aff23ae1f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-985e8a08-5c28-4135-a6d3-48db739872a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-985e8a08-5c28-4135-a6d3-48db739872a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-985e8a08-5c28-4135-a6d3-48db739872a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "imagefilepaths_df",
              "summary": "{\n  \"name\": \"imagefilepaths_df\",\n  \"rows\": 5238,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3948,\n        \"min\": 8,\n        \"max\": 13798,\n        \"num_unique_values\": 5238,\n        \"samples\": [\n          8089,\n          3379,\n          1179\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_file_paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5238,\n        \"samples\": [\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8089.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3379.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/1179.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b) Combine labels and image file paths into one dataframe"
      ],
      "metadata": {
        "id": "CjDdyYd6cMBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
        "merged_df['speed'] = merged_df['speed'].round(6) # to get rid of floating point errors"
      ],
      "metadata": {
        "id": "6NdbonzPcLKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "-VstirIAdAZi",
        "outputId": "0b37f561-e659-4ae7-cf83-bcd18e18092f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          angle  speed  \\\n",
              "image_id                 \n",
              "8         0.500    1.0   \n",
              "9         0.500    0.0   \n",
              "14        0.875    1.0   \n",
              "15        0.625    1.0   \n",
              "16        0.500    1.0   \n",
              "\n",
              "                                                                                       image_file_paths  \n",
              "image_id                                                                                                 \n",
              "8          /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8.png  \n",
              "9          /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/9.png  \n",
              "14        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/14.png  \n",
              "15        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/15.png  \n",
              "16        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/16.png  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-196fb6c9-95d2-4f89-afdd-6eef4c88adf2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/9.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/14.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/15.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/16.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-196fb6c9-95d2-4f89-afdd-6eef4c88adf2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-196fb6c9-95d2-4f89-afdd-6eef4c88adf2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-196fb6c9-95d2-4f89-afdd-6eef4c88adf2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ad751cfc-9046-46fc-bce0-576d01a4db8b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad751cfc-9046-46fc-bce0-576d01a4db8b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ad751cfc-9046-46fc-bce0-576d01a4db8b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 5235,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3948,\n        \"min\": 8,\n        \"max\": 13798,\n        \"num_unique_values\": 5235,\n        \"samples\": [\n          8102,\n          3380,\n          1179\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"angle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1566358687964845,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.5,\n          0.875,\n          0.8125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4346144313921845,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_file_paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5235,\n        \"samples\": [\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8102.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3380.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.loc[3139:3143]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "8MgNoL8nfBm2",
        "outputId": "4ef87e41-78d0-4297-f4c6-1e2393a20447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          angle  speed  \\\n",
              "image_id                 \n",
              "3140      0.875    1.0   \n",
              "3142      0.625    0.0   \n",
              "3143      0.625    1.0   \n",
              "\n",
              "                                                                                         image_file_paths  \n",
              "image_id                                                                                                   \n",
              "3140      /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3140.png  \n",
              "3142      /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3142.png  \n",
              "3143      /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3143.png  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fde8d5e-f57c-45af-9a8c-93a0a63dabf0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>0.875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3140.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3142</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3142.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3143</th>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3143.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fde8d5e-f57c-45af-9a8c-93a0a63dabf0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6fde8d5e-f57c-45af-9a8c-93a0a63dabf0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6fde8d5e-f57c-45af-9a8c-93a0a63dabf0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41fb7189-88f4-4333-8da4-df7f2c8af313\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41fb7189-88f4-4333-8da4-df7f2c8af313')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41fb7189-88f4-4333-8da4-df7f2c8af313 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3140,\n        \"max\": 3143,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3140,\n          3142,\n          3143\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"angle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14433756729740646,\n        \"min\": 0.625,\n        \"max\": 0.875,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.625,\n          0.875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5773502691896258,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_file_paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3140.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3142.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above cell shows that:\n",
        "\n",
        " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
        "\n",
        " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
      ],
      "metadata": {
        "id": "U7PCxqJbmXE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c) EDA"
      ],
      "metadata": {
        "id": "h3OKLcn9u0Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.value_counts('speed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "IWQCQrR-oCps",
        "outputId": "344847bc-7f27-44d8-abfb-b0bcfe3e7c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "speed\n",
              "1.0    3912\n",
              "0.0    1323\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speed</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>3912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>1323</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note: imbalance datset"
      ],
      "metadata": {
        "id": "K4pZ65pYvdqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "identifying the row with the erroneous speed value"
      ],
      "metadata": {
        "id": "xJmG7jmNkE0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df[merged_df['speed'] == 1.428571]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "wAQnbLLeiqy2",
        "outputId": "bb399525-122a-46be-944e-0e6301b2c060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [angle, speed, image_file_paths]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45f0e566-e16b-4040-a121-287f84c00eb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45f0e566-e16b-4040-a121-287f84c00eb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45f0e566-e16b-4040-a121-287f84c00eb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45f0e566-e16b-4040-a121-287f84c00eb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to remove this row"
      ],
      "metadata": {
        "id": "zMZq41-RkLz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = merged_df[merged_df['speed'] != 1.428571]\n",
        "cleaned_df.loc[3882:3886]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "TDMqIiOLSKGX",
        "outputId": "a24ec2cd-6670-4aad-8e19-0e6e78e0d5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [angle, speed, image_file_paths]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-637afd2d-011f-4252-b527-46940d716fc4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-637afd2d-011f-4252-b527-46940d716fc4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-637afd2d-011f-4252-b527-46940d716fc4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-637afd2d-011f-4252-b527-46940d716fc4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1d) convert images to numerical RGB feature maps"
      ],
      "metadata": {
        "id": "Di6F6km_DBmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path, label, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, resized_shape)\n",
        "    image = image / 255.0  # Normalise pixel values to [0,1]\n",
        "    return image, label\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"speed\"])) # Convert pd df into a tf ds\n",
        "\n",
        "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(len(cleaned_df))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oeeBTruNCQ96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets check and see if what we have done works"
      ],
      "metadata": {
        "id": "pUOlsWQeVlyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in dataset.take(1):\n",
        "    print(images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "jBTNjNhMVk2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c055f3-3744-4690-8289-8b55ddbc1476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3) (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1e) Splitting data into training and validation sets (test set is already provided in kaggle data)"
      ],
      "metadata": {
        "id": "Md6U_i84SiK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80-20 split\n",
        "\n",
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)"
      ],
      "metadata": {
        "id": "yYlssPh5dxaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train size: {train_size}, validation size: {dataset_size - train_size}\")"
      ],
      "metadata": {
        "id": "qPUE6rd8cgQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292b1dce-606d-4507-915f-10ed3d074f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 131, validation size: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1f) Data Augmentation applied to training set\n",
        "\n",
        "- Random Horizontal Flip\n",
        "- Random Brightness Adjustment\n",
        "- Random Contrast Adjustment\n",
        "- Random Hue Adjustment\n",
        "- Random Saturation Adjustment\n",
        "- Random Vertical Flip\n",
        "\n"
      ],
      "metadata": {
        "id": "0ujsjhMPSw4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_image(image, label):\n",
        "  seed = (6, 9)\n",
        "  image = tf.image.stateless_random_brightness(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_contrast(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_saturation(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_flip_left_right(image, seed)\n",
        "  image = tf.image.stateless_random_flip_up_down(image, seed)\n",
        "  return image, label\n",
        "\n",
        "# Create a dataset of augmented images from the original train_dataset\n",
        "augmented_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Concatenate the original and augmented datasets\n",
        "train_dataset = train_dataset.concatenate(augmented_dataset)\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(cleaned_df))"
      ],
      "metadata": {
        "id": "T9r811eWsYfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "count how many images are in the training set"
      ],
      "metadata": {
        "id": "ZOqizFg7rvKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_images = 0\n",
        "for image_batch, _ in train_dataset:\n",
        "    total_images += image_batch.shape[0]  # Add the batch size\n",
        "\n",
        "print(f\"Total number of images in train_dataset: {total_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjlyfjAxLsrC",
        "outputId": "f25f7ba0-8fed-4227-8d54-55594302318c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images in train_dataset: 8384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking to see if whats been done was successful or needs debugging"
      ],
      "metadata": {
        "id": "HEdi-dUCTND1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, axarr = plt.subplots(1,10)\n",
        "\n",
        "i = 0\n",
        "for image_batch, label_batch in dataset.take(1):  # Take one batch\n",
        "    for image in image_batch:  # Iterate through images in the batch\n",
        "        if i < 10:  # Only display the first 5 images\n",
        "            print('image shape: ', np.shape(image))\n",
        "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
        "            axarr[i].imshow(image)\n",
        "            axarr[i].axis('off')\n",
        "            i += 1\n",
        "        else:\n",
        "            break  # Stop after displaying 5 images\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OeboVhsQKGFS",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "577049e3-a9d1-4a5e-a3c1-08dbf5ec7b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Model Building - MobileNetV3Large Transfer Learning\n",
        "\n",
        "a) Set up model architecture\n",
        "\n",
        "b) define training step\n",
        "\n",
        "c) training the model on the training set\n",
        "\n",
        "d) fine-tuning"
      ],
      "metadata": {
        "id": "cmetmzNHTWzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a) Set up model architecture\n",
        "\n",
        "- MobileNetV2 to learn lower level features\n",
        "- global average pooling layer\n",
        "- drop out layer\n",
        "- dense layer with sigmoid activation"
      ],
      "metadata": {
        "id": "48RHLVshdX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
        "])\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = False # freeze the first layers to the imagenet weights\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "Eh1-U-VYeN9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "de5ba6d4-25a3-4560-b1e4-0be309f2cc08"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n",
            "\u001b[1m12683000/12683000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m)           │       \u001b[38;5;34m2,996,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m961\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">961</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,997,313\u001b[0m (11.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,997,313</span> (11.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m961\u001b[0m (3.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">961</span> (3.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,996,352\u001b[0m (11.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> (11.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) Define training step\n",
        "\n",
        "- adam optimiser\n",
        "- binary cross entropy loss function"
      ],
      "metadata": {
        "id": "3iuqe2Xwpu7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.001  # learning rate\n",
        "optimizer = tf.optimizers.Adam(LR)\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, X, Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model(X)  # Get the predictions from the model\n",
        "\n",
        "        # Use binary cross-entropy for binary classification\n",
        "        current_loss = tf.reduce_mean(tf.losses.binary_crossentropy(Y, pred))\n",
        "\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Threshold predictions to binary values (0 or 1) for accuracy calculation\n",
        "    pred_binary = tf.cast(pred > 0.5, dtype=tf.int32)  # Convert predictions to binary (0 or 1)\n",
        "\n",
        "    # Calculate True Positives, False Positives, True Negatives, False Negatives\n",
        "    TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 1), dtype=tf.int32))\n",
        "    TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 0), dtype=tf.int32))\n",
        "    FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 0), dtype=tf.int32))\n",
        "    FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 1), dtype=tf.int32))\n",
        "\n",
        "    # Calculate Balanced Accuracy\n",
        "    sensitivity = TP / (TP + FN)  # Recall for class 1\n",
        "    specificity = TN / (TN + FP)  # Recall for class 0\n",
        "    balanced_accuracy = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "    return current_loss, balanced_accuracy\n"
      ],
      "metadata": {
        "id": "9AErZvcTeX-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2c) Training the model on the training set"
      ],
      "metadata": {
        "id": "bUMefNeTpDWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 50\n",
        "\n",
        "tloss = []\n",
        "tacc = []\n",
        "vloss = []\n",
        "vacc = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_accs = []\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "        # Convert labels to correct format for binary classification\n",
        "        # Convert to [batch_size, 1] for binary classification with sigmoid\n",
        "        labels = tf.expand_dims(tf.cast(label_batch, dtype=tf.float32), axis=1)\n",
        "        loss, acc = train_step(model, image_batch, labels)\n",
        "        batch_losses.append(loss)\n",
        "        batch_accs.append(acc)\n",
        "\n",
        "    # Average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses).numpy()\n",
        "    avg_acc = tf.reduce_mean(batch_accs).numpy()\n",
        "    tloss.append(avg_loss)\n",
        "    tacc.append(avg_acc)\n",
        "\n",
        "    # LOGGING METRICS TO CHECK HOW TRAIING IS GOING\n",
        "\n",
        "    if it % 10 == 0:\n",
        "        tf.print(f'iter: {it}, train_loss: {avg_loss:.3f}, train_balanced_acc: {avg_acc:.3f}')\n",
        "\n",
        "        # If you have a validation dataset, evaluate on it\n",
        "        if 'val_dataset' in globals():\n",
        "            val_losses = []\n",
        "            val_accs = []\n",
        "            for val_images, val_labels in val_dataset:\n",
        "                val_labels = tf.expand_dims(tf.cast(val_labels, dtype=tf.float32), axis=1)\n",
        "                val_preds = model(val_images)\n",
        "                val_loss = tf.reduce_mean(tf.losses.binary_crossentropy(val_labels, val_preds))\n",
        "\n",
        "                # Use the same balanced accuracy calculation as in train_step\n",
        "                pred_binary = tf.cast(val_preds > 0.5, dtype=tf.int32)\n",
        "                val_labels_int = tf.cast(val_labels, dtype=tf.int32)\n",
        "\n",
        "                TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 1), dtype=tf.int32))\n",
        "                TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 1), dtype=tf.int32))\n",
        "\n",
        "                sensitivity = TP / (TP + FN + 1e-7)\n",
        "                specificity = TN / (TN + FP + 1e-7)\n",
        "                val_acc = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "\n",
        "            avg_val_loss = tf.reduce_mean(val_losses).numpy()\n",
        "            avg_val_acc = tf.reduce_mean(val_accs).numpy()\n",
        "            vloss.append(avg_val_loss)\n",
        "            vacc.append(avg_val_acc)\n",
        "\n",
        "            tf.print(f'val_loss: {avg_val_loss:.3f}, val_balanced_acc: {avg_val_acc:.3f}')"
      ],
      "metadata": {
        "id": "uE2K4gVQedXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "collapsed": true,
        "outputId": "669d147b-7a0a-4e65-f41c-c2f437901296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0dfbeacec027>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Convert to [batch_size, 1] for binary classification with sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatch_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/home/apyba3/car_frozen_regression_mobv3.weights.h5')\n",
        "# model.save_weights('/home/ppytr13/car_frozen.weights.h5')"
      ],
      "metadata": {
        "id": "FiHy6opSP2sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session() #Clear keras session"
      ],
      "metadata": {
        "id": "FpLHyw20P93U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2d) fine-tuning"
      ],
      "metadata": {
        "id": "ENHbUvQdvyFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rebuild model after clearing keras session"
      ],
      "metadata": {
        "id": "h0ek_ytyw0KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
        "])\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = True # UNFREEZE the first layers to the imagenet weights\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "ZuKL3X-QP-Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/home/apyba3/car_frozen_regression_mobv3.weights.h5')\n",
        "# model.load_weights('/home/ppytr13/car_frozen.weights.h5')"
      ],
      "metadata": {
        "id": "8oAenzEiP-C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up fine-tuning training"
      ],
      "metadata": {
        "id": "XWDtRxBow89t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.0001\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser"
      ],
      "metadata": {
        "id": "JQvDo1RVP-Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(model, X, Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model(X)  # Get the predictions from the model\n",
        "\n",
        "        # Use binary cross-entropy for binary classification\n",
        "        current_loss = tf.reduce_mean(tf.losses.binary_crossentropy(Y, pred))\n",
        "\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Threshold predictions to binary values (0 or 1) for accuracy calculation\n",
        "    pred_binary = tf.cast(pred > 0.5, dtype=tf.int32)  # Convert predictions to binary (0 or 1)\n",
        "\n",
        "    # Calculate True Positives, False Positives, True Negatives, False Negatives\n",
        "    TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 1), dtype=tf.int32))\n",
        "    TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 0), dtype=tf.int32))\n",
        "    FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 0), dtype=tf.int32))\n",
        "    FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 1), dtype=tf.int32))\n",
        "\n",
        "    # Calculate Balanced Accuracy\n",
        "    sensitivity = TP / (TP + FN)  # Recall for class 1\n",
        "    specificity = TN / (TN + FP)  # Recall for class 0\n",
        "    balanced_accuracy = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "    return current_loss, balanced_accuracy"
      ],
      "metadata": {
        "id": "-mwoRy9saOM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 50\n",
        "\n",
        "tloss = []\n",
        "tacc = []\n",
        "vloss = []\n",
        "vacc = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_accs = []\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "        # Convert labels to correct format for binary classification\n",
        "        # Convert to [batch_size, 1] for binary classification with sigmoid\n",
        "        labels = tf.expand_dims(tf.cast(label_batch, dtype=tf.float32), axis=1)\n",
        "        loss, acc = train_step(model, image_batch, labels)\n",
        "        batch_losses.append(loss)\n",
        "        batch_accs.append(acc)\n",
        "\n",
        "    # Average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses).numpy()\n",
        "    avg_acc = tf.reduce_mean(batch_accs).numpy()\n",
        "    tloss.append(avg_loss)\n",
        "    tacc.append(avg_acc)\n",
        "\n",
        "    # LOGGING METRICS TO CHECK HOW TRAIING IS GOING\n",
        "\n",
        "    if it % 10 == 0:\n",
        "        tf.print(f'iter: {it}, train_loss: {avg_loss:.3f}, train_balanced_acc: {avg_acc:.3f}')\n",
        "\n",
        "        # If you have a validation dataset, evaluate on it\n",
        "        if 'val_dataset' in globals():\n",
        "            val_losses = []\n",
        "            val_accs = []\n",
        "            for val_images, val_labels in val_dataset:\n",
        "                val_labels = tf.expand_dims(tf.cast(val_labels, dtype=tf.float32), axis=1)\n",
        "                val_preds = model(val_images)\n",
        "                val_loss = tf.reduce_mean(tf.losses.binary_crossentropy(val_labels, val_preds))\n",
        "\n",
        "                # Use the same balanced accuracy calculation as in train_step\n",
        "                pred_binary = tf.cast(val_preds > 0.5, dtype=tf.int32)\n",
        "                val_labels_int = tf.cast(val_labels, dtype=tf.int32)\n",
        "\n",
        "                TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 1), dtype=tf.int32))\n",
        "                TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 1), dtype=tf.int32))\n",
        "\n",
        "                sensitivity = TP / (TP + FN + 1e-7)\n",
        "                specificity = TN / (TN + FP + 1e-7)\n",
        "                val_acc = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "\n",
        "            avg_val_loss = tf.reduce_mean(val_losses).numpy()\n",
        "            avg_val_acc = tf.reduce_mean(val_accs).numpy()\n",
        "            vloss.append(avg_val_loss)\n",
        "            vacc.append(avg_val_acc)\n",
        "\n",
        "            tf.print(f'val_loss: {avg_val_loss:.3f}, val_balanced_acc: {avg_val_acc:.3f}')"
      ],
      "metadata": {
        "id": "ZvmWxC1fP-Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('car_unfrozen_regression_mobv3.weights.h5')\n",
        "# model.save_weights('/home/ppytr13/car_unfrozen.weights.h5')"
      ],
      "metadata": {
        "id": "O14u6175RLjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Test-Set Predictions\n",
        "\n",
        "a) load in test data\n",
        "\n",
        "b) convert test images to numerical RGB feature maps\n",
        "\n",
        "c) generate predictions on the test set\n",
        "\n",
        "d) correctly format the predictions into a pandas dataframe\n",
        "\n",
        "e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ],
      "metadata": {
        "id": "GCbo4VcLxLgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3a) load in test data"
      ],
      "metadata": {
        "id": "HnygDJsKxYhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data'\n",
        "image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data' # tylers file path\n",
        "\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'\n",
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "id": "W-e59lQQRXKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "65c75e24-2677-481b-a50f-ee3882701d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                              image_file_paths\n",
              "image_id                                                                                      \n",
              "1         /content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/1.png\n",
              "2         /content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/2.png\n",
              "3         /content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/3.png\n",
              "4         /content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/4.png\n",
              "5         /content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/5.png"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c45d051-fa20-47cf-9e46-156bbd79c9fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c45d051-fa20-47cf-9e46-156bbd79c9fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c45d051-fa20-47cf-9e46-156bbd79c9fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c45d051-fa20-47cf-9e46-156bbd79c9fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9dbf3cbf-febc-448b-8067-e396dba4da17\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9dbf3cbf-febc-448b-8067-e396dba4da17')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9dbf3cbf-febc-448b-8067-e396dba4da17 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "imagefilepaths_df",
              "summary": "{\n  \"name\": \"imagefilepaths_df\",\n  \"rows\": 1020,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 294,\n        \"min\": 1,\n        \"max\": 1020,\n        \"num_unique_values\": 1020,\n        \"samples\": [\n          524,\n          603,\n          527\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_file_paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1020,\n        \"samples\": [\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/524.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/603.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/527.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3b) convert test images to numerical RGB feature maps"
      ],
      "metadata": {
        "id": "t-9i5trTyDTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image_no_label(image_path, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
        "    image = tf.image.resize(image, resized_shape)  # Resize to uniform shape\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((imagefilepaths_df[\"image_file_paths\"]))\n",
        "\n",
        "test_dataset = test_dataset.map(process_image_no_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "3hT_c1s5TAR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3c) generate predictions on test set"
      ],
      "metadata": {
        "id": "gobnK7PhyLa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "NtqcOFr7TAXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "7568201a-fae2-493b-d1cb-dbc4d9dccf8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7c784bea9760>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-736142a45787>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                 \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_to_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m           )\n\u001b[1;32m    918\u001b[0m       )\n\u001b[0;32m--> 919\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    920\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3d) correctly format the predictions into a pandas dataframe"
      ],
      "metadata": {
        "id": "zT1LJxHTPeQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = pd.DataFrame(predictions, columns=['speed'])"
      ],
      "metadata": {
        "id": "pFVWGi04fza7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "OnO0K1rReHOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sigmoid output is between [0,1]"
      ],
      "metadata": {
        "id": "sftRAg6PPnsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df[predictions_df['speed'] > 0.5] = 1\n",
        "predictions_df[predictions_df['speed'] < 0.5] = 0"
      ],
      "metadata": {
        "id": "AQ7of6YqeNJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaggle expects integers for the speed column"
      ],
      "metadata": {
        "id": "qWghSOvSPs2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df['speed'] = predictions_df['speed'].astype(int)"
      ],
      "metadata": {
        "id": "sSUAR4u0TAdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "jRGM4-OiPKAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df['speed'].value_counts()"
      ],
      "metadata": {
        "id": "4CcRKL9KTAfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ],
      "metadata": {
        "id": "oU-PhskZPaHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.to_csv('/home/apyba3/mbnetv3_speedclassification_predictions.csv')"
      ],
      "metadata": {
        "id": "deXjPTO0TAiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsp7UPIJQlKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Working Guided GradCAM"
      ],
      "metadata": {
        "id": "uw2Q0tLcwS9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow matplotlib opencv-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap1__2vJwxiH",
        "outputId": "4470db34-bc5d-4be8-cac4-1d3a63a7036d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n"
      ],
      "metadata": {
        "id": "NP4AQ4zxwzp9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: defining the guided Grad-CAM Function\n",
        "Basic info on what it is:the Guided Grad-CAM combines both the Grad-CAM and Guided Backpropagation techniques. First i will compute the gradients of the predicted class with respect to the output feature map. Then i will using these gradients, then will highlight the relevant regions in the image."
      ],
      "metadata": {
        "id": "MeEQEYr2w_cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def guided_gradcam(model, img_array, class_index=None):\n",
        "\n",
        "    # gets the model's output layer\n",
        "    last_conv_layer = model.get_layer('conv2d')  # This can vary based on your architecture\n",
        "    heatmap_model = Model([model.inputs], [last_conv_layer.output, model.output])\n",
        "\n",
        "    # calculates the gradient of the class with respect to the last convolutional layer output\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = heatmap_model(img_array)\n",
        "        class_index = tf.argmax(preds[0]) if class_index is None else class_index\n",
        "        class_channel = preds[:, class_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # hre we use the guided backpropagation gradients here\n",
        "    guided_grads = grads * tf.cast(last_conv_layer_output > 0, 'float32')\n",
        "\n",
        "    # pool the gradients across all the channels\n",
        "    pooled_grads = tf.reduce_mean(guided_grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Mmultiply each channel by the pooled gradients\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    for i in range(last_conv_layer_output.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # reate the heatmap\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap = heatmap / np.max(heatmap)  # Normalize the heatmap\n",
        "\n",
        "    # resize the heatmap to the size of the input image\n",
        "    heatmap = cv2.resize(heatmap.numpy(), (img_array.shape[2], img_array.shape[1]))\n",
        "\n",
        "    return heatmap\n"
      ],
      "metadata": {
        "id": "oU1Gv_c_xXic"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 2: overlay Grad-CAM on the Image\n",
        "Once we have the Grad-CAM heatma we can overlay it on the original image to see which parts of the image the model is focusing on."
      ],
      "metadata": {
        "id": "4nOy3SdWxiPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_gradcam(heatmap, img_array, alpha=0.4):\n",
        "\n",
        "    # convertingthe image to the range [0, 255]\n",
        "    img_array = img_array[0]\n",
        "    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
        "    img_array = np.uint8(255 * img_array)\n",
        "\n",
        "    # converting the heatmap to the range [0, 255]\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # applys a colormap to the heatmap\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    # overlay the heatmap on the image\n",
        "    gradcam_img = cv2.addWeighted(img_array, 1 - alpha, heatmap, alpha, 0)\n",
        "\n",
        "    return gradcam_img\n"
      ],
      "metadata": {
        "id": "3NI9gfPSxste"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 3:Run Guided Grad-CAM on the Images\n",
        " we now loop over the images in our test/validation dataset, process them, and generate the visualisations."
      ],
      "metadata": {
        "id": "cGwT9Lh1x3KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here I just loaded an example image from the dataset (we can loop over this for all images)\n",
        "# image_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3045.png'\n",
        "image_path = '/content/drive/MyDrive/0. MSc MLiS/google SPRING SEMESTER/1. PHYS4036 MLiS2/MLiS2 Project/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3045.png'\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# ppreprocess the image\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "# generate Grad-CAM heatmap\n",
        "heatmap = guided_gradcam(model, img_array)\n",
        "\n",
        "# ovverlay Grad-CAM heatmap on the original image\n",
        "gradcam_img = overlay_gradcam(heatmap, img_array)\n",
        "\n",
        "# display the original image and the Grad-CAM overlay\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(gradcam_img)\n",
        "plt.title(\"Guided Grad-CAM\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "UhlmSujVyBBb",
        "outputId": "bce33cb0-f3a7-43c0-80d1-9cb728672925"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No such layer: conv2d. Existing layers are: ['MobileNetV3Large', 'global_average_pooling2d', 'dropout', 'dense'].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4477dc250cb3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# generate Grad-CAM heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguided_gradcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ovverlay Grad-CAM heatmap on the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4d3b01ca2ffa>\u001b[0m in \u001b[0;36mguided_gradcam\u001b[0;34m(model, img_array, class_index)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# gets the model's output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlast_conv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv2d'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This can vary based on your architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mheatmap_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0;34mf\"No such layer: {name}. Existing layers are: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34mf\"{list(layer.name for layer in self.layers)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No such layer: conv2d. Existing layers are: ['MobileNetV3Large', 'global_average_pooling2d', 'dropout', 'dense']."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final step: Batch Processing Ik this is probally optinal but i tried to include it.\n",
        "loops through the images in the dataset, process them, and save/display the Grad-CAM results for each one."
      ],
      "metadata": {
        "id": "EfkN-7mOyKls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_path in image_file_paths:\n",
        "\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    # Generate Grad-CAM heatmap and overlay it\n",
        "    heatmap = guided_gradcam(model, img_array)\n",
        "    gradcam_img = overlay_gradcam(heatmap, img_array)\n",
        "\n",
        "    # Save the image or display it\n",
        "    output_path = '/content/grad_cam_outputs/{}'.format(os.path.basename(image_path))\n",
        "    cv2.imwrite(output_path, gradcam_img)  # Save the image\n"
      ],
      "metadata": {
        "id": "s8ZGt1C4yXiY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "7d659ef6-85f4-4d65-a8d0-fd457d36972c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No such layer: conv2d. Existing layers are: ['MobileNetV3Large', 'global_average_pooling2d', 'dropout', 'dense'].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3f68abf3b243>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Generate Grad-CAM heatmap and overlay it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguided_gradcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mgradcam_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverlay_gradcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4d3b01ca2ffa>\u001b[0m in \u001b[0;36mguided_gradcam\u001b[0;34m(model, img_array, class_index)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# gets the model's output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlast_conv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv2d'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This can vary based on your architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mheatmap_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0;34mf\"No such layer: {name}. Existing layers are: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34mf\"{list(layer.name for layer in self.layers)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No such layer: conv2d. Existing layers are: ['MobileNetV3Large', 'global_average_pooling2d', 'dropout', 'dense']."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = model.get_layer(\"MobileNetV3Large\")\n",
        "for layer in base_model.layers:\n",
        "    print(layer.name, layer.output.shape)\n"
      ],
      "metadata": {
        "id": "TyPXtqAz2dgO",
        "outputId": "bceb6420-cccc-4fd8-bb5b-cb05c697146c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer (None, 224, 224, 3)\n",
            "rescaling (None, 224, 224, 3)\n",
            "conv (None, 112, 112, 16)\n",
            "conv_bn (None, 112, 112, 16)\n",
            "activation (None, 112, 112, 16)\n",
            "expanded_conv_depthwise (None, 112, 112, 16)\n",
            "expanded_conv_depthwise_bn (None, 112, 112, 16)\n",
            "re_lu (None, 112, 112, 16)\n",
            "expanded_conv_project (None, 112, 112, 16)\n",
            "expanded_conv_project_bn (None, 112, 112, 16)\n",
            "expanded_conv_add (None, 112, 112, 16)\n",
            "expanded_conv_1_expand (None, 112, 112, 64)\n",
            "expanded_conv_1_expand_bn (None, 112, 112, 64)\n",
            "re_lu_1 (None, 112, 112, 64)\n",
            "expanded_conv_1_depthwise_pad (None, 113, 113, 64)\n",
            "expanded_conv_1_depthwise (None, 56, 56, 64)\n",
            "expanded_conv_1_depthwise_bn (None, 56, 56, 64)\n",
            "re_lu_2 (None, 56, 56, 64)\n",
            "expanded_conv_1_project (None, 56, 56, 24)\n",
            "expanded_conv_1_project_bn (None, 56, 56, 24)\n",
            "expanded_conv_2_expand (None, 56, 56, 72)\n",
            "expanded_conv_2_expand_bn (None, 56, 56, 72)\n",
            "re_lu_3 (None, 56, 56, 72)\n",
            "expanded_conv_2_depthwise (None, 56, 56, 72)\n",
            "expanded_conv_2_depthwise_bn (None, 56, 56, 72)\n",
            "re_lu_4 (None, 56, 56, 72)\n",
            "expanded_conv_2_project (None, 56, 56, 24)\n",
            "expanded_conv_2_project_bn (None, 56, 56, 24)\n",
            "expanded_conv_2_add (None, 56, 56, 24)\n",
            "expanded_conv_3_expand (None, 56, 56, 72)\n",
            "expanded_conv_3_expand_bn (None, 56, 56, 72)\n",
            "re_lu_5 (None, 56, 56, 72)\n",
            "expanded_conv_3_depthwise_pad (None, 59, 59, 72)\n",
            "expanded_conv_3_depthwise (None, 28, 28, 72)\n",
            "expanded_conv_3_depthwise_bn (None, 28, 28, 72)\n",
            "re_lu_6 (None, 28, 28, 72)\n",
            "expanded_conv_3_squeeze_excite_avg_pool (None, 1, 1, 72)\n",
            "expanded_conv_3_squeeze_excite_conv (None, 1, 1, 24)\n",
            "expanded_conv_3_squeeze_excite_relu (None, 1, 1, 24)\n",
            "expanded_conv_3_squeeze_excite_conv_1 (None, 1, 1, 72)\n",
            "re_lu_7 (None, 1, 1, 72)\n",
            "expanded_conv_3_squeeze_excite_mul (None, 28, 28, 72)\n",
            "expanded_conv_3_project (None, 28, 28, 40)\n",
            "expanded_conv_3_project_bn (None, 28, 28, 40)\n",
            "expanded_conv_4_expand (None, 28, 28, 120)\n",
            "expanded_conv_4_expand_bn (None, 28, 28, 120)\n",
            "re_lu_8 (None, 28, 28, 120)\n",
            "expanded_conv_4_depthwise (None, 28, 28, 120)\n",
            "expanded_conv_4_depthwise_bn (None, 28, 28, 120)\n",
            "re_lu_9 (None, 28, 28, 120)\n",
            "expanded_conv_4_squeeze_excite_avg_pool (None, 1, 1, 120)\n",
            "expanded_conv_4_squeeze_excite_conv (None, 1, 1, 32)\n",
            "expanded_conv_4_squeeze_excite_relu (None, 1, 1, 32)\n",
            "expanded_conv_4_squeeze_excite_conv_1 (None, 1, 1, 120)\n",
            "re_lu_10 (None, 1, 1, 120)\n",
            "expanded_conv_4_squeeze_excite_mul (None, 28, 28, 120)\n",
            "expanded_conv_4_project (None, 28, 28, 40)\n",
            "expanded_conv_4_project_bn (None, 28, 28, 40)\n",
            "expanded_conv_4_add (None, 28, 28, 40)\n",
            "expanded_conv_5_expand (None, 28, 28, 120)\n",
            "expanded_conv_5_expand_bn (None, 28, 28, 120)\n",
            "re_lu_11 (None, 28, 28, 120)\n",
            "expanded_conv_5_depthwise (None, 28, 28, 120)\n",
            "expanded_conv_5_depthwise_bn (None, 28, 28, 120)\n",
            "re_lu_12 (None, 28, 28, 120)\n",
            "expanded_conv_5_squeeze_excite_avg_pool (None, 1, 1, 120)\n",
            "expanded_conv_5_squeeze_excite_conv (None, 1, 1, 32)\n",
            "expanded_conv_5_squeeze_excite_relu (None, 1, 1, 32)\n",
            "expanded_conv_5_squeeze_excite_conv_1 (None, 1, 1, 120)\n",
            "re_lu_13 (None, 1, 1, 120)\n",
            "expanded_conv_5_squeeze_excite_mul (None, 28, 28, 120)\n",
            "expanded_conv_5_project (None, 28, 28, 40)\n",
            "expanded_conv_5_project_bn (None, 28, 28, 40)\n",
            "expanded_conv_5_add (None, 28, 28, 40)\n",
            "expanded_conv_6_expand (None, 28, 28, 240)\n",
            "expanded_conv_6_expand_bn (None, 28, 28, 240)\n",
            "activation_1 (None, 28, 28, 240)\n",
            "expanded_conv_6_depthwise_pad (None, 29, 29, 240)\n",
            "expanded_conv_6_depthwise (None, 14, 14, 240)\n",
            "expanded_conv_6_depthwise_bn (None, 14, 14, 240)\n",
            "activation_2 (None, 14, 14, 240)\n",
            "expanded_conv_6_project (None, 14, 14, 80)\n",
            "expanded_conv_6_project_bn (None, 14, 14, 80)\n",
            "expanded_conv_7_expand (None, 14, 14, 200)\n",
            "expanded_conv_7_expand_bn (None, 14, 14, 200)\n",
            "activation_3 (None, 14, 14, 200)\n",
            "expanded_conv_7_depthwise (None, 14, 14, 200)\n",
            "expanded_conv_7_depthwise_bn (None, 14, 14, 200)\n",
            "activation_4 (None, 14, 14, 200)\n",
            "expanded_conv_7_project (None, 14, 14, 80)\n",
            "expanded_conv_7_project_bn (None, 14, 14, 80)\n",
            "expanded_conv_7_add (None, 14, 14, 80)\n",
            "expanded_conv_8_expand (None, 14, 14, 184)\n",
            "expanded_conv_8_expand_bn (None, 14, 14, 184)\n",
            "activation_5 (None, 14, 14, 184)\n",
            "expanded_conv_8_depthwise (None, 14, 14, 184)\n",
            "expanded_conv_8_depthwise_bn (None, 14, 14, 184)\n",
            "activation_6 (None, 14, 14, 184)\n",
            "expanded_conv_8_project (None, 14, 14, 80)\n",
            "expanded_conv_8_project_bn (None, 14, 14, 80)\n",
            "expanded_conv_8_add (None, 14, 14, 80)\n",
            "expanded_conv_9_expand (None, 14, 14, 184)\n",
            "expanded_conv_9_expand_bn (None, 14, 14, 184)\n",
            "activation_7 (None, 14, 14, 184)\n",
            "expanded_conv_9_depthwise (None, 14, 14, 184)\n",
            "expanded_conv_9_depthwise_bn (None, 14, 14, 184)\n",
            "activation_8 (None, 14, 14, 184)\n",
            "expanded_conv_9_project (None, 14, 14, 80)\n",
            "expanded_conv_9_project_bn (None, 14, 14, 80)\n",
            "expanded_conv_9_add (None, 14, 14, 80)\n",
            "expanded_conv_10_expand (None, 14, 14, 480)\n",
            "expanded_conv_10_expand_bn (None, 14, 14, 480)\n",
            "activation_9 (None, 14, 14, 480)\n",
            "expanded_conv_10_depthwise (None, 14, 14, 480)\n",
            "expanded_conv_10_depthwise_bn (None, 14, 14, 480)\n",
            "activation_10 (None, 14, 14, 480)\n",
            "expanded_conv_10_squeeze_excite_avg_pool (None, 1, 1, 480)\n",
            "expanded_conv_10_squeeze_excite_conv (None, 1, 1, 120)\n",
            "expanded_conv_10_squeeze_excite_relu (None, 1, 1, 120)\n",
            "expanded_conv_10_squeeze_excite_conv_1 (None, 1, 1, 480)\n",
            "re_lu_14 (None, 1, 1, 480)\n",
            "expanded_conv_10_squeeze_excite_mul (None, 14, 14, 480)\n",
            "expanded_conv_10_project (None, 14, 14, 112)\n",
            "expanded_conv_10_project_bn (None, 14, 14, 112)\n",
            "expanded_conv_11_expand (None, 14, 14, 672)\n",
            "expanded_conv_11_expand_bn (None, 14, 14, 672)\n",
            "activation_11 (None, 14, 14, 672)\n",
            "expanded_conv_11_depthwise (None, 14, 14, 672)\n",
            "expanded_conv_11_depthwise_bn (None, 14, 14, 672)\n",
            "activation_12 (None, 14, 14, 672)\n",
            "expanded_conv_11_squeeze_excite_avg_pool (None, 1, 1, 672)\n",
            "expanded_conv_11_squeeze_excite_conv (None, 1, 1, 168)\n",
            "expanded_conv_11_squeeze_excite_relu (None, 1, 1, 168)\n",
            "expanded_conv_11_squeeze_excite_conv_1 (None, 1, 1, 672)\n",
            "re_lu_15 (None, 1, 1, 672)\n",
            "expanded_conv_11_squeeze_excite_mul (None, 14, 14, 672)\n",
            "expanded_conv_11_project (None, 14, 14, 112)\n",
            "expanded_conv_11_project_bn (None, 14, 14, 112)\n",
            "expanded_conv_11_add (None, 14, 14, 112)\n",
            "expanded_conv_12_expand (None, 14, 14, 672)\n",
            "expanded_conv_12_expand_bn (None, 14, 14, 672)\n",
            "activation_13 (None, 14, 14, 672)\n",
            "expanded_conv_12_depthwise_pad (None, 17, 17, 672)\n",
            "expanded_conv_12_depthwise (None, 7, 7, 672)\n",
            "expanded_conv_12_depthwise_bn (None, 7, 7, 672)\n",
            "activation_14 (None, 7, 7, 672)\n",
            "expanded_conv_12_squeeze_excite_avg_pool (None, 1, 1, 672)\n",
            "expanded_conv_12_squeeze_excite_conv (None, 1, 1, 168)\n",
            "expanded_conv_12_squeeze_excite_relu (None, 1, 1, 168)\n",
            "expanded_conv_12_squeeze_excite_conv_1 (None, 1, 1, 672)\n",
            "re_lu_16 (None, 1, 1, 672)\n",
            "expanded_conv_12_squeeze_excite_mul (None, 7, 7, 672)\n",
            "expanded_conv_12_project (None, 7, 7, 160)\n",
            "expanded_conv_12_project_bn (None, 7, 7, 160)\n",
            "expanded_conv_13_expand (None, 7, 7, 960)\n",
            "expanded_conv_13_expand_bn (None, 7, 7, 960)\n",
            "activation_15 (None, 7, 7, 960)\n",
            "expanded_conv_13_depthwise (None, 7, 7, 960)\n",
            "expanded_conv_13_depthwise_bn (None, 7, 7, 960)\n",
            "activation_16 (None, 7, 7, 960)\n",
            "expanded_conv_13_squeeze_excite_avg_pool (None, 1, 1, 960)\n",
            "expanded_conv_13_squeeze_excite_conv (None, 1, 1, 240)\n",
            "expanded_conv_13_squeeze_excite_relu (None, 1, 1, 240)\n",
            "expanded_conv_13_squeeze_excite_conv_1 (None, 1, 1, 960)\n",
            "re_lu_17 (None, 1, 1, 960)\n",
            "expanded_conv_13_squeeze_excite_mul (None, 7, 7, 960)\n",
            "expanded_conv_13_project (None, 7, 7, 160)\n",
            "expanded_conv_13_project_bn (None, 7, 7, 160)\n",
            "expanded_conv_13_add (None, 7, 7, 160)\n",
            "expanded_conv_14_expand (None, 7, 7, 960)\n",
            "expanded_conv_14_expand_bn (None, 7, 7, 960)\n",
            "activation_17 (None, 7, 7, 960)\n",
            "expanded_conv_14_depthwise (None, 7, 7, 960)\n",
            "expanded_conv_14_depthwise_bn (None, 7, 7, 960)\n",
            "activation_18 (None, 7, 7, 960)\n",
            "expanded_conv_14_squeeze_excite_avg_pool (None, 1, 1, 960)\n",
            "expanded_conv_14_squeeze_excite_conv (None, 1, 1, 240)\n",
            "expanded_conv_14_squeeze_excite_relu (None, 1, 1, 240)\n",
            "expanded_conv_14_squeeze_excite_conv_1 (None, 1, 1, 960)\n",
            "re_lu_18 (None, 1, 1, 960)\n",
            "expanded_conv_14_squeeze_excite_mul (None, 7, 7, 960)\n",
            "expanded_conv_14_project (None, 7, 7, 160)\n",
            "expanded_conv_14_project_bn (None, 7, 7, 160)\n",
            "expanded_conv_14_add (None, 7, 7, 160)\n",
            "conv_1 (None, 7, 7, 960)\n",
            "conv_1_bn (None, 7, 7, 960)\n",
            "activation_19 (None, 7, 7, 960)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_conv_layer = base_model.get_layer(\"conv_1_bn\").output\n"
      ],
      "metadata": {
        "id": "CCMteHCK3OOd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models\n",
        "\n",
        "def grad_cam(input_model, image, layer_name=\"conv_1_bn\"):\n",
        "\n",
        "    last_conv_layer = input_model.get_layer(layer_name).output\n",
        "    classifier_input = input_model.input\n",
        "    classifier_output = input_model.output\n",
        "    grad_model = models.Model([classifier_input], [last_conv_layer, classifier_output])\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        tape.watch(image)\n",
        "        conv_outputs, predictions = grad_model(image)\n",
        "        loss = predictions[:, np.argmax(predictions[0])]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    heatmap = conv_outputs[0] @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "def display_grad_cam(heatmap, image, alpha=0.4):\n",
        "\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = np.expand_dims(heatmap, axis=-1)\n",
        "    heatmap = np.repeat(heatmap, 3, axis=-1)\n",
        "\n",
        "\n",
        "    superimposed_img = image * (1 - alpha) + heatmap * alpha\n",
        "\n",
        "\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "R2XxzYRg3y8v"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working GradCAM on one image."
      ],
      "metadata": {
        "id": "gZBxGfGx5WtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import cv2  # OpenCV for resizing\n",
        "\n",
        "# Grad-CAM function with corrected layer name\n",
        "def grad_cam(input_model, image, layer_name=\"conv1_bn\"):\n",
        "    # convert the image to a tf.Tensor\n",
        "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "\n",
        "    last_conv_layer = input_model.get_layer(layer_name).output\n",
        "    classifier_input = input_model.input\n",
        "    classifier_output = input_model.output\n",
        "\n",
        "    grad_model = tf.keras.models.Model([classifier_input], [last_conv_layer, classifier_output])\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        conv_outputs, predictions = grad_model(image)\n",
        "        loss = predictions[:, np.argmax(predictions[0])]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    heatmap = conv_outputs[0] @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "# ffunction to display Grad-CAM\n",
        "def display_grad_cam(heatmap, image, alpha=0.4):\n",
        "    # i had to resize heatmap to match the input image size\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = np.expand_dims(heatmap, axis=-1)\n",
        "    heatmap = np.repeat(heatmap, 3, axis=-1)\n",
        "\n",
        "    # resize heatmap to the original image dimensions (224x224)\n",
        "    heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
        "\n",
        "    superimposed_img = image * (1 - alpha) + heatmap_resized * alpha\n",
        "\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# loading pre-trained model (ResNet50 example)\n",
        "base_model = tf.keras.applications.ResNet50(weights='imagenet')\n",
        "\n",
        "# load and preprocess the image\n",
        "img_path = '/content/drive/MyDrive/0. MSc MLiS/google SPRING SEMESTER/1. PHYS4036 MLiS2/MLiS2 Project/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data/3045.png'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "# preprocessing image\n",
        "img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
        "\n",
        "# add batch dimension\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# generate and display Grad-CAM\n",
        "heatmap = grad_cam(base_model, img_array)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "colourmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "plt.imshow(colourmap)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "# display_grad_cam(heatmap, img_array[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "pe6nn7A_4EBS",
        "outputId": "2d973f1f-fc28-4975-d7cd-cdfcfdf54519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor_1978']\n",
            "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "last_conv_layer = base_model.get_layer(\"conv_1_bn\").output\n",
        "\n"
      ],
      "metadata": {
        "id": "6G_0X-3i3nQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[::-1]:  # Iterate in reverse\n",
        "    if 'conv' in layer.name.lower():\n",
        "        print(layer.name)\n",
        "        break  # Stop at the last convolutional layer\n"
      ],
      "metadata": {
        "id": "87HtnyR03AQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap = guided_gradcam(model, img_array)\n"
      ],
      "metadata": {
        "id": "GiMy2PJ_1p-s",
        "outputId": "b8707e8d-d59f-400a-f49d-dda7639f96b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "The layer sequential has never been called and thus has no defined input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-3046365baf45>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguided_gradcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-50aba7cb6a6c>\u001b[0m in \u001b[0;36mguided_gradcam\u001b[0;34m(model, img_array)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# 2. Model predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     grad_model = tf.keras.models.Model(\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: The layer sequential has never been called and thus has no defined input."
          ]
        }
      ]
    }
  ]
}