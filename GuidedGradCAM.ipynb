{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/GuidedGradCAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
      ],
      "metadata": {
        "id": "-fhwRSFoj6C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "g4V83PflfFkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kP6UczzNe1l2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "print(platform.system())"
      ],
      "metadata": {
        "id": "O24_U-m8q-xv",
        "outputId": "b40fbbe3-2652-477e-9e1a-71175136f05d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# makes it so pd dfs aren't truncated\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "IF_vPVifaU9V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eocC68amnhEI",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d82587c-f3fc-43cb-b867-7639b54a0b13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) DATA PRE-PROCESSING\n",
        "\n",
        "a) Load in labels + image file paths\n",
        "\n",
        "b) combine them into one dataframe\n",
        "\n",
        "c) EDA - spotted and removed erroneous label (speed = 1.42...)\n",
        "\n",
        "- `cleaned_df` is the cleaned df with a) b) c) completed\n",
        "\n",
        "d) convert images to numerical RGB feature maps - ML algorithms only understand numerical data\n",
        "\n",
        "e) Splitting data into training and validation sets\n",
        "\n",
        "f) data augmentation applied to training set"
      ],
      "metadata": {
        "id": "-_MvRvYnfIM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a) load in labels + image file paths"
      ],
      "metadata": {
        "id": "HU3TvBZ5hfhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # tylers file path\n",
        "#labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
        "# labels_file_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_norm.csv' # tyler hpc file path (mlis2 cluster)\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ],
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data' # ben hpc file path (mlis2 cluster)\n",
        "# image_folder_path = '/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data'\n",
        "image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ],
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking labels dataframe"
      ],
      "metadata": {
        "id": "0oeuvmeZaGSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "2pi13TZ2aFhO",
        "outputId": "10a5f4e0-5415-48c9-e6ad-99ff0569d564"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed\n",
              "image_id               \n",
              "1         0.4375    0.0\n",
              "2         0.8125    1.0\n",
              "3         0.4375    1.0\n",
              "4         0.6250    1.0\n",
              "5         0.5000    0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ef8faf3-1df2-4c96-ad6e-bc0fef7d58b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ef8faf3-1df2-4c96-ad6e-bc0fef7d58b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ef8faf3-1df2-4c96-ad6e-bc0fef7d58b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ef8faf3-1df2-4c96-ad6e-bc0fef7d58b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-56b21a99-5d9f-4315-a389-2dac2c141167\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56b21a99-5d9f-4315-a389-2dac2c141167')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-56b21a99-5d9f-4315-a389-2dac2c141167 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df",
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 13793,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3983,\n        \"min\": 1,\n        \"max\": 13798,\n        \"num_unique_values\": 13793,\n        \"samples\": [\n          2486,\n          7115,\n          748\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"angle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15555820377620463,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.4375,\n          0.8125,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4305956548518498,\n        \"min\": 0.0,\n        \"max\": 1.42857142857143,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0,\n          1.42857142857143\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
      ],
      "metadata": {
        "id": "puEjGoOJaRS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "a1suFSK7aWKH",
        "outputId": "01952708-c62b-4ca7-9f79-51d9dd837340"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                       image_file_paths\n",
              "image_id                                                                                               \n",
              "8          /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8.png\n",
              "9          /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/9.png\n",
              "14        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/14.png\n",
              "15        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/15.png\n",
              "16        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/16.png"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38bd8b14-5869-48c7-b83e-f5aff23ae1f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/9.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/14.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/15.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/16.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38bd8b14-5869-48c7-b83e-f5aff23ae1f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38bd8b14-5869-48c7-b83e-f5aff23ae1f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38bd8b14-5869-48c7-b83e-f5aff23ae1f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-985e8a08-5c28-4135-a6d3-48db739872a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-985e8a08-5c28-4135-a6d3-48db739872a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-985e8a08-5c28-4135-a6d3-48db739872a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "imagefilepaths_df",
              "summary": "{\n  \"name\": \"imagefilepaths_df\",\n  \"rows\": 5238,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3948,\n        \"min\": 8,\n        \"max\": 13798,\n        \"num_unique_values\": 5238,\n        \"samples\": [\n          8089,\n          3379,\n          1179\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_file_paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5238,\n        \"samples\": [\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8089.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3379.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/1179.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b) Combine labels and image file paths into one dataframe"
      ],
      "metadata": {
        "id": "CjDdyYd6cMBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
        "merged_df['speed'] = merged_df['speed'].round(6) # to get rid of floating point errors"
      ],
      "metadata": {
        "id": "6NdbonzPcLKB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "-VstirIAdAZi",
        "outputId": "0b37f561-e659-4ae7-cf83-bcd18e18092f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          angle  speed  \\\n",
              "image_id                 \n",
              "8         0.500    1.0   \n",
              "9         0.500    0.0   \n",
              "14        0.875    1.0   \n",
              "15        0.625    1.0   \n",
              "16        0.500    1.0   \n",
              "\n",
              "                                                                                       image_file_paths  \n",
              "image_id                                                                                                 \n",
              "8          /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8.png  \n",
              "9          /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/9.png  \n",
              "14        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/14.png  \n",
              "15        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/15.png  \n",
              "16        /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/16.png  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-196fb6c9-95d2-4f89-afdd-6eef4c88adf2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/9.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/14.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/15.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/16.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-196fb6c9-95d2-4f89-afdd-6eef4c88adf2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-196fb6c9-95d2-4f89-afdd-6eef4c88adf2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-196fb6c9-95d2-4f89-afdd-6eef4c88adf2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ad751cfc-9046-46fc-bce0-576d01a4db8b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad751cfc-9046-46fc-bce0-576d01a4db8b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ad751cfc-9046-46fc-bce0-576d01a4db8b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 5235,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3948,\n        \"min\": 8,\n        \"max\": 13798,\n        \"num_unique_values\": 5235,\n        \"samples\": [\n          8102,\n          3380,\n          1179\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"angle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1566358687964845,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.5,\n          0.875,\n          0.8125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4346144313921845,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_file_paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5235,\n        \"samples\": [\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/8102.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3380.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.loc[3139:3143]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "8MgNoL8nfBm2",
        "outputId": "4ef87e41-78d0-4297-f4c6-1e2393a20447"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          angle  speed  \\\n",
              "image_id                 \n",
              "3140      0.875    1.0   \n",
              "3142      0.625    0.0   \n",
              "3143      0.625    1.0   \n",
              "\n",
              "                                                                                         image_file_paths  \n",
              "image_id                                                                                                   \n",
              "3140      /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3140.png  \n",
              "3142      /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3142.png  \n",
              "3143      /content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3143.png  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fde8d5e-f57c-45af-9a8c-93a0a63dabf0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>0.875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3140.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3142</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3142.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3143</th>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3143.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fde8d5e-f57c-45af-9a8c-93a0a63dabf0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6fde8d5e-f57c-45af-9a8c-93a0a63dabf0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6fde8d5e-f57c-45af-9a8c-93a0a63dabf0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41fb7189-88f4-4333-8da4-df7f2c8af313\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41fb7189-88f4-4333-8da4-df7f2c8af313')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41fb7189-88f4-4333-8da4-df7f2c8af313 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3140,\n        \"max\": 3143,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3140,\n          3142,\n          3143\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"angle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14433756729740646,\n        \"min\": 0.625,\n        \"max\": 0.875,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.625,\n          0.875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5773502691896258,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_file_paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3140.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3142.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above cell shows that:\n",
        "\n",
        " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
        "\n",
        " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
      ],
      "metadata": {
        "id": "U7PCxqJbmXE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c) EDA"
      ],
      "metadata": {
        "id": "h3OKLcn9u0Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.value_counts('speed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "IWQCQrR-oCps",
        "outputId": "344847bc-7f27-44d8-abfb-b0bcfe3e7c04"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "speed\n",
              "1.0    3912\n",
              "0.0    1323\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speed</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>3912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>1323</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note: imbalance datset"
      ],
      "metadata": {
        "id": "K4pZ65pYvdqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "identifying the row with the erroneous speed value"
      ],
      "metadata": {
        "id": "xJmG7jmNkE0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df[merged_df['speed'] == 1.428571]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "wAQnbLLeiqy2",
        "outputId": "bb399525-122a-46be-944e-0e6301b2c060"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [angle, speed, image_file_paths]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45f0e566-e16b-4040-a121-287f84c00eb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45f0e566-e16b-4040-a121-287f84c00eb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45f0e566-e16b-4040-a121-287f84c00eb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45f0e566-e16b-4040-a121-287f84c00eb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to remove this row"
      ],
      "metadata": {
        "id": "zMZq41-RkLz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = merged_df[merged_df['speed'] != 1.428571]\n",
        "cleaned_df.loc[3882:3886]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "TDMqIiOLSKGX",
        "outputId": "a24ec2cd-6670-4aad-8e19-0e6e78e0d5a8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [angle, speed, image_file_paths]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-637afd2d-011f-4252-b527-46940d716fc4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-637afd2d-011f-4252-b527-46940d716fc4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-637afd2d-011f-4252-b527-46940d716fc4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-637afd2d-011f-4252-b527-46940d716fc4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1d) convert images to numerical RGB feature maps"
      ],
      "metadata": {
        "id": "Di6F6km_DBmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path, label, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, resized_shape)\n",
        "    image = image / 255.0  # Normalise pixel values to [0,1]\n",
        "    return image, label\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"speed\"])) # Convert pd df into a tf ds\n",
        "\n",
        "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(len(cleaned_df))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oeeBTruNCQ96"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets check and see if what we have done works"
      ],
      "metadata": {
        "id": "pUOlsWQeVlyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in dataset.take(1):\n",
        "    print(images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "jBTNjNhMVk2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c055f3-3744-4690-8289-8b55ddbc1476"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3) (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1e) Splitting data into training and validation sets (test set is already provided in kaggle data)"
      ],
      "metadata": {
        "id": "Md6U_i84SiK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80-20 split\n",
        "\n",
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)"
      ],
      "metadata": {
        "id": "yYlssPh5dxaO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train size: {train_size}, validation size: {dataset_size - train_size}\")"
      ],
      "metadata": {
        "id": "qPUE6rd8cgQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292b1dce-606d-4507-915f-10ed3d074f50"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 131, validation size: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1f) Data Augmentation applied to training set\n",
        "\n",
        "- Random Horizontal Flip\n",
        "- Random Brightness Adjustment\n",
        "- Random Contrast Adjustment\n",
        "- Random Hue Adjustment\n",
        "- Random Saturation Adjustment\n",
        "- Random Vertical Flip\n",
        "\n"
      ],
      "metadata": {
        "id": "0ujsjhMPSw4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_image(image, label):\n",
        "  seed = (6, 9)\n",
        "  image = tf.image.stateless_random_brightness(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_contrast(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_saturation(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_flip_left_right(image, seed)\n",
        "  image = tf.image.stateless_random_flip_up_down(image, seed)\n",
        "  return image, label\n",
        "\n",
        "# Create a dataset of augmented images from the original train_dataset\n",
        "augmented_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Concatenate the original and augmented datasets\n",
        "train_dataset = train_dataset.concatenate(augmented_dataset)\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(cleaned_df))"
      ],
      "metadata": {
        "id": "T9r811eWsYfe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "count how many images are in the training set"
      ],
      "metadata": {
        "id": "ZOqizFg7rvKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_images = 0\n",
        "for image_batch, _ in train_dataset:\n",
        "    total_images += image_batch.shape[0]  # Add the batch size\n",
        "\n",
        "print(f\"Total number of images in train_dataset: {total_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjlyfjAxLsrC",
        "outputId": "f25f7ba0-8fed-4227-8d54-55594302318c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images in train_dataset: 8384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking to see if whats been done was successful or needs debugging"
      ],
      "metadata": {
        "id": "HEdi-dUCTND1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, axarr = plt.subplots(1,10)\n",
        "\n",
        "i = 0\n",
        "for image_batch, label_batch in dataset.take(1):  # Take one batch\n",
        "    for image in image_batch:  # Iterate through images in the batch\n",
        "        if i < 10:  # Only display the first 5 images\n",
        "            print('image shape: ', np.shape(image))\n",
        "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
        "            axarr[i].imshow(image)\n",
        "            axarr[i].axis('off')\n",
        "            i += 1\n",
        "        else:\n",
        "            break  # Stop after displaying 5 images\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OeboVhsQKGFS",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "577049e3-a9d1-4a5e-a3c1-08dbf5ec7b45"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Model Building - MobileNetV3Large Transfer Learning\n",
        "\n",
        "a) Set up model architecture\n",
        "\n",
        "b) define training step\n",
        "\n",
        "c) training the model on the training set\n",
        "\n",
        "d) fine-tuning"
      ],
      "metadata": {
        "id": "cmetmzNHTWzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a) Set up model architecture\n",
        "\n",
        "- MobileNetV2 to learn lower level features\n",
        "- global average pooling layer\n",
        "- drop out layer\n",
        "- dense layer with sigmoid activation"
      ],
      "metadata": {
        "id": "48RHLVshdX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
        "])\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = False # freeze the first layers to the imagenet weights\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "Eh1-U-VYeN9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "66a3117e-876f-4fc1-a038-2fee5fceb6f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " MobileNetV3Large (\u001b[38;5;33mFunctional\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m)                  \u001b[38;5;34m2,996,352\u001b[0m \n",
              "\n",
              " global_average_pooling2d              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)                                                           \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                                \u001b[38;5;34m961\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " MobileNetV3Large (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> \n",
              "\n",
              " global_average_pooling2d              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)                                                           \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">961</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,997,313\u001b[0m (11.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,997,313</span> (11.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m961\u001b[0m (3.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">961</span> (3.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,996,352\u001b[0m (11.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> (11.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) Define training step\n",
        "\n",
        "- adam optimiser\n",
        "- binary cross entropy loss function"
      ],
      "metadata": {
        "id": "3iuqe2Xwpu7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.001  # learning rate\n",
        "optimizer = tf.optimizers.Adam(LR)\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, X, Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model(X)  # Get the predictions from the model\n",
        "\n",
        "        # Use binary cross-entropy for binary classification\n",
        "        current_loss = tf.reduce_mean(tf.losses.binary_crossentropy(Y, pred))\n",
        "\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Threshold predictions to binary values (0 or 1) for accuracy calculation\n",
        "    pred_binary = tf.cast(pred > 0.5, dtype=tf.int32)  # Convert predictions to binary (0 or 1)\n",
        "\n",
        "    # Calculate True Positives, False Positives, True Negatives, False Negatives\n",
        "    TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 1), dtype=tf.int32))\n",
        "    TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 0), dtype=tf.int32))\n",
        "    FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 0), dtype=tf.int32))\n",
        "    FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 1), dtype=tf.int32))\n",
        "\n",
        "    # Calculate Balanced Accuracy\n",
        "    sensitivity = TP / (TP + FN)  # Recall for class 1\n",
        "    specificity = TN / (TN + FP)  # Recall for class 0\n",
        "    balanced_accuracy = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "    return current_loss, balanced_accuracy\n"
      ],
      "metadata": {
        "id": "9AErZvcTeX-d"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2c) Training the model on the training set"
      ],
      "metadata": {
        "id": "bUMefNeTpDWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 50\n",
        "\n",
        "tloss = []\n",
        "tacc = []\n",
        "vloss = []\n",
        "vacc = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_accs = []\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "        # Convert labels to correct format for binary classification\n",
        "        # Convert to [batch_size, 1] for binary classification with sigmoid\n",
        "        labels = tf.expand_dims(tf.cast(label_batch, dtype=tf.float32), axis=1)\n",
        "        loss, acc = train_step(model, image_batch, labels)\n",
        "        batch_losses.append(loss)\n",
        "        batch_accs.append(acc)\n",
        "\n",
        "    # Average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses).numpy()\n",
        "    avg_acc = tf.reduce_mean(batch_accs).numpy()\n",
        "    tloss.append(avg_loss)\n",
        "    tacc.append(avg_acc)\n",
        "\n",
        "    # LOGGING METRICS TO CHECK HOW TRAIING IS GOING\n",
        "\n",
        "    if it % 10 == 0:\n",
        "        tf.print(f'iter: {it}, train_loss: {avg_loss:.3f}, train_balanced_acc: {avg_acc:.3f}')\n",
        "\n",
        "        # If you have a validation dataset, evaluate on it\n",
        "        if 'val_dataset' in globals():\n",
        "            val_losses = []\n",
        "            val_accs = []\n",
        "            for val_images, val_labels in val_dataset:\n",
        "                val_labels = tf.expand_dims(tf.cast(val_labels, dtype=tf.float32), axis=1)\n",
        "                val_preds = model(val_images)\n",
        "                val_loss = tf.reduce_mean(tf.losses.binary_crossentropy(val_labels, val_preds))\n",
        "\n",
        "                # Use the same balanced accuracy calculation as in train_step\n",
        "                pred_binary = tf.cast(val_preds > 0.5, dtype=tf.int32)\n",
        "                val_labels_int = tf.cast(val_labels, dtype=tf.int32)\n",
        "\n",
        "                TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 1), dtype=tf.int32))\n",
        "                TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 1), dtype=tf.int32))\n",
        "\n",
        "                sensitivity = TP / (TP + FN + 1e-7)\n",
        "                specificity = TN / (TN + FP + 1e-7)\n",
        "                val_acc = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "\n",
        "            avg_val_loss = tf.reduce_mean(val_losses).numpy()\n",
        "            avg_val_acc = tf.reduce_mean(val_accs).numpy()\n",
        "            vloss.append(avg_val_loss)\n",
        "            vacc.append(avg_val_acc)\n",
        "\n",
        "            tf.print(f'val_loss: {avg_val_loss:.3f}, val_balanced_acc: {avg_val_acc:.3f}')"
      ],
      "metadata": {
        "id": "uE2K4gVQedXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "collapsed": true,
        "outputId": "669d147b-7a0a-4e65-f41c-c2f437901296"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0dfbeacec027>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Convert to [batch_size, 1] for binary classification with sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatch_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/home/apyba3/car_frozen_regression_mobv3.weights.h5')\n",
        "# model.save_weights('/home/ppytr13/car_frozen.weights.h5')"
      ],
      "metadata": {
        "id": "FiHy6opSP2sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session() #Clear keras session"
      ],
      "metadata": {
        "id": "FpLHyw20P93U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2d) fine-tuning"
      ],
      "metadata": {
        "id": "ENHbUvQdvyFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rebuild model after clearing keras session"
      ],
      "metadata": {
        "id": "h0ek_ytyw0KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
        "])\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = True # UNFREEZE the first layers to the imagenet weights\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "ZuKL3X-QP-Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/home/apyba3/car_frozen_regression_mobv3.weights.h5')\n",
        "# model.load_weights('/home/ppytr13/car_frozen.weights.h5')"
      ],
      "metadata": {
        "id": "8oAenzEiP-C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up fine-tuning training"
      ],
      "metadata": {
        "id": "XWDtRxBow89t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.0001\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser"
      ],
      "metadata": {
        "id": "JQvDo1RVP-Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(model, X, Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model(X)  # Get the predictions from the model\n",
        "\n",
        "        # Use binary cross-entropy for binary classification\n",
        "        current_loss = tf.reduce_mean(tf.losses.binary_crossentropy(Y, pred))\n",
        "\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Threshold predictions to binary values (0 or 1) for accuracy calculation\n",
        "    pred_binary = tf.cast(pred > 0.5, dtype=tf.int32)  # Convert predictions to binary (0 or 1)\n",
        "\n",
        "    # Calculate True Positives, False Positives, True Negatives, False Negatives\n",
        "    TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 1), dtype=tf.int32))\n",
        "    TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 0), dtype=tf.int32))\n",
        "    FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 0), dtype=tf.int32))\n",
        "    FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 1), dtype=tf.int32))\n",
        "\n",
        "    # Calculate Balanced Accuracy\n",
        "    sensitivity = TP / (TP + FN)  # Recall for class 1\n",
        "    specificity = TN / (TN + FP)  # Recall for class 0\n",
        "    balanced_accuracy = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "    return current_loss, balanced_accuracy"
      ],
      "metadata": {
        "id": "-mwoRy9saOM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 50\n",
        "\n",
        "tloss = []\n",
        "tacc = []\n",
        "vloss = []\n",
        "vacc = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_accs = []\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "        # Convert labels to correct format for binary classification\n",
        "        # Convert to [batch_size, 1] for binary classification with sigmoid\n",
        "        labels = tf.expand_dims(tf.cast(label_batch, dtype=tf.float32), axis=1)\n",
        "        loss, acc = train_step(model, image_batch, labels)\n",
        "        batch_losses.append(loss)\n",
        "        batch_accs.append(acc)\n",
        "\n",
        "    # Average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses).numpy()\n",
        "    avg_acc = tf.reduce_mean(batch_accs).numpy()\n",
        "    tloss.append(avg_loss)\n",
        "    tacc.append(avg_acc)\n",
        "\n",
        "    # LOGGING METRICS TO CHECK HOW TRAIING IS GOING\n",
        "\n",
        "    if it % 10 == 0:\n",
        "        tf.print(f'iter: {it}, train_loss: {avg_loss:.3f}, train_balanced_acc: {avg_acc:.3f}')\n",
        "\n",
        "        # If you have a validation dataset, evaluate on it\n",
        "        if 'val_dataset' in globals():\n",
        "            val_losses = []\n",
        "            val_accs = []\n",
        "            for val_images, val_labels in val_dataset:\n",
        "                val_labels = tf.expand_dims(tf.cast(val_labels, dtype=tf.float32), axis=1)\n",
        "                val_preds = model(val_images)\n",
        "                val_loss = tf.reduce_mean(tf.losses.binary_crossentropy(val_labels, val_preds))\n",
        "\n",
        "                # Use the same balanced accuracy calculation as in train_step\n",
        "                pred_binary = tf.cast(val_preds > 0.5, dtype=tf.int32)\n",
        "                val_labels_int = tf.cast(val_labels, dtype=tf.int32)\n",
        "\n",
        "                TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 1), dtype=tf.int32))\n",
        "                TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 1), dtype=tf.int32))\n",
        "\n",
        "                sensitivity = TP / (TP + FN + 1e-7)\n",
        "                specificity = TN / (TN + FP + 1e-7)\n",
        "                val_acc = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "\n",
        "            avg_val_loss = tf.reduce_mean(val_losses).numpy()\n",
        "            avg_val_acc = tf.reduce_mean(val_accs).numpy()\n",
        "            vloss.append(avg_val_loss)\n",
        "            vacc.append(avg_val_acc)\n",
        "\n",
        "            tf.print(f'val_loss: {avg_val_loss:.3f}, val_balanced_acc: {avg_val_acc:.3f}')"
      ],
      "metadata": {
        "id": "ZvmWxC1fP-Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('car_unfrozen_regression_mobv3.weights.h5')\n",
        "# model.save_weights('/home/ppytr13/car_unfrozen.weights.h5')"
      ],
      "metadata": {
        "id": "O14u6175RLjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Test-Set Predictions\n",
        "\n",
        "a) load in test data\n",
        "\n",
        "b) convert test images to numerical RGB feature maps\n",
        "\n",
        "c) generate predictions on the test set\n",
        "\n",
        "d) correctly format the predictions into a pandas dataframe\n",
        "\n",
        "e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ],
      "metadata": {
        "id": "GCbo4VcLxLgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3a) load in test data"
      ],
      "metadata": {
        "id": "HnygDJsKxYhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data'\n",
        "image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data' # tylers file path\n",
        "\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'\n",
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "id": "W-e59lQQRXKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "65c75e24-2677-481b-a50f-ee3882701d4d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                              image_file_paths\n",
              "image_id                                                                                      \n",
              "1         /content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/1.png\n",
              "2         /content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/2.png\n",
              "3         /content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/3.png\n",
              "4         /content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/4.png\n",
              "5         /content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/5.png"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c45d051-fa20-47cf-9e46-156bbd79c9fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c45d051-fa20-47cf-9e46-156bbd79c9fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c45d051-fa20-47cf-9e46-156bbd79c9fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c45d051-fa20-47cf-9e46-156bbd79c9fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9dbf3cbf-febc-448b-8067-e396dba4da17\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9dbf3cbf-febc-448b-8067-e396dba4da17')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9dbf3cbf-febc-448b-8067-e396dba4da17 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "imagefilepaths_df",
              "summary": "{\n  \"name\": \"imagefilepaths_df\",\n  \"rows\": 1020,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 294,\n        \"min\": 1,\n        \"max\": 1020,\n        \"num_unique_values\": 1020,\n        \"samples\": [\n          524,\n          603,\n          527\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_file_paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1020,\n        \"samples\": [\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/524.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/603.png\",\n          \"/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data/527.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3b) convert test images to numerical RGB feature maps"
      ],
      "metadata": {
        "id": "t-9i5trTyDTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image_no_label(image_path, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
        "    image = tf.image.resize(image, resized_shape)  # Resize to uniform shape\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((imagefilepaths_df[\"image_file_paths\"]))\n",
        "\n",
        "test_dataset = test_dataset.map(process_image_no_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "3hT_c1s5TAR-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3c) generate predictions on test set"
      ],
      "metadata": {
        "id": "gobnK7PhyLa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "NtqcOFr7TAXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "7568201a-fae2-493b-d1cb-dbc4d9dccf8e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7c784bea9760>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-736142a45787>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                 \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_to_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m           )\n\u001b[1;32m    918\u001b[0m       )\n\u001b[0;32m--> 919\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    920\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3d) correctly format the predictions into a pandas dataframe"
      ],
      "metadata": {
        "id": "zT1LJxHTPeQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = pd.DataFrame(predictions, columns=['speed'])"
      ],
      "metadata": {
        "id": "pFVWGi04fza7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "OnO0K1rReHOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sigmoid output is between [0,1]"
      ],
      "metadata": {
        "id": "sftRAg6PPnsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df[predictions_df['speed'] > 0.5] = 1\n",
        "predictions_df[predictions_df['speed'] < 0.5] = 0"
      ],
      "metadata": {
        "id": "AQ7of6YqeNJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaggle expects integers for the speed column"
      ],
      "metadata": {
        "id": "qWghSOvSPs2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df['speed'] = predictions_df['speed'].astype(int)"
      ],
      "metadata": {
        "id": "sSUAR4u0TAdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "jRGM4-OiPKAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df['speed'].value_counts()"
      ],
      "metadata": {
        "id": "4CcRKL9KTAfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ],
      "metadata": {
        "id": "oU-PhskZPaHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.to_csv('/home/apyba3/mbnetv3_speedclassification_predictions.csv')"
      ],
      "metadata": {
        "id": "deXjPTO0TAiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsp7UPIJQlKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Working Guided GradCAM"
      ],
      "metadata": {
        "id": "uw2Q0tLcwS9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow matplotlib opencv-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap1__2vJwxiH",
        "outputId": "bba65d4b-08a0-4852-dc39-e0098c93d41d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n"
      ],
      "metadata": {
        "id": "NP4AQ4zxwzp9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: defining the guided Grad-CAM Function\n",
        "Basic info on what it is:the Guided Grad-CAM combines both the Grad-CAM and Guided Backpropagation techniques. First i will compute the gradients of the predicted class with respect to the output feature map. Then i will using these gradients, then will highlight the relevant regions in the image."
      ],
      "metadata": {
        "id": "MeEQEYr2w_cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def guided_gradcam(model, img_array, class_index=None):\n",
        "\n",
        "    # gets the model's output layer\n",
        "    last_conv_layer = model.get_layer('conv2d')  # This can vary based on your architecture\n",
        "    heatmap_model = Model([model.inputs], [last_conv_layer.output, model.output])\n",
        "\n",
        "    # calculates the gradient of the class with respect to the last convolutional layer output\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = heatmap_model(img_array)\n",
        "        class_index = tf.argmax(preds[0]) if class_index is None else class_index\n",
        "        class_channel = preds[:, class_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # hre we use the guided backpropagation gradients here\n",
        "    guided_grads = grads * tf.cast(last_conv_layer_output > 0, 'float32')\n",
        "\n",
        "    # pool the gradients across all the channels\n",
        "    pooled_grads = tf.reduce_mean(guided_grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Mmultiply each channel by the pooled gradients\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    for i in range(last_conv_layer_output.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # reate the heatmap\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap = heatmap / np.max(heatmap)  # Normalize the heatmap\n",
        "\n",
        "    # resize the heatmap to the size of the input image\n",
        "    heatmap = cv2.resize(heatmap.numpy(), (img_array.shape[2], img_array.shape[1]))\n",
        "\n",
        "    return heatmap\n"
      ],
      "metadata": {
        "id": "oU1Gv_c_xXic"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 2: overlay Grad-CAM on the Image\n",
        "Once we have the Grad-CAM heatma we can overlay it on the original image to see which parts of the image the model is focusing on."
      ],
      "metadata": {
        "id": "4nOy3SdWxiPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_gradcam(heatmap, img_array, alpha=0.4):\n",
        "\n",
        "    # convertingthe image to the range [0, 255]\n",
        "    img_array = img_array[0]\n",
        "    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
        "    img_array = np.uint8(255 * img_array)\n",
        "\n",
        "    # converting the heatmap to the range [0, 255]\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # applys a colormap to the heatmap\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    # overlay the heatmap on the image\n",
        "    gradcam_img = cv2.addWeighted(img_array, 1 - alpha, heatmap, alpha, 0)\n",
        "\n",
        "    return gradcam_img\n"
      ],
      "metadata": {
        "id": "3NI9gfPSxste"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 3:Run Guided Grad-CAM on the Images\n",
        " we now loop over the images in our test/validation dataset, process them, and generate the visualisations."
      ],
      "metadata": {
        "id": "cGwT9Lh1x3KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here I just loaded an example image from the dataset (we can loop over this for all images)\n",
        "image_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3045.png'\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# ppreprocess the image\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "# generate Grad-CAM heatmap\n",
        "heatmap = guided_gradcam(model, img_array)\n",
        "\n",
        "# ovverlay Grad-CAM heatmap on the original image\n",
        "gradcam_img = overlay_gradcam(heatmap, img_array)\n",
        "\n",
        "# display the original image and the Grad-CAM overlay\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(gradcam_img)\n",
        "plt.title(\"Guided Grad-CAM\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "UhlmSujVyBBb",
        "outputId": "8eb0f894-fb1f-4b07-cb80-88c0b4665866"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No such layer: conv2d. Existing layers are: ['MobileNetV3Large', 'global_average_pooling2d', 'dropout', 'dense'].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c1d9a2f4f5dc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Generate Grad-CAM heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguided_gradcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Overlay Grad-CAM heatmap on the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-5cacca677ea7>\u001b[0m in \u001b[0;36mguided_gradcam\u001b[0;34m(model, img_array, class_index)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Get the model's output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlast_conv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv2d'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This can vary based on your architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mheatmap_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0;34mf\"No such layer: {name}. Existing layers are: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34mf\"{list(layer.name for layer in self.layers)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No such layer: conv2d. Existing layers are: ['MobileNetV3Large', 'global_average_pooling2d', 'dropout', 'dense']."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final step: Batch Processing Ik this is probally optinal but i tried to include it.\n",
        "loops through the images in the dataset, process them, and save/display the Grad-CAM results for each one."
      ],
      "metadata": {
        "id": "EfkN-7mOyKls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_path in image_file_paths:\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    # Generate Grad-CAM heatmap and overlay it\n",
        "    heatmap = guided_gradcam(model, img_array)\n",
        "    gradcam_img = overlay_gradcam(heatmap, img_array)\n",
        "\n",
        "    # Save the image or display it\n",
        "    output_path = '/content/grad_cam_outputs/{}'.format(os.path.basename(image_path))\n",
        "    cv2.imwrite(output_path, gradcam_img)  # Save the image\n"
      ],
      "metadata": {
        "id": "s8ZGt1C4yXiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = model.get_layer(\"MobileNetV3Large\")\n",
        "for layer in base_model.layers:\n",
        "    print(layer.name, layer.output.shape)\n"
      ],
      "metadata": {
        "id": "TyPXtqAz2dgO",
        "outputId": "c0c22970-a739-4111-c8b8-b35ea9c7b325",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer (None, 224, 224, 3)\n",
            "rescaling (None, 224, 224, 3)\n",
            "conv (None, 112, 112, 16)\n",
            "conv_bn (None, 112, 112, 16)\n",
            "activation (None, 112, 112, 16)\n",
            "expanded_conv_depthwise (None, 112, 112, 16)\n",
            "expanded_conv_depthwise_bn (None, 112, 112, 16)\n",
            "re_lu (None, 112, 112, 16)\n",
            "expanded_conv_project (None, 112, 112, 16)\n",
            "expanded_conv_project_bn (None, 112, 112, 16)\n",
            "expanded_conv_add (None, 112, 112, 16)\n",
            "expanded_conv_1_expand (None, 112, 112, 64)\n",
            "expanded_conv_1_expand_bn (None, 112, 112, 64)\n",
            "re_lu_1 (None, 112, 112, 64)\n",
            "expanded_conv_1_depthwise_pad (None, 113, 113, 64)\n",
            "expanded_conv_1_depthwise (None, 56, 56, 64)\n",
            "expanded_conv_1_depthwise_bn (None, 56, 56, 64)\n",
            "re_lu_2 (None, 56, 56, 64)\n",
            "expanded_conv_1_project (None, 56, 56, 24)\n",
            "expanded_conv_1_project_bn (None, 56, 56, 24)\n",
            "expanded_conv_2_expand (None, 56, 56, 72)\n",
            "expanded_conv_2_expand_bn (None, 56, 56, 72)\n",
            "re_lu_3 (None, 56, 56, 72)\n",
            "expanded_conv_2_depthwise (None, 56, 56, 72)\n",
            "expanded_conv_2_depthwise_bn (None, 56, 56, 72)\n",
            "re_lu_4 (None, 56, 56, 72)\n",
            "expanded_conv_2_project (None, 56, 56, 24)\n",
            "expanded_conv_2_project_bn (None, 56, 56, 24)\n",
            "expanded_conv_2_add (None, 56, 56, 24)\n",
            "expanded_conv_3_expand (None, 56, 56, 72)\n",
            "expanded_conv_3_expand_bn (None, 56, 56, 72)\n",
            "re_lu_5 (None, 56, 56, 72)\n",
            "expanded_conv_3_depthwise_pad (None, 59, 59, 72)\n",
            "expanded_conv_3_depthwise (None, 28, 28, 72)\n",
            "expanded_conv_3_depthwise_bn (None, 28, 28, 72)\n",
            "re_lu_6 (None, 28, 28, 72)\n",
            "expanded_conv_3_squeeze_excite_avg_pool (None, 1, 1, 72)\n",
            "expanded_conv_3_squeeze_excite_conv (None, 1, 1, 24)\n",
            "expanded_conv_3_squeeze_excite_relu (None, 1, 1, 24)\n",
            "expanded_conv_3_squeeze_excite_conv_1 (None, 1, 1, 72)\n",
            "re_lu_7 (None, 1, 1, 72)\n",
            "expanded_conv_3_squeeze_excite_mul (None, 28, 28, 72)\n",
            "expanded_conv_3_project (None, 28, 28, 40)\n",
            "expanded_conv_3_project_bn (None, 28, 28, 40)\n",
            "expanded_conv_4_expand (None, 28, 28, 120)\n",
            "expanded_conv_4_expand_bn (None, 28, 28, 120)\n",
            "re_lu_8 (None, 28, 28, 120)\n",
            "expanded_conv_4_depthwise (None, 28, 28, 120)\n",
            "expanded_conv_4_depthwise_bn (None, 28, 28, 120)\n",
            "re_lu_9 (None, 28, 28, 120)\n",
            "expanded_conv_4_squeeze_excite_avg_pool (None, 1, 1, 120)\n",
            "expanded_conv_4_squeeze_excite_conv (None, 1, 1, 32)\n",
            "expanded_conv_4_squeeze_excite_relu (None, 1, 1, 32)\n",
            "expanded_conv_4_squeeze_excite_conv_1 (None, 1, 1, 120)\n",
            "re_lu_10 (None, 1, 1, 120)\n",
            "expanded_conv_4_squeeze_excite_mul (None, 28, 28, 120)\n",
            "expanded_conv_4_project (None, 28, 28, 40)\n",
            "expanded_conv_4_project_bn (None, 28, 28, 40)\n",
            "expanded_conv_4_add (None, 28, 28, 40)\n",
            "expanded_conv_5_expand (None, 28, 28, 120)\n",
            "expanded_conv_5_expand_bn (None, 28, 28, 120)\n",
            "re_lu_11 (None, 28, 28, 120)\n",
            "expanded_conv_5_depthwise (None, 28, 28, 120)\n",
            "expanded_conv_5_depthwise_bn (None, 28, 28, 120)\n",
            "re_lu_12 (None, 28, 28, 120)\n",
            "expanded_conv_5_squeeze_excite_avg_pool (None, 1, 1, 120)\n",
            "expanded_conv_5_squeeze_excite_conv (None, 1, 1, 32)\n",
            "expanded_conv_5_squeeze_excite_relu (None, 1, 1, 32)\n",
            "expanded_conv_5_squeeze_excite_conv_1 (None, 1, 1, 120)\n",
            "re_lu_13 (None, 1, 1, 120)\n",
            "expanded_conv_5_squeeze_excite_mul (None, 28, 28, 120)\n",
            "expanded_conv_5_project (None, 28, 28, 40)\n",
            "expanded_conv_5_project_bn (None, 28, 28, 40)\n",
            "expanded_conv_5_add (None, 28, 28, 40)\n",
            "expanded_conv_6_expand (None, 28, 28, 240)\n",
            "expanded_conv_6_expand_bn (None, 28, 28, 240)\n",
            "activation_1 (None, 28, 28, 240)\n",
            "expanded_conv_6_depthwise_pad (None, 29, 29, 240)\n",
            "expanded_conv_6_depthwise (None, 14, 14, 240)\n",
            "expanded_conv_6_depthwise_bn (None, 14, 14, 240)\n",
            "activation_2 (None, 14, 14, 240)\n",
            "expanded_conv_6_project (None, 14, 14, 80)\n",
            "expanded_conv_6_project_bn (None, 14, 14, 80)\n",
            "expanded_conv_7_expand (None, 14, 14, 200)\n",
            "expanded_conv_7_expand_bn (None, 14, 14, 200)\n",
            "activation_3 (None, 14, 14, 200)\n",
            "expanded_conv_7_depthwise (None, 14, 14, 200)\n",
            "expanded_conv_7_depthwise_bn (None, 14, 14, 200)\n",
            "activation_4 (None, 14, 14, 200)\n",
            "expanded_conv_7_project (None, 14, 14, 80)\n",
            "expanded_conv_7_project_bn (None, 14, 14, 80)\n",
            "expanded_conv_7_add (None, 14, 14, 80)\n",
            "expanded_conv_8_expand (None, 14, 14, 184)\n",
            "expanded_conv_8_expand_bn (None, 14, 14, 184)\n",
            "activation_5 (None, 14, 14, 184)\n",
            "expanded_conv_8_depthwise (None, 14, 14, 184)\n",
            "expanded_conv_8_depthwise_bn (None, 14, 14, 184)\n",
            "activation_6 (None, 14, 14, 184)\n",
            "expanded_conv_8_project (None, 14, 14, 80)\n",
            "expanded_conv_8_project_bn (None, 14, 14, 80)\n",
            "expanded_conv_8_add (None, 14, 14, 80)\n",
            "expanded_conv_9_expand (None, 14, 14, 184)\n",
            "expanded_conv_9_expand_bn (None, 14, 14, 184)\n",
            "activation_7 (None, 14, 14, 184)\n",
            "expanded_conv_9_depthwise (None, 14, 14, 184)\n",
            "expanded_conv_9_depthwise_bn (None, 14, 14, 184)\n",
            "activation_8 (None, 14, 14, 184)\n",
            "expanded_conv_9_project (None, 14, 14, 80)\n",
            "expanded_conv_9_project_bn (None, 14, 14, 80)\n",
            "expanded_conv_9_add (None, 14, 14, 80)\n",
            "expanded_conv_10_expand (None, 14, 14, 480)\n",
            "expanded_conv_10_expand_bn (None, 14, 14, 480)\n",
            "activation_9 (None, 14, 14, 480)\n",
            "expanded_conv_10_depthwise (None, 14, 14, 480)\n",
            "expanded_conv_10_depthwise_bn (None, 14, 14, 480)\n",
            "activation_10 (None, 14, 14, 480)\n",
            "expanded_conv_10_squeeze_excite_avg_pool (None, 1, 1, 480)\n",
            "expanded_conv_10_squeeze_excite_conv (None, 1, 1, 120)\n",
            "expanded_conv_10_squeeze_excite_relu (None, 1, 1, 120)\n",
            "expanded_conv_10_squeeze_excite_conv_1 (None, 1, 1, 480)\n",
            "re_lu_14 (None, 1, 1, 480)\n",
            "expanded_conv_10_squeeze_excite_mul (None, 14, 14, 480)\n",
            "expanded_conv_10_project (None, 14, 14, 112)\n",
            "expanded_conv_10_project_bn (None, 14, 14, 112)\n",
            "expanded_conv_11_expand (None, 14, 14, 672)\n",
            "expanded_conv_11_expand_bn (None, 14, 14, 672)\n",
            "activation_11 (None, 14, 14, 672)\n",
            "expanded_conv_11_depthwise (None, 14, 14, 672)\n",
            "expanded_conv_11_depthwise_bn (None, 14, 14, 672)\n",
            "activation_12 (None, 14, 14, 672)\n",
            "expanded_conv_11_squeeze_excite_avg_pool (None, 1, 1, 672)\n",
            "expanded_conv_11_squeeze_excite_conv (None, 1, 1, 168)\n",
            "expanded_conv_11_squeeze_excite_relu (None, 1, 1, 168)\n",
            "expanded_conv_11_squeeze_excite_conv_1 (None, 1, 1, 672)\n",
            "re_lu_15 (None, 1, 1, 672)\n",
            "expanded_conv_11_squeeze_excite_mul (None, 14, 14, 672)\n",
            "expanded_conv_11_project (None, 14, 14, 112)\n",
            "expanded_conv_11_project_bn (None, 14, 14, 112)\n",
            "expanded_conv_11_add (None, 14, 14, 112)\n",
            "expanded_conv_12_expand (None, 14, 14, 672)\n",
            "expanded_conv_12_expand_bn (None, 14, 14, 672)\n",
            "activation_13 (None, 14, 14, 672)\n",
            "expanded_conv_12_depthwise_pad (None, 17, 17, 672)\n",
            "expanded_conv_12_depthwise (None, 7, 7, 672)\n",
            "expanded_conv_12_depthwise_bn (None, 7, 7, 672)\n",
            "activation_14 (None, 7, 7, 672)\n",
            "expanded_conv_12_squeeze_excite_avg_pool (None, 1, 1, 672)\n",
            "expanded_conv_12_squeeze_excite_conv (None, 1, 1, 168)\n",
            "expanded_conv_12_squeeze_excite_relu (None, 1, 1, 168)\n",
            "expanded_conv_12_squeeze_excite_conv_1 (None, 1, 1, 672)\n",
            "re_lu_16 (None, 1, 1, 672)\n",
            "expanded_conv_12_squeeze_excite_mul (None, 7, 7, 672)\n",
            "expanded_conv_12_project (None, 7, 7, 160)\n",
            "expanded_conv_12_project_bn (None, 7, 7, 160)\n",
            "expanded_conv_13_expand (None, 7, 7, 960)\n",
            "expanded_conv_13_expand_bn (None, 7, 7, 960)\n",
            "activation_15 (None, 7, 7, 960)\n",
            "expanded_conv_13_depthwise (None, 7, 7, 960)\n",
            "expanded_conv_13_depthwise_bn (None, 7, 7, 960)\n",
            "activation_16 (None, 7, 7, 960)\n",
            "expanded_conv_13_squeeze_excite_avg_pool (None, 1, 1, 960)\n",
            "expanded_conv_13_squeeze_excite_conv (None, 1, 1, 240)\n",
            "expanded_conv_13_squeeze_excite_relu (None, 1, 1, 240)\n",
            "expanded_conv_13_squeeze_excite_conv_1 (None, 1, 1, 960)\n",
            "re_lu_17 (None, 1, 1, 960)\n",
            "expanded_conv_13_squeeze_excite_mul (None, 7, 7, 960)\n",
            "expanded_conv_13_project (None, 7, 7, 160)\n",
            "expanded_conv_13_project_bn (None, 7, 7, 160)\n",
            "expanded_conv_13_add (None, 7, 7, 160)\n",
            "expanded_conv_14_expand (None, 7, 7, 960)\n",
            "expanded_conv_14_expand_bn (None, 7, 7, 960)\n",
            "activation_17 (None, 7, 7, 960)\n",
            "expanded_conv_14_depthwise (None, 7, 7, 960)\n",
            "expanded_conv_14_depthwise_bn (None, 7, 7, 960)\n",
            "activation_18 (None, 7, 7, 960)\n",
            "expanded_conv_14_squeeze_excite_avg_pool (None, 1, 1, 960)\n",
            "expanded_conv_14_squeeze_excite_conv (None, 1, 1, 240)\n",
            "expanded_conv_14_squeeze_excite_relu (None, 1, 1, 240)\n",
            "expanded_conv_14_squeeze_excite_conv_1 (None, 1, 1, 960)\n",
            "re_lu_18 (None, 1, 1, 960)\n",
            "expanded_conv_14_squeeze_excite_mul (None, 7, 7, 960)\n",
            "expanded_conv_14_project (None, 7, 7, 160)\n",
            "expanded_conv_14_project_bn (None, 7, 7, 160)\n",
            "expanded_conv_14_add (None, 7, 7, 160)\n",
            "conv_1 (None, 7, 7, 960)\n",
            "conv_1_bn (None, 7, 7, 960)\n",
            "activation_19 (None, 7, 7, 960)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_conv_layer = base_model.get_layer(\"conv_1_bn\").output\n"
      ],
      "metadata": {
        "id": "CCMteHCK3OOd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models\n",
        "\n",
        "def grad_cam(input_model, image, layer_name=\"conv_1_bn\"):\n",
        "\n",
        "    last_conv_layer = input_model.get_layer(layer_name).output\n",
        "    classifier_input = input_model.input\n",
        "    classifier_output = input_model.output\n",
        "    grad_model = models.Model([classifier_input], [last_conv_layer, classifier_output])\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        tape.watch(image)\n",
        "        conv_outputs, predictions = grad_model(image)\n",
        "        loss = predictions[:, np.argmax(predictions[0])]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    heatmap = conv_outputs[0] @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "def display_grad_cam(heatmap, image, alpha=0.4):\n",
        "\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = np.expand_dims(heatmap, axis=-1)\n",
        "    heatmap = np.repeat(heatmap, 3, axis=-1)\n",
        "\n",
        "\n",
        "    superimposed_img = image * (1 - alpha) + heatmap * alpha\n",
        "\n",
        "\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "R2XxzYRg3y8v"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working GradCAM on one image."
      ],
      "metadata": {
        "id": "gZBxGfGx5WtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import cv2  # OpenCV for resizing\n",
        "\n",
        "# Grad-CAM function with corrected layer name\n",
        "def grad_cam(input_model, image, layer_name=\"conv1_bn\"):\n",
        "    # convert the image to a tf.Tensor\n",
        "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "\n",
        "    last_conv_layer = input_model.get_layer(layer_name).output\n",
        "    classifier_input = input_model.input\n",
        "    classifier_output = input_model.output\n",
        "\n",
        "    grad_model = tf.keras.models.Model([classifier_input], [last_conv_layer, classifier_output])\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        conv_outputs, predictions = grad_model(image)\n",
        "        loss = predictions[:, np.argmax(predictions[0])]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    heatmap = conv_outputs[0] @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "# ffunction to display Grad-CAM\n",
        "def display_grad_cam(heatmap, image, alpha=0.4):\n",
        "    # i had to resize heatmap to match the input image size\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = np.expand_dims(heatmap, axis=-1)\n",
        "    heatmap = np.repeat(heatmap, 3, axis=-1)\n",
        "\n",
        "    # resize heatmap to the original image dimensions (224x224)\n",
        "    heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
        "\n",
        "    superimposed_img = image * (1 - alpha) + heatmap_resized * alpha\n",
        "\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# loading pre-trained model (ResNet50 example)\n",
        "base_model = tf.keras.applications.ResNet50(weights='imagenet')\n",
        "\n",
        "# load and preprocess the image\n",
        "img_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data/3045.png'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "# preprocessing image\n",
        "img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
        "\n",
        "# add batch dimension\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# generate and display Grad-CAM\n",
        "heatmap = grad_cam(base_model, img_array)\n",
        "display_grad_cam(heatmap, img_array[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "pe6nn7A_4EBS",
        "outputId": "b9b2746e-e7e1-4900-8b8a-f5de54419798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor_1093']\n",
            "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
            "  warnings.warn(msg)\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-74.20800018310547..165.43660736083984].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "last_conv_layer = base_model.get_layer(\"conv_1_bn\").output\n",
        "\n"
      ],
      "metadata": {
        "id": "6G_0X-3i3nQT"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[::-1]:  # Iterate in reverse\n",
        "    if 'conv' in layer.name.lower():\n",
        "        print(layer.name)\n",
        "        break  # Stop at the last convolutional layer\n"
      ],
      "metadata": {
        "id": "87HtnyR03AQs"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap = guided_gradcam(model, img_array)\n"
      ],
      "metadata": {
        "id": "GiMy2PJ_1p-s",
        "outputId": "b8707e8d-d59f-400a-f49d-dda7639f96b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "The layer sequential has never been called and thus has no defined input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-3046365baf45>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguided_gradcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-50aba7cb6a6c>\u001b[0m in \u001b[0;36mguided_gradcam\u001b[0;34m(model, img_array)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# 2. Model predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     grad_model = tf.keras.models.Model(\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: The layer sequential has never been called and thus has no defined input."
          ]
        }
      ]
    }
  ]
}