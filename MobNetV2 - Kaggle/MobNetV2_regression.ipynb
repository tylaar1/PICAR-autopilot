{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/regression_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fhwRSFoj6C_"
      },
      "source": [
        "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4V83PflfFkL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "kP6UczzNe1l2",
        "outputId": "f7665472-ba2f-47f2-cd53-ca3692f7d7a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-30 11:09:46.855786: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-04-30 11:09:48.560929: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-04-30 11:09:48.578258: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-30 11:09:57.062755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from keras.callbacks import ModelCheckpoint, LambdaCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linux\n"
          ]
        }
      ],
      "source": [
        "import platform\n",
        "print(platform.system())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J2vKakD1ffIi"
      },
      "outputs": [],
      "source": [
        "# makes it so pd dfs aren't truncated\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_MvRvYnfIM5"
      },
      "source": [
        "# 1) DATA PRE-PROCESSING\n",
        "\n",
        "a) Load in labels + image file paths\n",
        "\n",
        "b) combine them into one dataframe\n",
        "\n",
        "c) EDA - spotted and removed erroneous label (speed = 1.42...)\n",
        "\n",
        "- `cleaned_df` is the cleaned df with a) b) c) completed\n",
        "\n",
        "d) convert images to numerical RGB feature maps - ML algorithms only understand numerical data\n",
        "\n",
        "e) Splitting data into training and validation sets\n",
        "\n",
        "f) data augmentation applied to training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU3TvBZ5hfhX"
      },
      "source": [
        "### 1a) load in labels + image file paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "outputs": [],
      "source": [
        "# labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # tylers file path\n",
        "labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
        "\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "outputs": [],
      "source": [
        "image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data' # ben hpc file path (mlis2 cluster)\n",
        "# image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
        "\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oeuvmeZaGSC"
      },
      "source": [
        "Checking labels dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2pi13TZ2aFhO"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle  speed\n",
              "image_id               \n",
              "1         0.4375    0.0\n",
              "2         0.8125    1.0\n",
              "3         0.4375    1.0\n",
              "4         0.6250    1.0\n",
              "5         0.5000    0.0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puEjGoOJaRS4"
      },
      "source": [
        "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a1suFSK7aWKH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                       image_file_paths\n",
              "image_id                                                                                               \n",
              "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/1.png\n",
              "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/2.png\n",
              "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3.png\n",
              "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/4.png\n",
              "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/5.png"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imagefilepaths_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjDdyYd6cMBE"
      },
      "source": [
        "### 1b) Combine labels and image file paths into one dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6NdbonzPcLKB"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
        "merged_df['speed'] = merged_df['speed'].round(6) # to get rid of floating point errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-VstirIAdAZi"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "1         0.4375    0.0   \n",
              "2         0.8125    1.0   \n",
              "3         0.4375    1.0   \n",
              "4         0.6250    1.0   \n",
              "5         0.5000    0.0   \n",
              "\n",
              "                                                                                       image_file_paths  \n",
              "image_id                                                                                                 \n",
              "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/1.png  \n",
              "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/2.png  \n",
              "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3.png  \n",
              "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/4.png  \n",
              "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/5.png  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8MgNoL8nfBm2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3139</th>\n",
              "      <td>0.750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3139.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>0.875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3140.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3142</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3142.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3143</th>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3143.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          angle  speed  \\\n",
              "image_id                 \n",
              "3139      0.750    1.0   \n",
              "3140      0.875    1.0   \n",
              "3142      0.625    0.0   \n",
              "3143      0.625    1.0   \n",
              "\n",
              "                                                                                          image_file_paths  \n",
              "image_id                                                                                                    \n",
              "3139      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3139.png  \n",
              "3140      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3140.png  \n",
              "3142      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3142.png  \n",
              "3143      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3143.png  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.loc[3139:3143]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7PCxqJbmXE6"
      },
      "source": [
        "The above cell shows that:\n",
        "\n",
        " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
        "\n",
        " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3OKLcn9u0Pz"
      },
      "source": [
        "### 1c) EDA - angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IWQCQrR-oCps"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "angle\n",
              "0.0000      60\n",
              "0.0625      28\n",
              "0.1250      99\n",
              "0.1875      98\n",
              "0.2500     104\n",
              "0.3125     213\n",
              "0.3750     428\n",
              "0.4375    1467\n",
              "0.5000    2046\n",
              "0.5625    1609\n",
              "0.6250    1963\n",
              "0.6875    2007\n",
              "0.7500    2123\n",
              "0.8125    1147\n",
              "0.8750     301\n",
              "0.9375      65\n",
              "1.0000      35\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.value_counts('angle').sort_index() #seems to favour right turn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4pZ65pYvdqb"
      },
      "source": [
        "note: imbalance datset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJmG7jmNkE0k"
      },
      "source": [
        "identifying the row with the erroneous speed value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wAQnbLLeiqy2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3884</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3884.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle     speed  \\\n",
              "image_id                     \n",
              "3884      0.4375  1.428571   \n",
              "\n",
              "                                                                                          image_file_paths  \n",
              "image_id                                                                                                    \n",
              "3884      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3884.png  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df[merged_df['speed'] == 1.428571]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMZq41-RkLz0"
      },
      "source": [
        "we want to remove this row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TDMqIiOLSKGX"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3882</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3882.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3883</th>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3883.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3885</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3885.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3886</th>\n",
              "      <td>0.7500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3886.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "3882      0.5625    1.0   \n",
              "3883      0.3750    0.0   \n",
              "3885      0.0000    1.0   \n",
              "3886      0.7500    1.0   \n",
              "\n",
              "                                                                                          image_file_paths  \n",
              "image_id                                                                                                    \n",
              "3882      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3882.png  \n",
              "3883      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3883.png  \n",
              "3885      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3885.png  \n",
              "3886      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3886.png  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_df = merged_df[merged_df['speed'] != 1.428571]\n",
        "cleaned_df.loc[3882:3886]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di6F6km_DBmj"
      },
      "source": [
        "### 1d) convert images to numerical RGB feature maps - make sure angle column is specified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oeeBTruNCQ96"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def process_image(image_path, label, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, resized_shape)\n",
        "    image = image / 255.0  # Normalise pixel values to [0,1]\n",
        "    return image, label\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"angle\"])) # Convert pd df into a tf ds\n",
        "\n",
        "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(len(cleaned_df))\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uSiqNM-f-NF"
      },
      "source": [
        "lets check and see if what we have done works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I2En76kf9Z5"
      },
      "outputs": [],
      "source": [
        "for images, labels in dataset.take(1):\n",
        "    print(images.shape, labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIqeJwilgRLT"
      },
      "source": [
        "### 1e) Splitting data into training and validation sets (test set is already provided in kaggle data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYlssPh5dxaO"
      },
      "outputs": [],
      "source": [
        "# 80-20 split\n",
        "\n",
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhRu7E4Dgiir"
      },
      "outputs": [],
      "source": [
        "print(f\"Train size: {train_size}, val size: {dataset_size - train_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "903n7Iu8gq5-"
      },
      "source": [
        "### 1f) Data augmentation applied to training set\n",
        "\n",
        "Flipping or rotating the image will render the angle labels incorrect so none of that was applied to the images for this regression task\n",
        "\n",
        "- Random Brightness Adjustment\n",
        "- Random Contrast Adjustment\n",
        "- Random Hue Adjustment\n",
        "- Random Saturation Adjustment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H366zr9DoOVI"
      },
      "outputs": [],
      "source": [
        "def augment_image(image, label):\n",
        "  seed = (6, 9)\n",
        "  image = tf.image.stateless_random_brightness(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_contrast(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_saturation(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_flip_left_right(image, seed)\n",
        "  image = tf.image.stateless_random_flip_up_down(image, seed)\n",
        "  return image, label\n",
        "\n",
        "# Create a dataset of augmented images from the original train_dataset\n",
        "augmented_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Concatenate the original and augmented datasets\n",
        "train_dataset = train_dataset.concatenate(augmented_dataset)\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(cleaned_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXs_qBHhhU5g"
      },
      "source": [
        "checking to see if whats been done was successful or needs debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p22_ybaIhUJ2"
      },
      "outputs": [],
      "source": [
        "f, axarr = plt.subplots(1,10)\n",
        "\n",
        "i = 0\n",
        "for image_batch, label_batch in dataset.take(1):  # Take one batch\n",
        "    for image in image_batch:  # Iterate through images in the batch\n",
        "        if i < 10:  # Only display the first 5 images\n",
        "            print('image shape: ', np.shape(image))\n",
        "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
        "            axarr[i].imshow(image)\n",
        "            axarr[i].axis('off')\n",
        "            i += 1\n",
        "        else:\n",
        "            break  # Stop after displaying 5 images\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WzPQ3vThZPV"
      },
      "source": [
        "# 2) Model Building - MobileNetV2 transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrISu-KhhdS-"
      },
      "source": [
        "### 2a) Set up model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "dropoutrate = 0.2\n",
        "input_shape = (224,224,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1280)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               327936    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2629185 (10.03 MB)\n",
            "Trainable params: 371201 (1.42 MB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "mobnetv2 = tf.keras.applications.MobileNetV2(\n",
        "    weights = 'imagenet',\n",
        "    include_top = False,\n",
        "    input_shape = input_shape\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mobnetv2,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "mobnetv2.trainable = False  # freeze mobnetv3small layers\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.MeanSquaredError(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2b) Train regression model with MobNetV2 layers frozen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define ModelCheckpoint callback\n",
        "checkpoint_filepath = '/home/apyba3/PICAR-autopilot/MobNetV2 - Kaggle/mobnetv2regressioncheckpoint.h5'\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,  # Save only weights instead of full model\n",
        "    save_best_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Define a callback to print epoch tracking info\n",
        "epoch_callback = LambdaCallback(\n",
        "    on_epoch_begin=lambda epoch, logs: print(f\"\\nStarting Epoch {epoch + 1}...\"),\n",
        "    on_epoch_end=lambda epoch, logs: print(f\"Completed Epoch {epoch + 1}, Loss: {logs['loss']:.4f}, Val Loss: {logs['val_loss']:.4f}\")\n",
        ")\n",
        "\n",
        "# Training loop with added callback\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=45,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[model_checkpoint, epoch_callback]  # Include both callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save_weights('/home/apyba3/PICAR-autopilot/MobNetV2 - Kaggle/frozentraining_mobnetv2_regression_weights.weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "clear keras session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session() #Clear keras session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2c) fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "rebuild model after clearing keras session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## UNFREEZE MOBNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mobnetv2 = tf.keras.applications.MobileNetV2(\n",
        "    weights = 'imagenet',\n",
        "    include_top = False,\n",
        "    input_shape = input_shape\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mobnetv2,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "mobnetv2.trainable = False  # freeze mobnetv3small layers\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "complile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # deliberatley smaller learning rate\n",
        "    loss=tf.keras.losses.MeanSquaredError(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now load the learned weights from frozen training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_weights('/home/apyba3/PICAR-autopilot/MobNetV2 - Kaggle/frozentraining_mobnetv2_regression_weights.weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "initiate fine-tuning training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define ModelCheckpoint callback\n",
        "checkpoint_filepath = '/home/apyba3/PICAR-autopilot/MobNetV2 - Kaggle/mobnetv2regressioncheckpoint.h5'\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,  # Save only weights instead of full model\n",
        "    save_best_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Define a callback to print epoch tracking info\n",
        "epoch_callback = LambdaCallback(\n",
        "    on_epoch_begin=lambda epoch, logs: print(f\"\\nStarting Epoch {epoch + 1}...\"),\n",
        "    on_epoch_end=lambda epoch, logs: print(f\"Completed Epoch {epoch + 1}, Loss: {logs['loss']:.4f}, Val Loss: {logs['val_loss']:.4f}\")\n",
        ")\n",
        "\n",
        "# Training loop with added callback\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=45,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[model_checkpoint, epoch_callback]  # Include both callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "save weights from fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3) CLASSIFICATION SPEED Test-Set Predictions\n",
        "\n",
        "a) load in test data\n",
        "\n",
        "b) convert test images to numerical RGB feature maps\n",
        "\n",
        "c) generate predictions on the test set\n",
        "\n",
        "d) correctly format the predictions into a pandas dataframe\n",
        "\n",
        "e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3a) load in test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data'\n",
        "# image_folder_path = '/home/ppyt13/machine-learning-in-science-ii-2025/test_data/test_data' # tylers file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'\n",
        "imagefilepaths_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3b) convert test images to numerical RGB feature maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_image_no_label(image_path, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
        "    image = tf.image.resize(image, resized_shape)  # Resize to uniform shape\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((imagefilepaths_df[\"image_file_paths\"]))\n",
        "\n",
        "test_dataset = test_dataset.map(process_image_no_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3c) generate predictions on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3d) correctly format the predictions into a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_df = pd.DataFrame(predictions, columns=['angle'])\n",
        "predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_df['angle'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3e) save predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_df.to_csv('/home/apyba3/PICAR-autopilot/MobNetV2 - Kaggle/mobnetv2_angleregression_withvalidation.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "car_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
