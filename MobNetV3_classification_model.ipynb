{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/MobNetV3_classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
      ],
      "metadata": {
        "id": "-fhwRSFoj6C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "g4V83PflfFkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kP6UczzNe1l2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104b0946-b9f7-4da7-9d0b-88d2ad6bc5c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-12 14:03:33.370772: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-12 14:03:35.394837: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-12 14:03:35.397115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-03-12 14:03:41.309798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "print(platform.system())"
      ],
      "metadata": {
        "id": "O24_U-m8q-xv",
        "outputId": "105f000f-694e-4102-8608-cd6b7f30a02a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# makes it so pd dfs aren't truncated\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "IF_vPVifaU9V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eocC68amnhEI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) DATA PRE-PROCESSING\n",
        "\n",
        "a) Load in labels + image file paths\n",
        "\n",
        "b) combine them into one dataframe\n",
        "\n",
        "c) EDA - spotted and removed erroneous label (speed = 1.42...)\n",
        "\n",
        "- `cleaned_df` is the cleaned df with a) b) c) completed\n",
        "\n",
        "d) convert images to numerical RGB feature maps - ML algorithms only understand numerical data\n",
        "\n",
        "e) Splitting data into training and validation sets\n",
        "\n",
        "f) data augmentation applied to training set"
      ],
      "metadata": {
        "id": "-_MvRvYnfIM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a) load in labels + image file paths"
      ],
      "metadata": {
        "id": "HU3TvBZ5hfhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # tylers file path\n",
        "#labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
        "labels_file_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_norm.csv' # tyler hpc file path (mlis2 cluster)\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ],
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data'\n",
        "image_folder_path = '/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data'\n",
        "# image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ],
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking labels dataframe"
      ],
      "metadata": {
        "id": "0oeuvmeZaGSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "2pi13TZ2aFhO",
        "outputId": "1946c859-4913-4a5e-817e-1b1a80723f6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed\n",
              "image_id               \n",
              "1         0.4375    0.0\n",
              "2         0.8125    1.0\n",
              "3         0.4375    1.0\n",
              "4         0.6250    1.0\n",
              "5         0.5000    0.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
      ],
      "metadata": {
        "id": "puEjGoOJaRS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "a1suFSK7aWKH",
        "outputId": "9598ab16-4766-4595-c349-906cbb816906"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                              image_file_paths\n",
              "image_id                                                                                      \n",
              "1         /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/1.png\n",
              "2         /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/2.png\n",
              "3         /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3.png\n",
              "4         /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/4.png\n",
              "5         /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/5.png"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b) Combine labels and image file paths into one dataframe"
      ],
      "metadata": {
        "id": "CjDdyYd6cMBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
        "merged_df['speed'] = merged_df['speed'].round(6) # to get rid of floating point errors"
      ],
      "metadata": {
        "id": "6NdbonzPcLKB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-VstirIAdAZi",
        "outputId": "93dc844a-8e56-46d0-cc9d-b00999acac53"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "1         0.4375    0.0   \n",
              "2         0.8125    1.0   \n",
              "3         0.4375    1.0   \n",
              "4         0.6250    1.0   \n",
              "5         0.5000    0.0   \n",
              "\n",
              "                                                                              image_file_paths  \n",
              "image_id                                                                                        \n",
              "1         /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/1.png  \n",
              "2         /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/2.png  \n",
              "3         /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3.png  \n",
              "4         /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/4.png  \n",
              "5         /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/5.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.loc[3139:3143]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8MgNoL8nfBm2",
        "outputId": "8611d265-332d-4730-d211-72d50c089164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          angle  speed  \\\n",
              "image_id                 \n",
              "3139      0.750    1.0   \n",
              "3140      0.875    1.0   \n",
              "3142      0.625    0.0   \n",
              "3143      0.625    1.0   \n",
              "\n",
              "                                                                                          image_file_paths  \n",
              "image_id                                                                                                    \n",
              "3139      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3139.png  \n",
              "3140      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3140.png  \n",
              "3142      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3142.png  \n",
              "3143      /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3143.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3139</th>\n",
              "      <td>0.750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3139.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>0.875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3140.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3142</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3142.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3143</th>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data/3143.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above cell shows that:\n",
        "\n",
        " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
        "\n",
        " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
      ],
      "metadata": {
        "id": "U7PCxqJbmXE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c) EDA"
      ],
      "metadata": {
        "id": "h3OKLcn9u0Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.value_counts('speed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWQCQrR-oCps",
        "outputId": "00260b75-8c04-4550-cb4e-e36abe94fdd8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "speed\n",
              "1.000000    10402\n",
              "0.000000     3390\n",
              "1.428571        1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note: imbalance datset"
      ],
      "metadata": {
        "id": "K4pZ65pYvdqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "identifying the row with the erroneous speed value"
      ],
      "metadata": {
        "id": "xJmG7jmNkE0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df[merged_df['speed'] == 1.428571]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "wAQnbLLeiqy2",
        "outputId": "e1dce30a-a100-403b-9ab9-e7d7f73b11a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle     speed  \\\n",
              "image_id                     \n",
              "3884      0.4375  1.428571   \n",
              "\n",
              "                                                                                 image_file_paths  \n",
              "image_id                                                                                           \n",
              "3884      /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3884.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3884</th>\n",
              "      <td>0.4375</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3884.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to remove this row"
      ],
      "metadata": {
        "id": "zMZq41-RkLz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = merged_df[merged_df['speed'] != 1.428571]\n",
        "cleaned_df.loc[3882:3886]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TDMqIiOLSKGX",
        "outputId": "a76cd5a0-5eb4-465d-d569-f106418dbbcf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           angle  speed  \\\n",
              "image_id                  \n",
              "3882      0.5625    1.0   \n",
              "3883      0.3750    0.0   \n",
              "3885      0.0000    1.0   \n",
              "3886      0.7500    1.0   \n",
              "\n",
              "                                                                                 image_file_paths  \n",
              "image_id                                                                                           \n",
              "3882      /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3882.png  \n",
              "3883      /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3883.png  \n",
              "3885      /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3885.png  \n",
              "3886      /home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3886.png  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3882</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3882.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3883</th>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3883.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3885</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3885.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3886</th>\n",
              "      <td>0.7500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data/3886.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1d) convert images to numerical RGB feature maps"
      ],
      "metadata": {
        "id": "Di6F6km_DBmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path, label, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, resized_shape)\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image, label\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"speed\"])) # Convert pd df into a tf ds\n",
        "\n",
        "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(len(cleaned_df))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oeeBTruNCQ96",
        "outputId": "2efad85f-819a-432c-8c8d-c33c8b14d5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-12 14:08:48.209866: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets check and see if what we have done works"
      ],
      "metadata": {
        "id": "pUOlsWQeVlyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in dataset.take(1):\n",
        "    print(images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "jBTNjNhMVk2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b054fb8-734f-49f2-f97f-21256e88dc83"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-12 14:09:01.002340: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 2772 of 13792\n",
            "2025-03-12 14:09:11.002979: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 5931 of 13792\n",
            "2025-03-12 14:09:21.003266: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 9267 of 13792\n",
            "2025-03-12 14:09:31.019733: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 12150 of 13792\n",
            "2025-03-12 14:09:37.581269: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3) (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1e) Splitting data into training and validation sets (test set is already provided in kaggle data)"
      ],
      "metadata": {
        "id": "Md6U_i84SiK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80-20 split\n",
        "\n",
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "validation_dataset = dataset.skip(train_size)"
      ],
      "metadata": {
        "id": "yYlssPh5dxaO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train size: {train_size}, Test size: {dataset_size - train_size}\")"
      ],
      "metadata": {
        "id": "qPUE6rd8cgQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3354b3a4-6d98-4182-8e74-966e41a9332b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 344, Test size: 87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1f) Data Augmentation applied to training set\n",
        "\n",
        "- Random Horizontal Flip\n",
        "- Random Brightness Adjustment\n",
        "- Random Contrast Adjustment\n",
        "- Random Hue Adjustment\n",
        "- Random Saturation Adjustment\n",
        "- Random Vertical Flip\n",
        "\n"
      ],
      "metadata": {
        "id": "0ujsjhMPSw4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_image(image, label):\n",
        "  seed = (6, 9)\n",
        "  image = tf.image.stateless_random_brightness(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_contrast(image, 0.8, 1.2, seed)\n",
        "  image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
        "  image = tf.image.stateless_random_saturation(image, 0.8, 1.2, seed)\n",
        "  return image, label\n",
        "\n",
        "# Create a dataset of augmented images from the original train_dataset\n",
        "augmented_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Concatenate the original and augmented datasets\n",
        "train_dataset = train_dataset.concatenate(augmented_dataset)\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(cleaned_df))"
      ],
      "metadata": {
        "id": "T9r811eWsYfe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking to see if whats been done was successful or needs debugging"
      ],
      "metadata": {
        "id": "HEdi-dUCTND1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, axarr = plt.subplots(1,10)\n",
        "\n",
        "i = 0\n",
        "for image_batch, label_batch in dataset.take(1):  # Take one batch\n",
        "    for image in image_batch:  # Iterate through images in the batch\n",
        "        if i < 10:  # Only display the first 5 images\n",
        "            print('image shape: ', np.shape(image))\n",
        "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
        "            axarr[i].imshow(image)\n",
        "            axarr[i].axis('off')\n",
        "            i += 1\n",
        "        else:\n",
        "            break  # Stop after displaying 5 images\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "OeboVhsQKGFS",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "92a9f7b7-55ad-4f65-f93b-62bb5353dfe5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape:  (224, 224, 3)\n",
            "label: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Model Building - MobileNetV3Large Transfer Learning\n",
        "\n",
        "a) Set up model architecture\n",
        "\n",
        "b) define training step\n",
        "\n",
        "c) training the model on the training set\n",
        "\n",
        "d) fine-tuning"
      ],
      "metadata": {
        "id": "cmetmzNHTWzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a) Set up model architecture\n",
        "\n",
        "- MobileNetV2 to learn lower level features\n",
        "- global average pooling layer\n",
        "- drop out layer\n",
        "- dense layer with sigmoid activation"
      ],
      "metadata": {
        "id": "48RHLVshdX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
        "])\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = False # freeze the first layers to the imagenet weights\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "Eh1-U-VYeN9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe238044-0dd3-40c5-eec7-55dcf840b2ec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 960)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 960)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 961       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2997313 (11.43 MB)\n",
            "Trainable params: 961 (3.75 KB)\n",
            "Non-trainable params: 2996352 (11.43 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) Define training step\n",
        "\n",
        "- adam optimiser\n",
        "- binary cross entropy loss function"
      ],
      "metadata": {
        "id": "3iuqe2Xwpu7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "LR = 0.001  # learning rate\n",
        "optimizer = tf.optimizers.Adam(LR)  # Adam optimizer\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, X, Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model(X)  # Get the predictions from the model\n",
        "\n",
        "        # Use binary cross-entropy for binary classification\n",
        "        current_loss = tf.reduce_mean(tf.losses.binary_crossentropy(Y, pred))\n",
        "\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Threshold predictions to binary values (0 or 1) for accuracy calculation\n",
        "    pred_binary = tf.cast(pred > 0.5, dtype=tf.int32)  # Convert predictions to binary (0 or 1)\n",
        "\n",
        "    # Calculate True Positives, False Positives, True Negatives, False Negatives\n",
        "    TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 1), dtype=tf.int32))\n",
        "    TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 0), dtype=tf.int32))\n",
        "    FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 0), dtype=tf.int32))\n",
        "    FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 1), dtype=tf.int32))\n",
        "\n",
        "    # Calculate Balanced Accuracy\n",
        "    sensitivity = TP / (TP + FN)  # Recall for class 1\n",
        "    specificity = TN / (TN + FP)  # Recall for class 0\n",
        "    balanced_accuracy = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "    return current_loss, balanced_accuracy\n"
      ],
      "metadata": {
        "id": "9AErZvcTeX-d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2c) Training the model on the training set"
      ],
      "metadata": {
        "id": "bUMefNeTpDWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 50\n",
        "\n",
        "tloss = []\n",
        "tacc = []\n",
        "vloss = []\n",
        "vacc = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_accs = []\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "        # Convert labels to correct format for binary classification\n",
        "        # Convert to [batch_size, 1] for binary classification with sigmoid\n",
        "        labels = tf.expand_dims(tf.cast(label_batch, dtype=tf.float32), axis=1)\n",
        "        loss, acc = train_step(model, image_batch, labels)\n",
        "        batch_losses.append(loss)\n",
        "        batch_accs.append(acc)\n",
        "\n",
        "    # Average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses).numpy()\n",
        "    avg_acc = tf.reduce_mean(batch_accs).numpy()\n",
        "    tloss.append(avg_loss)\n",
        "    tacc.append(avg_acc)\n",
        "\n",
        "    # LOGGING METRICS TO CHECK HOW TRAIING IS GOING\n",
        "\n",
        "    if it % 10 == 0:\n",
        "        tf.print(f'iter: {it}, train_loss: {avg_loss:.3f}, train_balanced_acc: {avg_acc:.3f}')\n",
        "\n",
        "        # If you have a validation dataset, evaluate on it\n",
        "        if 'val_dataset' in globals():\n",
        "            val_losses = []\n",
        "            val_accs = []\n",
        "            for val_images, val_labels in val_dataset:\n",
        "                val_labels = tf.expand_dims(tf.cast(val_labels, dtype=tf.float32), axis=1)\n",
        "                val_preds = model(val_images)\n",
        "                val_loss = tf.reduce_mean(tf.losses.binary_crossentropy(val_labels, val_preds))\n",
        "\n",
        "                # Use the same balanced accuracy calculation as in train_step\n",
        "                pred_binary = tf.cast(val_preds > 0.5, dtype=tf.int32)\n",
        "                val_labels_int = tf.cast(val_labels, dtype=tf.int32)\n",
        "\n",
        "                TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 1), dtype=tf.int32))\n",
        "                TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 1), dtype=tf.int32))\n",
        "\n",
        "                sensitivity = TP / (TP + FN + 1e-7)\n",
        "                specificity = TN / (TN + FP + 1e-7)\n",
        "                val_acc = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "\n",
        "            avg_val_loss = tf.reduce_mean(val_losses).numpy()\n",
        "            avg_val_acc = tf.reduce_mean(val_accs).numpy()\n",
        "            vloss.append(avg_val_loss)\n",
        "            vacc.append(avg_val_acc)\n",
        "\n",
        "            tf.print(f'val_loss: {avg_val_loss:.3f}, val_balanced_acc: {avg_val_acc:.3f}')"
      ],
      "metadata": {
        "id": "uE2K4gVQedXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "04a7ee74-9cd0-4a93-8fb3-2fd39d901933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0, train_loss: 0.472, train_balanced_acc: 0.545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_weights('/home/apyba3/car_frozen.weights.h5')\n",
        "model.save_weights('/home/ppytr13/car_frozen.weights.h5')"
      ],
      "metadata": {
        "id": "FiHy6opSP2sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session() #Clear keras session"
      ],
      "metadata": {
        "id": "FpLHyw20P93U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2d) fine-tuning"
      ],
      "metadata": {
        "id": "ENHbUvQdvyFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rebuild model after clearing keras session"
      ],
      "metadata": {
        "id": "h0ek_ytyw0KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
        "])\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = True # UNFREEZE the first layers to the imagenet weights\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "ZuKL3X-QP-Ax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "18069c08-6ce0-4a1f-f74a-aadc32a90df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m)      │     \u001b[38;5;34m2,996,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m961\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ MobileNetV3Large (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">961</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,997,313\u001b[0m (11.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,997,313</span> (11.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m961\u001b[0m (3.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">961</span> (3.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,996,352\u001b[0m (11.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span> (11.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.load_weights('/home/apyba3/car_frozen.weights.h5')\n",
        "model.load_weights('/home/ppytr13/car_frozen.weights.h5')"
      ],
      "metadata": {
        "id": "8oAenzEiP-C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up fine-tuning training"
      ],
      "metadata": {
        "id": "XWDtRxBow89t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.0001\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser"
      ],
      "metadata": {
        "id": "JQvDo1RVP-Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 50\n",
        "\n",
        "tloss = []\n",
        "tacc = []\n",
        "vloss = []\n",
        "vacc = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_accs = []\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "        # Convert labels to correct format for binary classification\n",
        "        # Convert to [batch_size, 1] for binary classification with sigmoid\n",
        "        labels = tf.expand_dims(tf.cast(label_batch, dtype=tf.float32), axis=1)\n",
        "        loss, acc = train_step(model, image_batch, labels)\n",
        "        batch_losses.append(loss)\n",
        "        batch_accs.append(acc)\n",
        "\n",
        "    # Average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses).numpy()\n",
        "    avg_acc = tf.reduce_mean(batch_accs).numpy()\n",
        "    tloss.append(avg_loss)\n",
        "    tacc.append(avg_acc)\n",
        "\n",
        "    # LOGGING METRICS TO CHECK HOW TRAIING IS GOING\n",
        "\n",
        "    if it % 10 == 0:\n",
        "        tf.print(f'iter: {it}, train_loss: {avg_loss:.3f}, train_balanced_acc: {avg_acc:.3f}')\n",
        "\n",
        "        # If you have a validation dataset, evaluate on it\n",
        "        if 'val_dataset' in globals():\n",
        "            val_losses = []\n",
        "            val_accs = []\n",
        "            for val_images, val_labels in val_dataset:\n",
        "                val_labels = tf.expand_dims(tf.cast(val_labels, dtype=tf.float32), axis=1)\n",
        "                val_preds = model(val_images)\n",
        "                val_loss = tf.reduce_mean(tf.losses.binary_crossentropy(val_labels, val_preds))\n",
        "\n",
        "                # Use the same balanced accuracy calculation as in train_step\n",
        "                pred_binary = tf.cast(val_preds > 0.5, dtype=tf.int32)\n",
        "                val_labels_int = tf.cast(val_labels, dtype=tf.int32)\n",
        "\n",
        "                TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 1), dtype=tf.int32))\n",
        "                TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 1), dtype=tf.int32))\n",
        "\n",
        "                sensitivity = TP / (TP + FN + 1e-7)\n",
        "                specificity = TN / (TN + FP + 1e-7)\n",
        "                val_acc = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "\n",
        "            avg_val_loss = tf.reduce_mean(val_losses).numpy()\n",
        "            avg_val_acc = tf.reduce_mean(val_accs).numpy()\n",
        "            vloss.append(avg_val_loss)\n",
        "            vacc.append(avg_val_acc)\n",
        "\n",
        "            tf.print(f'val_loss: {avg_val_loss:.3f}, val_balanced_acc: {avg_val_acc:.3f}')"
      ],
      "metadata": {
        "id": "ZvmWxC1fP-Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "923bb144-c25e-4a53-b71d-8aafcf25ada2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0, train_loss: 0.139, train_balanced_acc: nan\n",
            "iter: 10, train_loss: 0.136, train_balanced_acc: 0.919\n",
            "iter: 20, train_loss: 0.136, train_balanced_acc: 0.914\n",
            "iter: 30, train_loss: 0.130, train_balanced_acc: 0.921\n",
            "iter: 40, train_loss: 0.134, train_balanced_acc: 0.919\n",
            "iter: 50, train_loss: 0.134, train_balanced_acc: 0.922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-10 17:25:14.904913: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 60, train_loss: 0.130, train_balanced_acc: nan\n",
            "iter: 70, train_loss: 0.133, train_balanced_acc: 0.920\n",
            "iter: 80, train_loss: 0.129, train_balanced_acc: 0.923\n",
            "iter: 90, train_loss: 0.130, train_balanced_acc: 0.922\n",
            "iter: 100, train_loss: 0.132, train_balanced_acc: 0.923\n",
            "iter: 110, train_loss: 0.126, train_balanced_acc: 0.923\n",
            "iter: 120, train_loss: 0.129, train_balanced_acc: 0.922\n",
            "iter: 130, train_loss: 0.128, train_balanced_acc: 0.923\n",
            "iter: 140, train_loss: 0.127, train_balanced_acc: 0.922\n",
            "iter: 150, train_loss: 0.128, train_balanced_acc: 0.926\n",
            "iter: 160, train_loss: 0.125, train_balanced_acc: 0.926\n",
            "iter: 170, train_loss: 0.127, train_balanced_acc: 0.925\n",
            "iter: 180, train_loss: 0.125, train_balanced_acc: 0.925\n",
            "iter: 190, train_loss: 0.128, train_balanced_acc: 0.926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_weights('/home/apyba3/car_unfrozen.weights.h5')\n",
        "model.save_weights('/home/ppytr13/car_unfrozen.weights.h5')"
      ],
      "metadata": {
        "id": "O14u6175RLjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Test-Set Predictions\n",
        "\n",
        "a) load in test data\n",
        "\n",
        "b) convert test images to numerical RGB feature maps\n",
        "\n",
        "c) generate predictions on the test set\n",
        "\n",
        "d) correctly format the predictions into a pandas dataframe\n",
        "\n",
        "e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ],
      "metadata": {
        "id": "GCbo4VcLxLgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3a) load in test data"
      ],
      "metadata": {
        "id": "HnygDJsKxYhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/test_data/test_data'\n",
        "image_folder_path = '/home/ppyt13/machine-learning-in-science-ii-2025/test_data/test_data' # tylers file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'\n",
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "id": "W-e59lQQRXKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "b5f5d94a-affb-4d10-9a83-e68a9628362c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                               image_file_paths\n",
              "image_id                                                                                       \n",
              "1         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//test_data/test_data/1.png\n",
              "2         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//test_data/test_data/2.png\n",
              "3         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//test_data/test_data/3.png\n",
              "4         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//test_data/test_data/4.png\n",
              "5         /home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//test_data/test_data/5.png"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//test_data/test_data/1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//test_data/test_data/2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//test_data/test_data/3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//test_data/test_data/4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//test_data/test_data/5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3b) convert test images to numerical RGB feature maps"
      ],
      "metadata": {
        "id": "t-9i5trTyDTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image_no_label(image_path, resized_shape=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
        "    image = tf.image.resize(image, resized_shape)  # Resize to uniform shape\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((imagefilepaths_df[\"image_file_paths\"]))\n",
        "\n",
        "test_dataset = test_dataset.map(process_image_no_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "3hT_c1s5TAR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3c) generate predictions on test set"
      ],
      "metadata": {
        "id": "gobnK7PhyLa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "NtqcOFr7TAXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7857d7d0-c4db-4c1e-c14e-c25c339ffa11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3d) correctly format the predictions into a pandas dataframe"
      ],
      "metadata": {
        "id": "zT1LJxHTPeQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = pd.DataFrame(predictions, columns=['speed'])"
      ],
      "metadata": {
        "id": "pFVWGi04fza7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "OnO0K1rReHOT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4a41ee10-f09b-4572-9ea1-7919939c6838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      speed\n",
              "0  0.040182\n",
              "1  0.996354\n",
              "2  0.745791\n",
              "3  0.943694\n",
              "4  0.799895"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.040182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.996354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.745791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.943694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.799895</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sigmoid output is between [0,1]"
      ],
      "metadata": {
        "id": "sftRAg6PPnsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df[predictions_df['speed'] > 0.5] = 1\n",
        "predictions_df[predictions_df['speed'] < 0.5] = 0"
      ],
      "metadata": {
        "id": "AQ7of6YqeNJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaggle expects integers for the speed column"
      ],
      "metadata": {
        "id": "qWghSOvSPs2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df['speed'] = predictions_df['speed'].astype(int)"
      ],
      "metadata": {
        "id": "sSUAR4u0TAdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jRGM4-OiPKAQ",
        "outputId": "71f1de5b-e8c7-49a4-8d14-573deff5f031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   speed\n",
              "0      0\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df['speed'].value_counts()"
      ],
      "metadata": {
        "id": "4CcRKL9KTAfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8db31b-04d3-4368-e0b6-5a9dbf679f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "speed\n",
              "1    708\n",
              "0    312\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3e) save predictions to a file inside the hpc (to then later send from hpc to my laptop)"
      ],
      "metadata": {
        "id": "oU-PhskZPaHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.to_csv('/home/apyba3/mbnetv3_speedclassification_predictions.csv')"
      ],
      "metadata": {
        "id": "deXjPTO0TAiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsp7UPIJQlKB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}