{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/regression_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# remember to switch to t4 gpu"
      ],
      "metadata": {
        "id": "-fhwRSFoj6C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "g4V83PflfFkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP6UczzNe1l2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) DATA PRE-PROCESSING\n",
        "\n",
        "a) Load in labels + image file paths\n",
        "\n",
        "b) combine them into one dataframe\n",
        "\n",
        "c) EDA - spotted and removed erroneous label (speed = 1.42...)\n",
        "\n",
        "## `cleaned_df` is the final df with all of this completed"
      ],
      "metadata": {
        "id": "-_MvRvYnfIM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eocC68amnhEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "imfZR11CjvO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a) load in labels + image file paths"
      ],
      "metadata": {
        "id": "HU3TvBZ5hfhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv'\n",
        "#labels_file_path = '/content/drive/MyDrive/0. MSc MLiS/google SPRING SEMESTER/1. PHYS4036 MLiS2/MLiS2 Project/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv'\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ],
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image_folder_path = '/content/drive/MyDrive/0. MSc MLiS/google SPRING SEMESTER/1. PHYS4036 MLiS2/MLiS2 Project/KAGGLEDATAmachine-learning-in-science-ii-2025/training_data/training_data'\n",
        "image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data'\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ],
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking labels dataframe"
      ],
      "metadata": {
        "id": "0oeuvmeZaGSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.head()"
      ],
      "metadata": {
        "id": "2pi13TZ2aFhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking image file paths dataframe - as you can see the file paths are ordered correctly (1.png, 2.png, 3.png, ...)"
      ],
      "metadata": {
        "id": "puEjGoOJaRS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "id": "a1suFSK7aWKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b) Combine labels and image file paths into one dataframe"
      ],
      "metadata": {
        "id": "CjDdyYd6cMBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(labels_df, imagefilepaths_df, on='image_id', how='inner')\n",
        "merged_df['speed'] = merged_df['speed'].round(6) # to get rid of floating point errors"
      ],
      "metadata": {
        "id": "6NdbonzPcLKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head()"
      ],
      "metadata": {
        "id": "-VstirIAdAZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.loc[3139:3143]"
      ],
      "metadata": {
        "id": "8MgNoL8nfBm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above cell shows that:\n",
        "\n",
        " 1) the image files and labels match (see image_id and the number at the end of the file path)\n",
        "\n",
        " 2) the missing rows in labels_df (image_id: 3141, 3999, 4895, 8285, 10171) have been taken care of"
      ],
      "metadata": {
        "id": "U7PCxqJbmXE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c) EDA"
      ],
      "metadata": {
        "id": "h3OKLcn9u0Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.value_counts('angle') #seems to favour right turn"
      ],
      "metadata": {
        "id": "IWQCQrR-oCps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "note: imbalance datset"
      ],
      "metadata": {
        "id": "K4pZ65pYvdqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "identifying the row with the erroneous speed value"
      ],
      "metadata": {
        "id": "xJmG7jmNkE0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df[merged_df['speed'] == 1.428571]"
      ],
      "metadata": {
        "id": "wAQnbLLeiqy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to remove this row"
      ],
      "metadata": {
        "id": "zMZq41-RkLz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = merged_df[merged_df['speed'] != 1.428571]\n",
        "cleaned_df.loc[3882:3886]"
      ],
      "metadata": {
        "id": "TDMqIiOLSKGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## convert from pandas to tf\n"
      ],
      "metadata": {
        "id": "Di6F6km_DBmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
        "    image = tf.image.resize(image, (128, 128))  # Resize to uniform shape\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image, label\n",
        "\n",
        "# Convert DataFrame into a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((cleaned_df[\"image_file_paths\"], cleaned_df[\"angle\"]))\n",
        "\n",
        "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(len(cleaned_df))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "for images, labels in dataset.take(1):\n",
        "    print(images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "oeeBTruNCQ96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.8 * dataset_size)\n",
        "\n",
        "# Split into training and test sets\n",
        "train_dataset = dataset.take(train_size)\n",
        "validation_dataset = dataset.skip(train_size)\n",
        "\n",
        "#not using test set as kaggle is our test set\n",
        "\n",
        "print(f\"Train size: {train_size}, Test size: {dataset_size - train_size}\")"
      ],
      "metadata": {
        "id": "yYlssPh5dxaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataset.take(1):\n",
        "    print(batch)"
      ],
      "metadata": {
        "id": "OeboVhsQKGFS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = dropoutrate\n",
        "input_shape = input_shape\n",
        "\n",
        "mbnet =  tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Eh1-U-VYeN9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  tape.reset() #this resets the gradient tape"
      ],
      "metadata": {
        "id": "DX-wcs04eUTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.001 #learning rate\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser\n",
        "\n",
        "@tf.function\n",
        "def train_step( model, X , Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model( X )\n",
        "        Y = tf.cast(Y, tf.float32)\n",
        "        current_loss = tf.reduce_mean(tf.losses.MeanSquaredError()( Y,  pred))\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients( zip( grads , model.trainable_variables) )\n",
        "    current_MSE = tf.reduce_mean(tf.square(Y-pred))\n",
        "    return(current_loss, current_MSE)"
      ],
      "metadata": {
        "id": "9AErZvcTeX-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 20\n",
        "\n",
        "tloss = []\n",
        "tMSE = []\n",
        "vloss = []\n",
        "vMSE = []\n",
        "\n",
        "for it in range(niter):\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "      #for image, label in zip(image_batch, label_batch):\n",
        "        #print(image)\n",
        "        #print(label)\n",
        "        #print(image.shape, label.shape)\n",
        "\n",
        "        loss, MSE = train_step(model, image_batch, label_batch) #run training\n",
        "\n",
        "\n",
        "    if it % 10 == 0: #log training metrics\n",
        "      tf.print('iter: ',it, ', loss: {:.3f}, acc: {:.3f}'.format(loss, MSE))\n",
        "      tloss.append(loss)\n",
        "      tMSE.append(MSE)\n",
        "'we should probably switch to balanced accuracy as eval method due to unbalanced data'\n",
        "#commented out validation for now as it prints for each batch not each epoch massively slowwing process\n",
        "'''\n",
        "    if it % 50 == 0: #log validation metrics\n",
        "      for val_image, val_label in validation_dataset:\n",
        "        val_pred = model(val_image)\n",
        "        val_int=tf.cast(val_label, dtype=tf.int32)\n",
        "        val_loss = tf.reduce_mean(tf.losses.categorical_crossentropy(tf.one_hot(val_int,depth=2) , val_pred))\n",
        "        val_acc = tf.reduce_mean(tf.metrics.categorical_accuracy(tf.one_hot(val_int,depth=2) , val_pred))\n",
        "        tf.print('iter: ',it, ', validation loss: {:.3f}, validation acc: {:.3f}'.format(val_loss, val_acc))\n",
        "        vloss.append(val_loss)\n",
        "        vacc.append(val_acc)\n",
        "'''"
      ],
      "metadata": {
        "id": "uE2K4gVQedXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "'''\n",
        "f, axarr = plt.subplots(1,10)\n",
        "\n",
        "i = 0\n",
        "for image_batch, label_batch in dataset.take(1):  # Take one batch\n",
        "    for image in image_batch:  # Iterate through images in the batch\n",
        "        if i < 10:  # Only display the first 5 images\n",
        "            print('image shape: ', np.shape(image))\n",
        "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
        "            axarr[i].imshow(image)\n",
        "            axarr[i].axis('off')\n",
        "            i += 1\n",
        "        else:\n",
        "            break  # Stop after displaying 5 images\n",
        "        plt.show()\n",
        "'''"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "bU7lQg55Mgqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/machine-learning-in-science-ii-2025/car_frozen_regression.weights.h5')"
      ],
      "metadata": {
        "id": "FiHy6opSP2sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session() #Clear keras session"
      ],
      "metadata": {
        "id": "FpLHyw20P93U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = dropoutrate\n",
        "input_shape = input_shape\n",
        "\n",
        "mbnet =  tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZuKL3X-QP-Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/MyDrive/machine-learning-in-science-ii-2025/car_frozen_regression.weights.h5')"
      ],
      "metadata": {
        "id": "8oAenzEiP-C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mbnet.trainable = True\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "06irRCOzP-FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.0001\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser\n"
      ],
      "metadata": {
        "id": "JQvDo1RVP-Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 20\n",
        "\n",
        "tloss = []\n",
        "tMSE = []\n",
        "vloss = []\n",
        "vMSE = []\n",
        "\n",
        "for it in range(niter):\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "      #for image, label in zip(image_batch, label_batch):\n",
        "        #print(image)\n",
        "        #print(label)\n",
        "        #print(image.shape, label.shape)\n",
        "\n",
        "        loss, MSE = train_step(model, image_batch, label_batch) #run training\n",
        "\n",
        "\n",
        "    if it % 10 == 0: #log training metrics\n",
        "      tf.print('iter: ',it, ', loss: {:.3f}, acc: {:.3f}'.format(loss, MSE))\n",
        "      tloss.append(loss)\n",
        "      tMSE.append(MSE)"
      ],
      "metadata": {
        "id": "ZvmWxC1fP-Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/machine-learning-in-science-ii-2025/car_unfrozen_regression.weights.h5')"
      ],
      "metadata": {
        "id": "O14u6175RLjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/test_data/test_data'\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'\n",
        "imagefilepaths_df.head()"
      ],
      "metadata": {
        "id": "W-e59lQQRXKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image_no_label(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Use decode_png for PNG images\n",
        "    image = tf.image.resize(image, (128, 128))  # Resize to uniform shape\n",
        "    image = image / 255.0  # Normalize pixel values to [0,1]\n",
        "    return image\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((imagefilepaths_df[\"image_file_paths\"]))\n",
        "\n",
        "test_dataset = test_dataset.map(process_image_no_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "3hT_c1s5TAR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "NtqcOFr7TAXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = pd.DataFrame(predictions)"
      ],
      "metadata": {
        "id": "pFVWGi04fza7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "AQ7of6YqeNJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(predictions_df).to_csv('/content/drive/MyDrive/machine-learning-in-science-ii-2025/regressionpredictions.csv')"
      ],
      "metadata": {
        "id": "sSUAR4u0TAdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.value_counts()"
      ],
      "metadata": {
        "id": "4CcRKL9KTAfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "deXjPTO0TAiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# add data augmentation steps here"
      ],
      "metadata": {
        "id": "mUBDSjsLNMmT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2sK8FpOKw_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transfer learning here"
      ],
      "metadata": {
        "id": "ynpaLJEeNRtN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BWQC4CWwNXV7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}