{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylaar1/PICAR-autopilot/blob/main/GridSearchCV_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWITCH TO **`T4 GPU`** OR THE **`HPC`**"
      ],
      "metadata": {
        "id": "-fhwRSFoj6C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "g4V83PflfFkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP6UczzNe1l2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "print(platform.system())"
      ],
      "metadata": {
        "id": "O24_U-m8q-xv",
        "outputId": "3c4508ba-bd74-4ba0-ede4-7b234a6a9f29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# makes it so pd dfs aren't truncated\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "IF_vPVifaU9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eocC68amnhEI",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "303a2cf9-8852-44f1-9461-e574345e0f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_file_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_norm.csv' # James file path\n",
        "#labels_file_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025/training_norm.csv' # ben hpc file path (mlis2 cluster)\n",
        "#labels_file_path = '/home/ppytr13/machine-learning-in-science-ii-2025/training_norm.csv' # tyler hpc file path (mlis2 cluster)\n",
        "labels_df = pd.read_csv(labels_file_path, index_col='image_id')"
      ],
      "metadata": {
        "id": "ZiNf_BxOfEH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image_folder_path = '/home/apyba3/KAGGLEDATAmachine-learning-in-science-ii-2025//training_data/training_data'\n",
        "#image_folder_path = '/home/ppytr13/machine-learning-in-science-ii-2025//training_data/training_data'\n",
        "image_folder_path = '/content/drive/MyDrive/machine-learning-in-science-ii-2025/training_data/training_data' # tylers file path\n",
        "image_file_paths = [\n",
        "    os.path.join(image_folder_path, f)\n",
        "    for f in os.listdir(image_folder_path)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "image_file_paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0])) # sorts the files in the right order (1.png, 2.png, 3.png, ...)\n",
        "\n",
        "imagefilepaths_df = pd.DataFrame(\n",
        "    image_file_paths,\n",
        "    columns=['image_file_paths'],\n",
        "    index=[int(os.path.splitext(os.path.basename(path))[0]) for path in image_file_paths]\n",
        ")\n",
        "\n",
        "imagefilepaths_df.index.name = 'image_id'"
      ],
      "metadata": {
        "id": "nOXmN--gb-Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to remove this row"
      ],
      "metadata": {
        "id": "zMZq41-RkLz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = merged_df[merged_df['speed'] != 1.428571]\n",
        "cleaned_df.loc[3882:3886]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "TDMqIiOLSKGX",
        "outputId": "cd65c715-0771-4eb5-8dc4-927d8f2b2d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [angle, speed, image_file_paths]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48bcfdc0-0bf7-4869-b200-5a9583a81b47\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angle</th>\n",
              "      <th>speed</th>\n",
              "      <th>image_file_paths</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48bcfdc0-0bf7-4869-b200-5a9583a81b47')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48bcfdc0-0bf7-4869-b200-5a9583a81b47 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48bcfdc0-0bf7-4869-b200-5a9583a81b47');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in dataset.take(1):\n",
        "    print(images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "jBTNjNhMVk2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2a0e146-2fd4-4515-ca14-994cbab53773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3) (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f, axarr = plt.subplots(1,10)\n",
        "\n",
        "i = 0\n",
        "for image_batch, label_batch in dataset.take(1):  # Take one batch\n",
        "    for image in image_batch:  # Iterate through images in the batch\n",
        "        if i < 10:  # Only display the first 5 images\n",
        "            print('image shape: ', np.shape(image))\n",
        "            tf.print('label:', label_batch[i])  # Print label for the corresponding image\n",
        "            axarr[i].imshow(image)\n",
        "            axarr[i].axis('off')\n",
        "            i += 1\n",
        "        else:\n",
        "            break  # Stop after displaying 5 images\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "OeboVhsQKGFS",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "210e5353-d934-4ef7-ce86-737e4044013a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape:  (224, 224, 3)\n",
            "label: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 0\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n",
            "image shape:  (224, 224, 3)\n",
            "label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropoutrate = 0.2\n",
        "num_classes = 1 # we're only predicting the prob of the positive class with a sigmoid\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    minimalistic=False\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  mbnet,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dropout(dropoutrate),\n",
        "  tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
        "])\n",
        "model.build()\n",
        "\n",
        "mbnet.trainable = False # freeze the first layers to the imagenet weights\n",
        "\n",
        "model.summary() # print the model"
      ],
      "metadata": {
        "id": "Eh1-U-VYeN9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "LR = 0.001  # learning rate\n",
        "optimizer = tf.optimizers.Adam(LR)  # Adam optimizer\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, X, Y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model(X)  # Get the predictions from the model\n",
        "\n",
        "        # Use binary cross-entropy for binary classification\n",
        "        current_loss = tf.reduce_mean(tf.losses.binary_crossentropy(Y, pred))\n",
        "\n",
        "    grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Threshold predictions to binary values (0 or 1) for accuracy calculation\n",
        "    pred_binary = tf.cast(pred > 0.5, dtype=tf.int32)  # Convert predictions to binary (0 or 1)\n",
        "\n",
        "    # Calculate True Positives, False Positives, True Negatives, False Negatives\n",
        "    TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 1), dtype=tf.int32))\n",
        "    TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 0), dtype=tf.int32))\n",
        "    FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y == 0), dtype=tf.int32))\n",
        "    FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y == 1), dtype=tf.int32))\n",
        "\n",
        "    # Calculate Balanced Accuracy\n",
        "    sensitivity = TP / (TP + FN)  # Recall for class 1\n",
        "    specificity = TN / (TN + FP)  # Recall for class 0\n",
        "    balanced_accuracy = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "    return current_loss, balanced_accuracy\n"
      ],
      "metadata": {
        "id": "9AErZvcTeX-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 50\n",
        "\n",
        "tloss = []\n",
        "tacc = []\n",
        "vloss = []\n",
        "vacc = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_accs = []\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "        # Convert labels to correct format for binary classification\n",
        "        # Convert to [batch_size, 1] for binary classification with sigmoid\n",
        "        labels = tf.expand_dims(tf.cast(label_batch, dtype=tf.float32), axis=1)\n",
        "        loss, acc = train_step(model, image_batch, labels)\n",
        "        batch_losses.append(loss)\n",
        "        batch_accs.append(acc)\n",
        "\n",
        "    # Average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses).numpy()\n",
        "    avg_acc = tf.reduce_mean(batch_accs).numpy()\n",
        "    tloss.append(avg_loss)\n",
        "    tacc.append(avg_acc)\n",
        "\n",
        "    # LOGGING METRICS TO CHECK HOW TRAIING IS GOING\n",
        "\n",
        "    if it % 10 == 0:\n",
        "        tf.print(f'iter: {it}, train_loss: {avg_loss:.3f}, train_balanced_acc: {avg_acc:.3f}')\n",
        "\n",
        "        # If you have a validation dataset, evaluate on it\n",
        "        if 'val_dataset' in globals():\n",
        "            val_losses = []\n",
        "            val_accs = []\n",
        "            for val_images, val_labels in val_dataset:\n",
        "                val_labels = tf.expand_dims(tf.cast(val_labels, dtype=tf.float32), axis=1)\n",
        "                val_preds = model(val_images)\n",
        "                val_loss = tf.reduce_mean(tf.losses.binary_crossentropy(val_labels, val_preds))\n",
        "\n",
        "                # Use the same balanced accuracy calculation as in train_step\n",
        "                pred_binary = tf.cast(val_preds > 0.5, dtype=tf.int32)\n",
        "                val_labels_int = tf.cast(val_labels, dtype=tf.int32)\n",
        "\n",
        "                TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 1), dtype=tf.int32))\n",
        "                TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 1), dtype=tf.int32))\n",
        "\n",
        "                sensitivity = TP / (TP + FN + 1e-7)\n",
        "                specificity = TN / (TN + FP + 1e-7)\n",
        "                val_acc = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "\n",
        "            avg_val_loss = tf.reduce_mean(val_losses).numpy()\n",
        "            avg_val_acc = tf.reduce_mean(val_accs).numpy()\n",
        "            vloss.append(avg_val_loss)\n",
        "            vacc.append(avg_val_acc)\n",
        "\n",
        "            tf.print(f'val_loss: {avg_val_loss:.3f}, val_balanced_acc: {avg_val_acc:.3f}')"
      ],
      "metadata": {
        "id": "uE2K4gVQedXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6492ff1a-c155-40c1-cca5-694be20b8442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0, train_loss: 0.525, train_balanced_acc: 0.503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "niter = 50\n",
        "\n",
        "tloss = []\n",
        "tacc = []\n",
        "vloss = []\n",
        "vacc = []\n",
        "\n",
        "for it in range(niter):\n",
        "    # Training\n",
        "    batch_losses = []\n",
        "    batch_accs = []\n",
        "    for image_batch, label_batch in train_dataset:\n",
        "        # Convert labels to correct format for binary classification\n",
        "        # Convert to [batch_size, 1] for binary classification with sigmoid\n",
        "        labels = tf.expand_dims(tf.cast(label_batch, dtype=tf.float32), axis=1)\n",
        "        loss, acc = train_step(model, image_batch, labels)\n",
        "        batch_losses.append(loss)\n",
        "        batch_accs.append(acc)\n",
        "\n",
        "    # Average metrics for this epoch\n",
        "    avg_loss = tf.reduce_mean(batch_losses).numpy()\n",
        "    avg_acc = tf.reduce_mean(batch_accs).numpy()\n",
        "    tloss.append(avg_loss)\n",
        "    tacc.append(avg_acc)\n",
        "\n",
        "    # LOGGING METRICS TO CHECK HOW TRAIING IS GOING\n",
        "\n",
        "    if it % 10 == 0:\n",
        "        tf.print(f'iter: {it}, train_loss: {avg_loss:.3f}, train_balanced_acc: {avg_acc:.3f}')\n",
        "\n",
        "        # If you have a validation dataset, evaluate on it\n",
        "        if 'val_dataset' in globals():\n",
        "            val_losses = []\n",
        "            val_accs = []\n",
        "            for val_images, val_labels in val_dataset:\n",
        "                val_labels = tf.expand_dims(tf.cast(val_labels, dtype=tf.float32), axis=1)\n",
        "                val_preds = model(val_images)\n",
        "                val_loss = tf.reduce_mean(tf.losses.binary_crossentropy(val_labels, val_preds))\n",
        "\n",
        "                # Use the same balanced accuracy calculation as in train_step\n",
        "                pred_binary = tf.cast(val_preds > 0.5, dtype=tf.int32)\n",
        "                val_labels_int = tf.cast(val_labels, dtype=tf.int32)\n",
        "\n",
        "                TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 1), dtype=tf.int32))\n",
        "                TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (val_labels_int == 0), dtype=tf.int32))\n",
        "                FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (val_labels_int == 1), dtype=tf.int32))\n",
        "\n",
        "                sensitivity = TP / (TP + FN + 1e-7)\n",
        "                specificity = TN / (TN + FP + 1e-7)\n",
        "                val_acc = 0.5 * (sensitivity + specificity)\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "\n",
        "            avg_val_loss = tf.reduce_mean(val_losses).numpy()\n",
        "            avg_val_acc = tf.reduce_mean(val_accs).numpy()\n",
        "            vloss.append(avg_val_loss)\n",
        "            vacc.append(avg_val_acc)\n",
        "\n",
        "            tf.print(f'val_loss: {avg_val_loss:.3f}, val_balanced_acc: {avg_val_acc:.3f}')"
      ],
      "metadata": {
        "id": "ZvmWxC1fP-Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_weights('/home/apyba3/car_unfrozen.weights.h5')\n",
        "model.save_weights('/home/ppytr13/car_unfrozen.weights.h5')"
      ],
      "metadata": {
        "id": "O14u6175RLjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = pd.DataFrame(predictions, columns=['speed'])"
      ],
      "metadata": {
        "id": "pFVWGi04fza7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "OnO0K1rReHOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sigmoid output is between [0,1]"
      ],
      "metadata": {
        "id": "sftRAg6PPnsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df[predictions_df['speed'] > 0.5] = 1\n",
        "predictions_df[predictions_df['speed'] < 0.5] = 0"
      ],
      "metadata": {
        "id": "AQ7of6YqeNJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.to_csv('/home/apyba3/mbnetv3_speedclassification_predictions.csv')"
      ],
      "metadata": {
        "id": "deXjPTO0TAiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsp7UPIJQlKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b6KVVfBz2b0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search CV to tune the Hyperperameters"
      ],
      "metadata": {
        "id": "anBySsNy2c4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Function to build the model with tunable hyperparameters\n",
        "def build_model(learning_rate=0.001, dropout_rate=0.2):\n",
        "    mbnet = tf.keras.applications.MobileNetV3Large(\n",
        "        input_shape=(224,224,3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    mbnet.trainable = False  # Freeze base layers\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        mbnet,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Regression output\n",
        "    ])\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "                  loss='mean_squared_error',  # Adjust loss for regression\n",
        "                  metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Wrap the model using KerasRegressor for GridSearchCV\n",
        "keras_regressor = KerasRegressor(build_fn=build_model, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'learning_rate': [0.0001, 0.001, 0.01],  # Test different learning rates\n",
        "    'dropout_rate': [0.2, 0.3, 0.4],        # Tune dropout rate\n",
        "    'batch_size': [32, 64],                 # Tune batch size\n",
        "    'epochs': [10, 20]                      # Number of training epochs\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=keras_regressor, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)  # Replace X_train, y_train with your dataset\n",
        "\n",
        "# Print best parameters and best score\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best MAE score:\", -grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "y_d3zjh42jgq",
        "outputId": "fdc298dd-2c17-4823-abe3-b939f54e8b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow.keras.wrappers.scikit_learn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f88a1b3e70ff>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Function to build the model with tunable hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers.scikit_learn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "id": "P4giIC6059k0",
        "outputId": "eabf2bf3-30b0-459c-da1b-989e5d787a23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "import numpy as np\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "# Defines a function to build the model with tunable hyperparameters\n",
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=hp.Int('conv1_filters', 32, 128, step=32), kernel_size=3, activation='relu', input_shape=(64, 64, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D(filters=hp.Int('conv2_filters', 32, 128, step=32), kernel_size=3, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(units=hp.Int('dense_units', 64, 256, step=64), activation='relu'),\n",
        "        tf.keras.layers.Dropout(rate=hp.Float('dropout_rate', 0.2, 0.5, step=0.1)),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='LOG')),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# deffineing training step\n",
        "@tf.function\n",
        "def train_step(model, train_dataset):\n",
        "    for X_train, Y_train in train_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            pred = model(X_train)\n",
        "            current_loss = tf.reduce_mean(tf.losses.binary_crossentropy(Y_train, pred))\n",
        "        grads = tape.gradient(current_loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        pred_binary = tf.cast(pred > 0.5, dtype=tf.int32)\n",
        "        TP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y_train == 1), dtype=tf.int32))\n",
        "        TN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y_train == 0), dtype=tf.int32))\n",
        "        FP = tf.reduce_sum(tf.cast((pred_binary == 1) & (Y_train == 0), dtype=tf.int32))\n",
        "        FN = tf.reduce_sum(tf.cast((pred_binary == 0) & (Y_train == 1), dtype=tf.int32))\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "        balanced_acc = balanced_accuracy_score(Y_train.numpy(), pred_binary.numpy())\n",
        "\n",
        "        return current_loss, accuracy, balanced_acc\n",
        "\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "train_labels = (train_labels < 5).astype(int)  # Convert to binary classification\n",
        "\n",
        "def preprocess_images(images):\n",
        "    images = tf.image.resize(images, (64, 64))\n",
        "    images = images / 255.0\n",
        "    return images\n",
        "\n",
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)\n",
        "\n",
        "# cvreates dataset pipeline\n",
        "batch_size = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(1000).batch(batch_size)\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='tuner_results',\n",
        "    project_name='autonomous_car_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(train_images, train_labels, epochs=10, validation_split=0.2)\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# 6traines the best model\n",
        "best_model = build_model(best_hps)\n",
        "best_model.fit(train_images, train_labels, epochs=20, batch_size=best_hps.get('batch_size'))\n"
      ],
      "metadata": {
        "id": "kcVMYq4U5o-b",
        "outputId": "8d135450-3697-4a8d-b86c-b2afcdc9411f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 57s]\n",
            "val_accuracy: 0.7008000016212463\n",
            "\n",
            "Best val_accuracy So Far: 0.7181000113487244\n",
            "Total elapsed time: 00h 07m 11s\n",
            "\n",
            "Search: Running Trial #11\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "96                |96                |conv1_filters\n",
            "64                |128               |conv2_filters\n",
            "256               |192               |dense_units\n",
            "0.4               |0.4               |dropout_rate\n",
            "0.00040536        |0.00066498        |learning_rate\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m 740/1250\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.5574 - loss: 0.6821"
          ]
        }
      ]
    }
  ]
}